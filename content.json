{"meta":{"title":"微笑流浪","subtitle":"silly-billy","description":"accumulating of knowledge and experience","author":"silly-billy","url":"https://sillybilly-share.top","root":"/"},"pages":[{"title":"404 Not Found","date":"2022-11-24T01:35:09.626Z","updated":"2022-11-24T01:35:09.626Z","comments":true,"path":"404.html","permalink":"https://sillybilly-share.top/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"关于","date":"2022-11-24T01:35:09.631Z","updated":"2022-11-24T01:35:09.631Z","comments":true,"path":"about/index.html","permalink":"https://sillybilly-share.top/about/","excerpt":"","text":"一个永远20 岁的沪漂青年 19年本科软件专业毕业，因为兴趣爱好加入java的学习行列。初入社会,还未遭受社会的毒打，依然对未来充满希望，希望能结识更多的同行大佬。 欢迎大佬们交换友链，互相学习进步哦！ 名称: silly-billy's blog 头像: favicon.ico 地址: sillybilly-share.top 标签: java 个人经历2018-2019 大四毕业前后沉迷实习，主要学习时下主流的开发框架（spring全家桶，微服务RPC远程过程调用等），对自己今后的工作内容有了初步认识。 2019-至今 坐标上海，做着通信和微服务相关工作。 More 当父母开始催着你找女朋友而自己还一事无成时，才发现年轻才是自己最大的资本。 未来可期，余生请多指教。 加油哦！ 陌生人 。 ————一个充满朝气的普通上班族 Last 文章中若存在不足或错误的地方，还望大佬们多多指正"},{"title":"所有分类","date":"2022-11-24T01:35:09.632Z","updated":"2022-11-24T01:35:09.632Z","comments":true,"path":"categories/index.html","permalink":"https://sillybilly-share.top/categories/","excerpt":"","text":""},{"title":"友链","date":"2022-11-24T01:35:09.633Z","updated":"2022-11-24T01:35:09.633Z","comments":true,"path":"friends/index.html","permalink":"https://sillybilly-share.top/friends/","excerpt":"loading 。。。","text":"loading 。。。"},{"title":"所有标签","date":"2022-11-24T01:35:09.634Z","updated":"2022-11-24T01:35:09.634Z","comments":true,"path":"tags/index.html","permalink":"https://sillybilly-share.top/tags/","excerpt":"","text":""}],"posts":[{"title":"mybatis mapper扫描问题","slug":"mybatis Mapper映射问题","date":"2022-11-22T14:16:39.000Z","updated":"2022-11-24T02:20:32.645Z","comments":true,"path":"mybatis Mapper映射问题.html","link":"","permalink":"https://sillybilly-share.top/mybatis%20Mapper%E6%98%A0%E5%B0%84%E9%97%AE%E9%A2%98.html","excerpt":"前提一个平凡的晚上，我悠闲自得的一边听歌一边码着代码，突然调试页面上报错500，查看后端显示org.apache.ibatis.binding.BindingException: Invalid bound statement (not found):xx。 很显然这是mybatis mapper映射关系出了问题，但问题的原因分为很多种，且此前没有遇到过这样的情况，所以在此记录一下。","text":"前提一个平凡的晚上，我悠闲自得的一边听歌一边码着代码，突然调试页面上报错500，查看后端显示org.apache.ibatis.binding.BindingException: Invalid bound statement (not found):xx。 很显然这是mybatis mapper映射关系出了问题，但问题的原因分为很多种，且此前没有遇到过这样的情况，所以在此记录一下。 三板斧每个人处理问题都有自己的一套流程，不太愿意遇到问题直接debug源码。所以我也是按照过往经验，逐个排查问题可能存在的原因。这里以若依（多模块单体应用）为例，复现问题场景。 mapper.xml书写错误 xxMapper.xml的namespace配置确认无误，查询id与xxMapper.java里的方法名也保持一致，所以不存在书写错误，这一情况直接否了。 mapperLocations未正确配置123#Mybatis-plusmybatis-plus: mapper-locations: classpath*:mapper/**/*Mapper.xml 因为若依框架是多模块工程，需要扫描jar包内部的mapper文件，所以需要配置classpath*而不能配置为classpath。但我们这里配置是没有任何问题的。但我一度认为这个配置没有生效，于是乎手动定义SqlSessionFactory 123456789101112131415@Beanpublic SqlSessionFactory sqlSessionFactory(DataSource dataSource) throws Exception &#123; //实体扫描，多个package用逗号或者分号分隔 String typeAliasesPackage = env.getProperty(\"mybatis-plus.typeAliasesPackage\"); // 配置mapper.xml地址 String mapperLocations = env.getProperty(\"mybatis-plus.mapperLocations\"); // 驼峰转换与缓存配置 String configLocation = env.getProperty(\"mybatis-plus.configLocation\"); ... sessionFactory.setDataSource(dataSource); sessionFactory.setTypeAliasesPackage(typeAliasesPackage); sessionFactory.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(mapperLocations)); sessionFactory.setConfigLocation(new DefaultResourceLoader().getResource(configLocation)); return sessionFactory.getObject();&#125; 报错依然存在，于是排除mapper-locations的配置问题 未及时maven install因为是多模块开发，可能我在当前模块新增的xxMapper.xml文件，没有打包到启动jar包里面？虽然-但是经检查打包也没有什么问题。 异常堆栈追溯可惜一套三板斧挥完，却找不到问题的原因，无奈只能按照堆栈从源码入手了。 MybatisMapperProxy了解过mybatis源码的应该都知道，我们获取的mapper映射对象是jdk生成的接口的动态代理类org.apache.ibatis.binding.MapperProxy，它实现了InvocationHandler接口,是我们sql执行的入口。 我们平台集成的mybatis-plus,它从mybatis中拷贝出MapperProxy，衍生出MybatisMapperProxy,所以一切报错的源头都要从这个类看起。因为是动态代理，这里执行invoke方法 if (Object.class.equals(method.getDeclaringClass()))肯定不成立，我们直接跳过看MybatisMapperProxy#cachedInvoker方法。 CollectionUtils.computeIfAbsent其实就是调用的concurrentHashMap#computeIfAbsent,如果methodCache.get(method)为null,就执行内部匿名函数 所以我们大致能明白methodCache充当了一个二级缓存的效果,如果每次的查询的方法一致就直接从缓存中取出结果返回。 当然第一次执行的时候，我们的缓存中肯定是空的，且我们需要执行的方法并不是默认实现，所以就执行到这一步 return new PlainMethodInvoker(new MybatisMapperMethod(mapperInterface, method, sqlSession.getConfiguration())); MybatisMapperMethodPlainMethodInvoker是MybatisMapperProxy一个内部类,它实现了MapperMethodInvoker接口,它的职责是通过MyBatis自定义的MapperMethod来执行对应的sqlSession 请求。我们需要先看new MybatisMapperMethod构造函数由哪些部分组成 SqlCommand调用resolveMappedStatement获取一个映射语句MappedStatement，然后设置其name和type MethodSignature类定义了method相关属性与本次排查无关。 所以呢，我们直接rua到MapperMethod#SqlCommand方法中 这里看到了我们的预期报错日志，那么就有理由怀疑MappedStatement对象为空,导致方法抛出BindingException异常 我们查看resolveMappedStatement执行情况来验证我们的猜想 statementId很明显是请求接口的全限定名,当前参数MapperInterface和declaringClass一致，所以如果configuration.hasStatement(statementId): false,实际就是Configuration#mappedStatements中需要包含这个statementId，否则此方法便会走到else if分支，返回null导致页面报错。 从上图执行结果来看，也确实如此，mappedStatements并没有包含我们想加载的statementId，所以下一步我们要看mappedStatements是如何初始化的 MybatisPlusAutoConfiguration前面饶了一大圈，主要是从报错方向入手找到问题的根本原因。因为我们知道mappedStatements是由MybatisPlusAutoConfiguration#sqlSessionFactory初始化而来， 所以现在又回到最初的起点。当然也可以通过打断点看调用链找到初始化源头 在MybatisSqlSessionFactoryBean#buildSqlSessionFactory方法中有这样一段 1234567891011121314151617// 遍历所有已加载的mapper.xmlfor (Resource mapperLocation : this.mapperLocations) &#123; if (mapperLocation == null) &#123; continue; &#125; try &#123; XMLMapperBuilder xmlMapperBuilder = new XMLMapperBuilder(mapperLocation.getInputStream(), targetConfiguration, mapperLocation.toString(), targetConfiguration.getSqlFragments()); // 初始化mappedStatements入口 xmlMapperBuilder.parse(); &#125; catch (Exception e) &#123; throw new NestedIOException(\"Failed to parse mapping resource: '\" + mapperLocation + \"'\", e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; LOGGER.debug(() -&gt; \"Parsed mapper file: '\" + mapperLocation + \"'\");&#125; 在调试过程中我发现mapperLocations中并不存在新增的mapper.xml,这是导致该mapper中的方法未加载到mappedStatements的根本原因。 那么为什么yml配置文件的mapperLocations正确配置，却未加载xml文件呢？带着问题，我们回到MybatisPlusAutoConfiguration看下mapperLocations的初始化方法。 123if (!ObjectUtils.isEmpty(this.properties.resolveMapperLocations())) &#123; factory.setMapperLocations(this.properties.resolveMapperLocations());&#125; 可以发现源头在this.properties.resolveMapperLocations()方法中，主要是通过ResourceLoader作为统一资源定位器,获取正则目录下的所有xml文件 从上面的截图可以发现，所有加载的xml都是从编译后的target文件中获取的,且sys、quartz、gen模块都是能正常加载的。 第一反应，难不成新建的crawler模块下面没有可以加载的xml文件？所以跑去target下查看目录结构 乍一看好像没毛病，可为什么sys模块可以正常运行呢？ 猛然发现了一个华点！！为什么编译后crawler模块下的mapper和crawler没有分层？猛拍脑壳哈哈 idea选中resource下的mapper.crawler右击open in explorer 果然！！mapper.crawler是一个文件，但在编译器中看不出差别,所以这就是mapper-locations配置为classpath*:mapper/**/*Mapper.xml却没有成功加载mapper.xml的根本原因，正则匹配不上… 最后经验 + 1 ， 三板斧 + 1","categories":[],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"https://sillybilly-share.top/tags/mybatis/"}]},{"title":"JWT原理与基本使用","slug":"JWT原理与基本使用","date":"2022-03-27T15:16:39.000Z","updated":"2022-11-24T01:35:09.627Z","comments":true,"path":"JWT原理与基本使用.html","link":"","permalink":"https://sillybilly-share.top/JWT%E5%8E%9F%E7%90%86%E4%B8%8E%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8.html","excerpt":"前提写这篇文章的原因是因为前段时间接手了一个项目，它并没有使用公司的统一的单点登录平台sso,而是通过调用uim接口来验证用户信息，并以JWT的实现方式生成一段token存到客户端的localStorage中，登录后的客户端每次携带该token去请求后端，经由后端服务器自定义的filter解析校验token完成登录。 究其原因，可能目前sso的实现方案符合cas标准，需要利用浏览器的重定向功能，而app全是接口交互，所以在系统需要兼容web端与移动端的情况下，采用了JWT来实现登录认证流程。之前我对于JWT是一种半了解的状态，于是乎趁此机会浅学了一波JWT的基本使用。","text":"前提写这篇文章的原因是因为前段时间接手了一个项目，它并没有使用公司的统一的单点登录平台sso,而是通过调用uim接口来验证用户信息，并以JWT的实现方式生成一段token存到客户端的localStorage中，登录后的客户端每次携带该token去请求后端，经由后端服务器自定义的filter解析校验token完成登录。 究其原因，可能目前sso的实现方案符合cas标准，需要利用浏览器的重定向功能，而app全是接口交互，所以在系统需要兼容web端与移动端的情况下，采用了JWT来实现登录认证流程。之前我对于JWT是一种半了解的状态，于是乎趁此机会浅学了一波JWT的基本使用。 概念JSON Web Token简称JWT，在https://jwt.io/中，有一段对于JWT的描述，大体意思为JWT拥有一套开放的行业标准(RFC 7519)，里面详细介绍了JWT的基本概念，Claims的含义、布局和算法实现等。JWT是一种紧凑的Claims声明格式，适用于空间受限的网络环境中传输，例如 HTTP授权标头和 URI 查询参数。JWT 对Claims编码并转化为 JSON [RFC7159] 对象传输，它被用作JWS[RFC 7515]的有效载荷或者JWE[RFC 7516]（加密后）的字符串。JWT 使用 JWS/JWE Compact 序列化，使用Message Authentication Code (MAC)and/or 加密手段对claims签名并提供完整性保护。 以上概念摘自规范性文件RFC7519，对于文中提到了JWS、JWE简单描述如下： JWS（祥见RFC 7515）：JSON Web Signature，使用基于JSON的数据结构的数字签名或消息身份验证码（MAC），对传输的Claims提供了完整性保护（Claims内容不被篡改，但会暴露明文）。 JWE（详见RFC 7516）：JSON Web Encryption，使用基于 JSON 的数据结构的加密内容、这使得Claims在传输过程中被破解的难度提高。 目前已知的主流框架大都未实现JWE,例如JJWT、auth0，故下文主要以JWS实现方式展开讨论。 123Currently Unsupported Features(当前不支持的功能)Non-compact serialization and parsing.JWE (Encryption for JWT) JWT布局JWS的紧凑布局定义为: 123BASE64URL(UTF8(JWS Protected Header)) || '.' ||BASE64URL(JWS Payload) || '.' ||BASE64URL(JWS Signature) 可以看出JWT由三个部分组成，并且各个部分分别使用Base64url编码，然后以句点连接，他的表现形式如下: 1const token = base64urlEncoding(header) + '.' + base64urlEncoding(payload) + '.' + base64urlEncoding(signature) 此外还有非紧凑布局，将header、payload、signature组合成一个json形式展示，此次不展开讨论（有关紧凑布局、非紧凑布局的概念详见JWS JSON序列化概述） headerJWT中的header又称Jose header，包含描述加密操作和对象签名的参数。下方是JWT中常用的header字段: code(简拼) name（全拼） description（描述） typ Token type token类型(JWT、JWS、JWE) cty Content type payload部分的MediaType(使用嵌套签名或加密，建议将其设置为JWT) alg Message authentication code algorithm 加解密算法 kid Key ID 算法密钥 x5c x.509 Certificate Chain x509证书链（用于服务器验证签名是否有效以及令牌是否真实） x5u x.509 Certificate Chain URL x509证书链的URL（服务器将检索并使用此信息来验证签名是否真实） crit Critical 用作实现定义的扩展，以便接受有效的令牌 payloadpayload部分其实就是一个完整的Claims,而Claims本质上是一个JSON字符串，我们会以k-v的形式去定义它。JWT规范中定义了内置的一些Claims属性，我们可以选用或者自定义一些业务特定的Claims(当然不能和内置的Claims发生冲突)，由于payload部分在JWS中仅作base64编码，即明文是直接暴露在外面的，所以自定义Claims的内容不能涉敏。 JWT中预定义的Claims: code(简拼) name（全拼） description（描述） iss Issuer 确定发布JWT的负责人 sub Subject 确定JWT的主体 aud Audience 标识JWT的目标收件人 exp Expiration Time 过期时间 nbf Not Before 确定JWT开始接受处理的时间。该值必须是NumericDate iat Issued at 确定发布JWT的时间。该值必须是NumericDate jti JWT ID 令牌的唯一标识符(区分大小写) SignatureJWS生成签名依赖特定的签名算法将header、payload部分进行一次签名加密，比较常见的如HS256(HMAC-SHA256)、RS256(RSA-SHA256)。在base64UrlEncode(header).base64UrlEncode(payload).之后拼上此次计算的签名（base64编码后）即为一个完整的java web token。 以简单的HMAC-SHA256为例(伪) 123456789// 定义32位密钥String secretKey = \"11111111111111111111111111111111\";// header payload 为base64编码后的值String content = header + \".\" + payload;Mac mac = HmacUtils.getInitializedMac(HmacAlgorithms.HMAC_SHA_256,secretKey.getBytes(StandardCharsets.UTF_8));// 签名byte[] output = mac.doFinal(content.getBytes(StandardCharsets.UTF_8));// base64得到最终签名结果String signaturePart = new String(Base64.encodeBase64URLSafe(output), StandardCharsets.UTF_8); JWT认证流程 由上图可知，整个JWT的认证流程分为6步： 用户从浏览器携带用户名、密码等身份信息进行登录 服务端确认身份信息后，通过指定的签名算法生成token(不包含敏感信息) 服务器将JWT返回给浏览器端 浏览器之后的请求中会把token携带在Authorization Header中一起发给服务端 服务器验证JWT(包含签名以及特定的Claims属性) 服务器将验证结果返回给浏览器 JWT生成解析流程基于前面对JWT的认知，我们可以通过硬编码的方式，实现一套JWT(JWS)的生成、解析、校验的流程。 引入common、json相关包： 12345678910&lt;dependency&gt; &lt;groupId&gt;commons-codec&lt;/groupId&gt; &lt;artifactId&gt;commons-codec&lt;/artifactId&gt; &lt;version&gt;$&#123;latest-version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;$&#123;latest-version&#125;&lt;/version&gt;&lt;/dependency&gt; 生成JWT示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081/** * JWT签名采用HMAC SHA-256散列算法 * 为了简化开发 固定header内容 * 为例简化开发 固定claims * * @since 1.8 */public class JsonGenerator &#123; // 256bit 密钥 private static final String KEY = \"11111111111111111111111111111111\"; // 初始化序列化对象 private static final ObjectMapper OBJECT_MAPPER = new ObjectMapper(); // header public static final Map&lt;String,String&gt; HEADER = new HashMap&lt;&gt;(4); // payload public static final Map&lt;String,Object&gt; CLAIMS = new HashMap&lt;&gt;(4); static &#123; // 定义Token类型 HEADER.put(\"typ\",\"JWT\"); // 定义签名算法 HEADER.put(\"alg\",\"HS256\"); // 定义发行方 CLAIMS.put(\"iss\", \"iss\"); // uuid CLAIMS.put(\"jti\", 1234567890L); // 过期时间 CLAIMS.put(\"exp\", 1648652266914L); &#125; /** * 编码header * * @return * @throws JsonProcessingException */ String generateHeader() throws JsonProcessingException &#123; byte[] headerBytes = OBJECT_MAPPER.writeValueAsBytes(HEADER); return new String(Base64.encodeBase64URLSafe(headerBytes), StandardCharsets.US_ASCII); &#125; /** * 编码payload * * @return * @throws JsonProcessingException */ String generatePayload() throws JsonProcessingException &#123; byte[] payloadBytes = OBJECT_MAPPER.writeValueAsBytes(CLAIMS); return new String(Base64.encodeBase64URLSafe(payloadBytes), StandardCharsets.UTF_8); &#125; /** * 对header、payload签名 * * @param header * @param payload * @return */ String generateSignature(String header, String payload) &#123; String msg = header + \".\" + payload; Mac mac = HmacUtils.getInitializedMac(HmacAlgorithms.HMAC_SHA_256, KEY.getBytes(StandardCharsets.UTF_8)); byte[] output = mac.doFinal(msg.getBytes(StandardCharsets.UTF_8)); return new String(Base64.encodeBase64URLSafe(output), StandardCharsets.UTF_8); &#125; public static void main(String[] args) throws Exception &#123; JsonGenerator jsonGenerator = new JsonGenerator(); String header = jsonGenerator.generateHeader(); System.out.println(\"生成header部分:\"+header); String payload = jsonGenerator.generatePayload(); System.out.println(\"生成payload部分\"+payload); String signature = jsonGenerator.generateSignature(header, payload); System.out.println(\"最终生成的token:\"+ Stream.of(header,payload,signature).collect(Collectors.joining(\".\"))); &#125;&#125; 运行main函数可以看到控制台输出: 123生成header部分:eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9生成payload部分eyJpc3MiOiJpc3MiLCJleHAiOjE2NDg2NTIyNjY5MTQsImp0aSI6MTIzNDU2Nzg5MH0最终生成的token:eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJpc3MiLCJleHAiOjE2NDg2NTIyNjY5MTQsImp0aSI6MTIzNDU2Nzg5MH0.ZbddEf9xTWJJwnCiDNIWs4t1QUgYsIo7cg1hH4SfM1U 可以将生成token放到jwt.io解析验证 其实这个逆向过程很简单，只需要按分隔符”.”取出编码后的header、payload以及Signature,在对header、payload做base64解码即可，简单的代码实现如下: 123456789101112131415161718public void parse()&#123; String token = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJpc3MiLCJleHAiOjE2NDg2NTIyNjY5MTQsImp0aSI6MTIzNDU2Nzg5MH0.ZbddEf9xTWJJwnCiDNIWs4t1QUgYsIo7cg1hH4SfM1U\"; StringTokenizer tokenizer = new StringTokenizer(token, \".\"); // 我们知道输入格式 所以这里简单写 String[] result = new String[]&#123;tokenizer.nextToken(),tokenizer.nextToken(),tokenizer.nextToken()&#125;; String header = new String(Base64.decodeBase64(result[0]), StandardCharsets.UTF_8); String payload = new String(Base64.decodeBase64(result[1]), StandardCharsets.UTF_8); System.out.println(\"解析后的header:\"+header); System.out.println(\"解析后的payload:\"+payload); System.out.println(\"签名部分:\"+result[2]);&#125;// 控制台输出解析后的header:&#123;\"alg\":\"HS256\",\"typ\":\"JWT\"&#125;解析后的payload:&#123;\"iss\":\"iss\",\"exp\":1648652266914,\"jti\":1234567890&#125;签名部分:ZbddEf9xTWJJwnCiDNIWs4t1QUgYsIo7cg1hH4SfM1U 最后非常重要的一步就是对token的完整与合法性校验。其一是验证上文解析出来的签名，其二是对Claims的重要属性做验证（例如过期时间）,伪代码实现如下： 1234567891011121314151617181920212223public void verify() throws Exception&#123; String token = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJpc3MiLCJleHAiOjE2NDg2NTIyNjY5MTQsImp0aSI6MTIzNDU2Nzg5MH0.ZbddEf9xTWJJwnCiDNIWs4t1QUgYsIo7cg1hH4SfM1U\"; StringTokenizer tokenizer = new StringTokenizer(token, \".\"); // 我们知道输入格式 所以这里简单写 String[] result = new String[]&#123;tokenizer.nextToken(),tokenizer.nextToken(),tokenizer.nextToken()&#125;; String header = new String(Base64.decodeBase64(result[0]), StandardCharsets.UTF_8); String payload = new String(Base64.decodeBase64(result[1]), StandardCharsets.UTF_8); System.out.println(\"解析后的header:\"+header); System.out.println(\"解析后的payload:\"+payload); System.out.println(\"签名部分:\"+result[2]); // 校验签名合法性 String signature = generateSignature(result[0], result[1]); if (!Objects.equals(signature,result[2]))&#123; // 签名校验不通过 自定义异常处理 &#125; Map&lt;String, Object&gt; payloadMap = OBJECT_MAPPER.readValue(payload, new TypeReference&lt;Map&lt;String, Object&gt;&gt;() &#123;&#125;); long exp = Long.parseLong(Objects.toString(payloadMap.get(\"exp\"))); // claims校验 过期时间有效期为1小时 if (System.currentTimeMillis() - exp &gt; 60 * 60 * 1000) &#123; // 签名已过期 自定义异常处理 &#125;&#125; JJWT实现上节的代码实现仅是简单的描述了JWT从生成、解析再到校验的过程，使用的签名算法的安全性较低且方式过于粗暴。在实际应用中还是需要采用主流的JWT框架,避免重复造轮子的同时，活跃的社区也能让问题快速的得到响应。 以开源项目JJWT为例，生成JWT 12345678910111213141516171819202122232425262728private String createJWT(String id, String issuer, String subject, long ttlMillis) &#123; // 签名算法 SignatureAlgorithm signatureAlgorithm = SignatureAlgorithm.HS256; // 定义密钥 String secretKey = \"11111111111111111111111111111111\"; long nowMillis = System.currentTimeMillis(); Date now = new Date(nowMillis); // 设置Claims JwtBuilder builder = Jwts.builder().setId(id) .setIssuedAt(now) .setSubject(subject) .setIssuer(issuer) .signWith(new SecretKeySpec(secretKey.getBytes(), \"HmacSHA256\"), signatureAlgorithm); // 设置过期时间 if (ttlMillis &gt;= 0) &#123; long expMillis = nowMillis + ttlMillis; Date exp = new Date(expMillis); builder.setExpiration(exp); &#125; // 构建 JWT 并将其序列化为紧凑的 URL 安全字符串 return builder.compact(); &#125; 解析校验token 123456789101112131415161718private void parseJWT(String jwt) &#123; // 定义密钥 String secretKey = \"11111111111111111111111111111111\"; // 解析token Claims claims = Jwts.parserBuilder() .setSigningKey(new SecretKeySpec(secretKey.getBytes(), \"HmacSHA256\")) .build() // 解析payload部分 // 进行签名校验，失败会抛出SignatureException异常 // token失效过期会抛出ExpiredJwtException异常 .parseClaimsJws(jwt) .getBody(); System.out.println(\"ID: \" + claims.getId()); System.out.println(\"Subject: \" + claims.getSubject()); System.out.println(\"Issuer: \" + claims.getIssuer()); System.out.println(\"Expiration: \" + claims.getExpiration()); &#125; 总结JWT本质上是一种无状态的token令牌，它设计的初衷就是更关注Claims的完整性，任何拿到JWT的客户端都可以无障碍的和服务器进行交互。这既是它的优势（支持跨域验证，可以应用于单点登录），同时也是它的劣势（JWS只签名不加密，token泄漏后会有安全问题），所以我们需要在算法选型时尽量选择复杂算法，严格校验Claims中的属性并且Claims中不能有敏感字段。 为了处理token过期刷新的问题，前文提到的项目在程序设计上会利用redis key的expire机制，将JWT持久化到redis中。这一点其实有些违背了JWT的设计理念，并且让整个系统强依赖redis（redis挂了系统无法登录）。 JWT与CAS不同的是，它的用户信息是以token的形式存储在客户端，而非存储在服务端。对于过期刷新的问题，其实可以参考OAuth2中refresh token的概念。 参考 规范性文件RFC7519 JJWT 维基百科","categories":[],"tags":[{"name":"jwt","slug":"jwt","permalink":"https://sillybilly-share.top/tags/jwt/"}]},{"title":"swagger接口文档同步yapi定义标准","slug":"swagger接口文档同步yapi定义标准","date":"2021-08-07T05:18:29.000Z","updated":"2022-11-24T01:35:09.629Z","comments":true,"path":"swagger接口文档同步yapi定义标准.html","link":"","permalink":"https://sillybilly-share.top/swagger%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3%E5%90%8C%E6%AD%A5yapi%E5%AE%9A%E4%B9%89%E6%A0%87%E5%87%86.html","excerpt":"前提在与前端约定yapi接口后，后端可能会与前端私下沟通修改接口方案或者业务调整未同步至yapi,导致经常性会出现实际开发接口与yapi维护的接口不统一的情况。滞后的接口文档，给后续介入开发的人员会造成很大的困惑，这也是这块未统一规范的体现。所以文章旨在通过一种定义标准（选型：swagger），通过实际开发中的代码生成yapi接口文档。一般情况下，联调接口会先于开发定义出来，所以需要定义两套文档，一套用于与前端或业务系统联调，另一套生成用于业务系统实际的开发接口。","text":"前提在与前端约定yapi接口后，后端可能会与前端私下沟通修改接口方案或者业务调整未同步至yapi,导致经常性会出现实际开发接口与yapi维护的接口不统一的情况。滞后的接口文档，给后续介入开发的人员会造成很大的困惑，这也是这块未统一规范的体现。所以文章旨在通过一种定义标准（选型：swagger），通过实际开发中的代码生成yapi接口文档。一般情况下，联调接口会先于开发定义出来，所以需要定义两套文档，一套用于与前端或业务系统联调，另一套生成用于业务系统实际的开发接口。 swagger使用配置swagger以Swagger2为例，添加jar包 12345678910&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt; 定义配置SwaggerConfig 1234@Configuration@EnableSwagger2public class SwaggerConfig &#123;&#125; 输入ip:port/swagger-ui.html，默认swagger页面的结构 接口分类信息：例如可以区分定义外部接口和内部接口，用Swagger Docket实例的groupName分组显示 项目基本信息：通过Swagger Docket实例的apiInfo方法描述 接口列表：Swagger Docket实例中指定过滤条件后，Controller层所有接口的展示与调用 定义Docket实例 12345678910111213141516171819202122232425262728293031323334353637@Configuration@EnableSwagger2public class SwaggerConfig &#123; @Bean public Docket docker()&#123; // 构造函数传入初始化规范，这是swagger2规范 return new Docket(DocumentationType.SWAGGER_2) //apiInfo： 添加api详情信息，参数为ApiInfo类型的参数，这个参数包含了项目基本信息的必要条件 .apiInfo(apiInfo()) //groupName 指定接口的分组信息 .groupName(\"groupTest\") //配置是否启用Swagger，如果是false，在浏览器将无法访问。生产环境需要置为false .enable(true) .select() //apis： 添加过滤条件, //.apis(RequestHandlerSelectors.basePackage(\"com.swagger.demo\")) //paths： 这里是控制哪些路径的api会被显示出来，比如下方的参数就是除了/test以外的其它路径都会生成api文档 //.paths((String test) -&gt; !a.equals(\"/test\")) .build(); &#125; private ApiInfo apiInfo()&#123; Contact contact = new Contact(\"项目名称：name\", \"项目连接地址：http://xxx.xxx.com/\", \"联系人邮箱：XXX\"); return new ApiInfo( \"标题内容\", \"描述内容\", \"版本内容：v1.0\", \"链接：http://terms.service.url/\", contact, \"许可\", \"许可链接\", // 扩展信息 new ArrayList&lt;&gt;() ); &#125;&#125; 实体类定义@ApiModel 用于swagger标记实体类 属性 类型 默认值 描述 value String 类名 类的备用名称 description String “” 类的详细描述 parent Class&lt;?&gt; Void.class 提供父类以允许描述继承关系 discriminator String “” 支持模型继承和多态，使用鉴别器的字段的名称，可以断言需要使用哪个子类型 subTypes Class&lt;?&gt;[] {} 继承该类的子类型数组 reference String “” 指定对应类型定义的引用，覆盖指定的任何其他元数据 @ApiModelProperty用于swagger标记实体类属性 属性 描述 value 简洁的介绍字段描述 name 如果设置这个字段，会覆盖原本属性的名字 allowableValues 标明字段的取值范围，例如range[1, infinity] 就是大于等于1 access 允许从API文档中过滤属性，参见 io.swagger.core.filter.SwaggerSpecFilter notes 应该是预留字段，未被使用 dataType 参数的数据类型 required 表示的是当前字段是否是必须的，默认是false position 属性在文档中的位置排序 hidden 表示的是是否隐藏当前字段，默认是false example 样例说明 readOnly 过时，用accessMode代替 accessMode 一个枚举AccessMode的值，其中包括AUTO、READ_ONLY、READ_WRITE reference 指定了属性的类型引用，如果设置了当前属性，会覆盖任何其他的元数据(不常使用) allowEmptyValue 是否允许该字段为空，默认是false extensions 该属性用于进行额外的描述。是一个可选项的数组组成 样例说明 1234567891011121314151617@Data@ApiModel(description = \"用户信息\")public class InfoVO &#123; @ApiModelProperty(value = \"名称\",required = true) private String name; @ApiModelProperty(value = \"价格\",example = \"1.0\") private BigDecimal price; @ApiModelProperty(value = \"状态 0-未删除 1-逻辑删除\",allowableValues = \"0,1\",example = \"0\") private String status; @ApiModelProperty(value = \"时间\",allowEmptyValue = true) private LocalDateTime localDateTime;&#125; 接口定义@Api 注解用于标注类为swagger资源 属性 描述 value 无实义，官网推荐用tags替代 tags tags标签用于将我们的请求分类 description 弃用 basePath 弃用 position 弃用 produces 指定返回的内容类型，仅当request请求头中的(Accept)类型中包含该指定类型才返回，例如:application/json consumes 指定处理请求的提交内容类型(Content-Type)，例如application/json protocols 标识的是当前的请求支持的协议，例如：http、https、ws、wss authorizations 高级特性认证时配置 hidden 配置为true将在文档中隐藏。隐藏整个Controller资源。作用与@ApiIgnore类似，但是没有@ApiIgnore功能强大 @ApiOperation注解一般用于方法上，用作一个HTTP请求的方法描述 属性 描述 value 表示的是这个方法的一个总结性的描述 notes 标识的是对于一个方法的具体性的描述 tags 和@Api的tags功能类似 response 这个属性设置的是当前请求的返回值类型 responseContainer 说明的是包装相应的容器。默认情况下，有效值为 List、Set、Map，任何其它值都将被忽略 responseReference 这里设置的是一个相应类型的引用。这个引用可以是本地的，也可以是远程的。如果设置了这个值，将会覆盖response属性的值 httpMethod 请求方式，例如GET、HEAD、POST、PUT、DELETE、OPTIONS position 弃用 nickname 这个字段对应的是operationId字段。第三方工具使用operationId来唯一表示此操作.在Swagger2.0之后的版本中，这个字段是不在强制的，如果没有，则系统默认为空 produces 指定返回的内容类型，仅当request请求头中的(Accept)类型中包含该指定类型才返回，例如:application/json consumes 指定处理请求的提交内容类型(Content-Type)，例如application/json protocols 标识的是当前的请求支持的协议，例如：http、https、ws、wss authorizations 高级特性认证时配置 hidden 配置为true将在文档中隐藏。隐藏整个Controller资源。作用与@ApiIgnore类似，但是没有@ApiIgnore功能强大 responseHeaders 指定response中header的信息列表 code http返回状态码 extensions 可选的扩展数组,举例：extensions = @Extension(properties ={@ExtensionProperty(name = &quot;author&quot;, value = &quot;test@xx.com&quot;)}) ignoreJsonView 忽略JsonView注解，主要的目的是为了做到向下兼容 样例说明 123456789101112@Api(tags = \"swaggger测试\")@RestControllerpublic class TestController &#123; @ApiOperation(value = \"总结性描述测试1\") @PostMapping(\"/test1\") public APIResult&lt;String&gt; test1(InfoVO infoVO)&#123; //TODO save operation ... return APIResult.ofSuccess(\"数据保存成功\"); &#125;&#125; swagger页面显示结果 基于swagger同步yapi规范因为swaggger对代码的浸入性很强，所以我们尽可能的定义yapi中所需要的接口信息，摒去无用的定义。 实体类定义非代码生成器生成的与数据库表结构相关联的domain类，例如与前端交互的VO类、与外部服务进行数据交换的DTO类，需在类头加上@ApiModel注解，在类属性加上@ApiModelProperty注解，便于补全接口文档的同时又可替换类注释。 @ApiModel注解@apiModel主要用于标记实体类，定义格式： 12@ApiModel(description = \"xxx\") public class XXX 属性 必填项 描述 description 是 定义为类的详细描述 该属性定义后，接口返回类型为Object时，yapi中会显示对象的备注 @ApiModelProperty注解@ApiModelProperty用于标记swagger实体类属性，定义格式： 12@ApiModelProperty(value = \"xxx\",required = true)private String xxx; 属性 必填项 描述 value 是 定义为字段的详细描述 required 否 如果字段为必填项，则需要定义required = true 默认为false 定义该属性用于展示在yapi接口中请求参数、返回参数的字段备注、是否必须项信息 接口定义@Api注解@Api用于标注类为swagger资源，定义格式： 123@Api(tags = \"XXX\")@RestControllerpublic class XXXController 属性 必填项 描述 tags 是 将接口请求分类 定义tags属性，主要用于维护yapi中的文档分类 @ApiOperation注解@ApiOperation用作一个HTTP请求的方法描述，定义格式： 123@ApiOperation(value = \"xxx\")@PostMapping(\"/xxx\")public APIResult&lt;String&gt; xxx()&#123;&#125; 属性 必填项 描述 value 是 一个方法总结性的描述 定义ApiOperation的value属性，主要用于维护yapi中主分类的接口信息 @ApiImplicitParams和@ApiImplicitParam@ApiImplicitParams和@ApiImplicitParam组合使用作用于方法上，这里主要用于定义yapi中请求参数的header属性。如非必须尽量不要使用，代码侵入性太严重了。 定义格式： 1234@ApiImplicitParams(&#123; @ApiImplicitParam(paramType &#x3D; &quot;header&quot;, name &#x3D; &quot;xxx&quot;, value &#x3D; &quot;xxx&quot;, dataType &#x3D; &quot;xxx&quot;, required &#x3D; true), ...&#125;) 属性 必填项 描述 paramType 是 定义为header,这里只用作生成yapi中入参的header属性 name 是 参数名称 value 是 参数的具体含义，用作生成yapi中的备注信息 dataType 否 参数的数据类型 required 否 如果字段为必填项，则需要定义required = true 默认为false yapi中显示结果以及定义方式: 注意事项例如以下的几个接口，均不符合标准 123456789101112131415161718192021222324252627282930313233343536373839//第一种情况 入参为JsonStr 出参为Map@ApiOperation(value = \"错误示范1\")@PostMapping(\"/errTest1\")public Map&lt;String,Object&gt; errTest1(@RequestBody String infoVo)&#123; //TODO save operation ... Map&lt;String,Object&gt; res = new HashMap&lt;&gt;(); res.put(\"msg\",\"ok\"); res.put(\"code\",200); res.put(\"data\",\"1\"); return res;&#125;//第二种情况 使用javabean传参、出参，但javabean中包含Map、Object的情况@Data@ApiModel(description = \"test4\")public class Test4 &#123; @ApiModelProperty(value = \"名称\",required = true) private String name; //object属性 swagger不能识别 @ApiModelProperty(value = \"值\") private Object value; //尽可能将map、object定义成新的javaBean @ApiModelProperty(value = \"用户信息\") private InfoVO infoVo;&#125; @ApiOperation(value = \"错误示范2\")@PostMapping(\"/errTest2\")public APIResult&lt;Test4&gt; errTest2(Test4 test4)&#123; //TODO save operation ... return APIResult.ofSuccess(test4);;&#125; 上方定义的接口生成的swagger文档示例如下 yapi中的接口展示: 错误示例定义出来的接口文档，增大了接口联调的测试难度。接口数据同步到yapi上，因为缺失了必要的字段信息，也会导致接口和代码的可阅读性较差。 所以在实际接口定义过程中，尽量使用javaBean，而不要使用Map、Object、JSON String等方式定义接口的出入参。如果是通用返回结果集，尽量使用泛型替换Object。","categories":[{"name":"接口文档","slug":"接口文档","permalink":"https://sillybilly-share.top/categories/%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3/"},{"name":"swagger","slug":"接口文档/swagger","permalink":"https://sillybilly-share.top/categories/%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3/swagger/"},{"name":"yapi","slug":"接口文档/swagger/yapi","permalink":"https://sillybilly-share.top/categories/%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3/swagger/yapi/"}],"tags":[{"name":"接口文档","slug":"接口文档","permalink":"https://sillybilly-share.top/tags/%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3/"},{"name":"swagger","slug":"swagger","permalink":"https://sillybilly-share.top/tags/swagger/"},{"name":"yapi","slug":"yapi","permalink":"https://sillybilly-share.top/tags/yapi/"}]},{"title":"mysql8.0.22-rpm安装","slug":"mysql8-0-22-rpm安装","date":"2021-01-25T02:39:41.000Z","updated":"2022-11-24T01:35:09.628Z","comments":true,"path":"mysql8-0-22-rpm安装.html","link":"","permalink":"https://sillybilly-share.top/mysql8-0-22-rpm%E5%AE%89%E8%A3%85.html","excerpt":"前提某个远古系统，随着业务量的增长，服务的响应速度过慢，导致用户体验较差。就数据库层面而言，为了寻求优化方案，听闻mysql8对比系统依赖的mysql5.7快了不止一倍，所以本文就mysql的升级安装做一个总结。 准备历史数据备份12#如果需要指定表名 可以添加 --tables [表名] 命令mysqldump -h [ip地址:默认localhost] -u[用户名] -p[密码] [数据库名] &gt; demo.sql","text":"前提某个远古系统，随着业务量的增长，服务的响应速度过慢，导致用户体验较差。就数据库层面而言，为了寻求优化方案，听闻mysql8对比系统依赖的mysql5.7快了不止一倍，所以本文就mysql的升级安装做一个总结。 准备历史数据备份12#如果需要指定表名 可以添加 --tables [表名] 命令mysqldump -h [ip地址:默认localhost] -u[用户名] -p[密码] [数据库名] &gt; demo.sql 删除原有mysql服务(以下操作确保mysql服务已停止)查看历史安装过哪些mysql的rpm包 1rpm -qa | grep mysql 删除rpm包 123#例如： rpm -e --nodeps mysql-community-common-5.7.30-1.el7.x86_64 #多个rpm以逗号分开或者执行多次 查询所有Mysql对应的文件夹 1234whereis mysqlfind / -name mysql#删除所有rm -rf [*] 检查mysql用户组和用户是否存在，没有则创建 123456#检查cat /etc/group | grep mysqlcat /etc/passwd |grep mysql#添加groupadd mysqluseradd -r -g mysql mysql rpm包下载官网地址: https://downloads.mysql.com/archives/community/ centos7 mysql version8.0.22 需要下载的rpm包如下: 安装rpm包安装因为mysql rpm包的server、client存在依赖关系，所以需要有顺序的执行安装rpm包，可以按如下方法操作 12345rpm -ivh mysql-community-common-8.0.22-1.el7.x86_64.rpmrpm -ivh mysql-community-client-plugins-8.0.22-1.el7.x86_64.rpmrpm -ivh mysql-community-libs-8.0.22-1.el7.x86_64.rpmrpm -ivh mysql-community-client-8.0.22-1.el7.x86_64.rpmrpm -ivh mysql-community-server-8.0.22-1.el7.x86_64.rpm 执行 rpm -qa | grep mysql 查看rpm包是否安装成功 my.cnf配置 可用上图中的df -h命令查看每个挂载磁盘的剩余空间容量，一般而言根目录即 / 目录空间分配都不会太大。而mysql默认的数据目录存放在/var/lib/mysql下，在业务数据量很大的时候，很容易让磁盘占满导致数据无法写入，这样不仅会影响本服务，同时在该服务器上的其他业务系统也会受到影响，这显然是不可取的。所以我们需要修改mysql的数据目录地址，上图中可以看出/home下的磁盘较为充裕 123456#/home/mysql充当新的数据目录mkdir -p /home/mysql#指定用户组chown -R mysql:mysql /home/mysql#添加权限chmod -R 755 /home/mysql 还不算完，这里有个坑，但不深追。需要关闭SELinux，可操作方法 12345#1、临时关闭（不用重启机器）：setenforce 0#2.修改/etc/selinux/config 文件将SELINUX=enforcing改为SELINUX=disabled#重启机器即可 否则在后续启动mysql时会发现权限不足 my.cnf调优的配置参考（默认位置 /etc/my.cnf） 123456789101112131415161718192021222324252627282930313233343536# For advice on how to change settings please see# http:&#x2F;&#x2F;dev.mysql.com&#x2F;doc&#x2F;refman&#x2F;8.0&#x2F;en&#x2F;server-configuration-defaults.html[mysqld]## Remove leading # and set to the amount of RAM for the most important data# cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%.innodb_buffer_pool_size &#x3D; 64G## Remove the leading &quot;# &quot; to disable binary logging# Binary logging captures changes between backups and is enabled by# default. It&#39;s default setting is log_bin&#x3D;binlog# disable_log_bin## Remove leading # to set options mainly useful for reporting servers.# The server defaults are faster for transactions and fast SELECTs.# Adjust sizes as needed, experiment to find the optimal values.# join_buffer_size &#x3D; 128Mread_buffer_size &#x3D; 4Msort_buffer_size &#x3D; 8Mread_rnd_buffer_size &#x3D; 8M## Remove leading # to revert to previous value for default_authentication_plugin,# this will increase compatibility with older clients. For background, see:# https:&#x2F;&#x2F;dev.mysql.com&#x2F;doc&#x2F;refman&#x2F;8.0&#x2F;en&#x2F;server-system-variables.html#sysvar_default_authentication_plugin# default-authentication-plugin&#x3D;mysql_native_password#指定新的数据目录datadir&#x3D;&#x2F;home&#x2F;mysqlsocket&#x3D;&#x2F;var&#x2F;lib&#x2F;mysql&#x2F;mysql.sock#忽略大小写 默认为0 在mysqld --initialize执行完成后 无法通过命令修改lower_case_table_names&#x3D;1log-error&#x3D;&#x2F;var&#x2F;log&#x2F;mysqld.logpid-file&#x3D;&#x2F;var&#x2F;run&#x2F;mysqld&#x2F;mysqld.pidinnodb_log_buffer_size &#x3D; 20Mtmp_table_size &#x3D; 16M#mysql8默认编码utf8mb4,兼容utf8这里可以不指定 编译启动mysql12#初始化mysqlmysqld --initialize --user=mysql --datadir=/home/mysql 查看默认密码grep 'temporary password' /var/log/mysqld.log 123456#启动mysqlservice mysqld start#关闭mysqlservice mysqld stop#重启service mysqld restart 修改默认密码和开放远程连接执行mysql -uroot -p,跳出enter password:输入默认密码即可进入mysql命令列界面。 由上图可以看到，执行mysql其他命令之前，我们需要重置mysql的密码，当然除此之外，我们还需要指定加密方式 1234567#更改加密方式alter user 'root'@'localhost' identified with mysql_native_password by '123456';#开放远程连接use mysql;update user set host = '%' where user = 'root';#刷新到策略到缓存 flush privileges; 原因是mysql8的caching_sha2_password属于强加密规则，远程连接工具navicat可能会不支持，并抛出2059错误再次访问，可以看到命令成功执行 其他注意事项在有些机器上安装mysql8，出现了登陆密码的弱口令校验，所以不能设置为像 “123456”这样简单的密码，为了安全考虑，可以将密码设置为中英文+大小写的组合 数据恢复1234567#第一种方法mysql -u[用户名] -p[密码] [数据库名] &lt; demo.sql#第二种方法 mysql -u[用户名] -p[密码]#进入命令列界面mysql&gt;use database;mysql&gt;source demo.sql; 数据目录迁移如果出现磁盘空间不足，需要扩展空间时，可以采用软连接的方式快速的将业务数据迁移出去。(前提:关闭SELinux) 1234567891011121314151617181920212223##一定要先关闭数据库systemctl stop mysqld#在磁盘充足环境创建mysql目录mkdir -p /home/mysql#找到数据目录(例子datadir=/var/lib/mysql)cat /etc/my.cnf|grep datadir#拷贝数据到新的mysql目录下cp /var/lib/mysql/* /home/mysql/#指定用户组chown -R mysql:mysql /home/mysql#修改数据目录名字(先保留原先数据目录 验证完可删除)mv /var/lib/mysql /var/lib/mysql_bak#建立软连接(在原数据目录下)ln -s /home/mysql /var/lib/mysql#启动数据库验证systemctl start mysqld","categories":[{"name":"mysql","slug":"mysql","permalink":"https://sillybilly-share.top/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://sillybilly-share.top/tags/mysql/"}]},{"title":"单点登录-无插件式SSO（cas标准）流程","slug":"单点登录-无插件式SSO（cas标准）流程","date":"2020-11-04T11:25:42.000Z","updated":"2022-11-24T01:35:09.630Z","comments":true,"path":"单点登录-无插件式SSO（cas标准）流程.html","link":"","permalink":"https://sillybilly-share.top/%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95-%E6%97%A0%E6%8F%92%E4%BB%B6%E5%BC%8FSSO%EF%BC%88cas%E6%A0%87%E5%87%86%EF%BC%89%E6%B5%81%E7%A8%8B.html","excerpt":"前提现有用户使用阿里的IDass作为统一身份认证平台，所以我们需要为此做一个定制化开发，舍弃公司原有的登录门户，转而对接阿里单点登录。由于之前并没有类似的经验，所以本人此次学到了不少单点登录的知识，在此做一些记录，方便以后查漏补缺。 单点登录概述单点登录（SSO），英文全称为 Single Sign On。 SSO 是指在多个应用系统中，用户只需要登录一次，就可以访问所有相互信任的应用系统。IDaaS SSO 服务用于解决同一公司不同业务应用之间的身份认证问题，只需要登录一次，即可访问所有添加的应用。","text":"前提现有用户使用阿里的IDass作为统一身份认证平台，所以我们需要为此做一个定制化开发，舍弃公司原有的登录门户，转而对接阿里单点登录。由于之前并没有类似的经验，所以本人此次学到了不少单点登录的知识，在此做一些记录，方便以后查漏补缺。 单点登录概述单点登录（SSO），英文全称为 Single Sign On。 SSO 是指在多个应用系统中，用户只需要登录一次，就可以访问所有相互信任的应用系统。IDaaS SSO 服务用于解决同一公司不同业务应用之间的身份认证问题，只需要登录一次，即可访问所有添加的应用。 插件式SSO（JWT）JWT 协议的流程是，浏览器在 IDaaS 中发起一个 SSO 请求的时候，IDaaS 会利用秘钥产生一个token ，然后将 token 放到请求里面作为参数 id_token 的值传到业务系统中去，业务系统就需要解析这个 token 进行身份识别，但是解析token 的关键就是需要集成我们提供的一个解析使用的 SDK，结合业务系统在 IDaaS 中添加应用的时候生成的一个不变的公钥，SDK+公钥才能对 token 进行校验识别。 无插件式SSO（Cas标准）CAS 协议的流程是浏览器在 IDaaS 中发起一个 SSO 请求的时候 IDaaS 会产生一个一次性随机code（类似于 JWT 中的 token ）作为参数 code 的值传到业务系统，然后业务系统并不解析这个code，而是通过一个 callback 回调在将其原封不动的传给 IDaaS ， IDaaS 对这个code进行验证，如果是我们传过去的就说明请求合法，IDaaS 会将用户信息传给业务系统，如果不是就验证失败。 本着代码改动量最少的优先原则，此次改造选取系统原有单点登录的方式，即以cas方式接入阿里平台。 cas原理与协议使用CAS 标准时，首先是由 CAS Client 发起， CAS Client 会重定向到 CAS Server（由 IDaaS 充当）进行登录，由 CAS Server 进行账户校验且多个 CAS Client 之间可以共享登录的 session ，Server 和Client 是一对多的关系； 从结构上看，CAS 包含两个部分： CAS Server 和 CAS Client 。 CAS Server 需要独立部署，主要负责对用户的认证工作； CAS Client 负责处理对客户端受保护资源的访问请求，需要登录时，重定向到CAS Server。 下图是标准 CAS 最基本的协议过程： CAS Client 与受保护的客户端应用部署在一起，以 Filter 方式保护受保护的资源。对于访问受保护资源的每个 Web 请求， CAS Client 会分析该请求的 Http 请求中是否包含 Service Ticket ，如果没 有，则说明当前用户尚未登录，于是将请求重定向到指定好的 CAS Server 登录地址，并传递 Service（也就是要访问的目的资源地址），以便登录成功过后转回该地址。 用户在 上图流程中的 第 3 步 输入认证信息，如果登录成功， CAS Server 随机产生一个相当长度、唯一、不可伪造的 Service Ticket ，并缓存以待将来验证，之后系统自动重定向到 Service 所在地址，并为客户端浏览器设置一个 Ticket Granted Cookie（TGC）， CAS Client 在拿到 Service 和新产生的 Ticket 过后，在第 5，6 步中与 CAS Server 进行身份核实，以确保 Service Ticket 的合法性。 而在 IDaaS 中， 一个 CAS （标准）应用实现了标准的 CAS 流程。它充当一个 CAS Server的角色。当CAS client 决定使用 CAS （标准）应用作为 CAS Server 时。在登录认证时需要使用 IDaaS 系统中公司的主账号，密码进行认证。 cas接入验证阿里方面并没有接入外网的测试环境，但其符合原生的cas标准，所以为了方便验证，需要在本地搭建一个cas服务。 cas服务器端搭建找一个编译后的版本，比如V4.0.0，下载地址：https://github.com/apereo/cas/releases/tag/v4.0.0将下载好的压缩包解压，并将modules下的cas-server-webapp-4.0.0.war（改名为cas.war）拿出来放到tomcat下部署，当前如果是作为练习的话，可以修改配置文件去掉https的要求。1、WEB-INF/deployerConfigContext.xml修改,添加 p:requireSecure=”false”配置 12&lt;bean id&#x3D;&quot;proxyAuthenticationHandler&quot; class&#x3D;&quot;org.jasig.cas.authentication.handler.support.HttpBasedServiceCredentialsAuthenticationHandler&quot; p:httpClient-ref&#x3D;&quot;httpClient&quot; p:requireSecure&#x3D;&quot;false&quot; &#x2F;&gt; 2、WEB-INF/spring-configuration/ticketGrantingTicketCookieGenerator.xml中将p:cookieSecure置为false 12345&lt;bean id&#x3D;&quot;ticketGrantingTicketCookieGenerator&quot; class&#x3D;&quot;org.jasig.cas.web.support.CookieRetrievingCookieGenerator&quot; p:cookieSecure&#x3D;&quot;false&quot; p:cookieMaxAge&#x3D;&quot;-1&quot; p:cookieName&#x3D;&quot;CASTGC&quot; p:cookiePath&#x3D;&quot;&#x2F;cas&quot; &#x2F;&gt; 3、WEB-INF/spring-configuration/warnCookieGenerator.xml中p:cookieSecure置为false 12345&lt;bean id&#x3D;&quot;warnCookieGenerator&quot; class&#x3D;&quot;org.jasig.cas.web.support.CookieRetrievingCookieGenerator&quot; p:cookieSecure&#x3D;&quot;false&quot; p:cookieMaxAge&#x3D;&quot;-1&quot; p:cookieName&#x3D;&quot;CASPRIVACY&quot; p:cookiePath&#x3D;&quot;&#x2F;cas&quot; &#x2F;&gt; 4、完成上述配置后就可以通过http://ip:port/cas/login 访问cas server了。当然该用户需要拥有系统权限，我们可以在WEB-INF/deployerConfigContext.xml配置真实的用户（实际上这里是需要JDBC支持的）,例如： 12345678&lt;bean id&#x3D;&quot;primaryAuthenticationHandler&quot; class&#x3D;&quot;org.jasig.cas.authentication.AcceptUsersAuthenticationHandler&quot;&gt; &lt;property name&#x3D;&quot;users&quot;&gt; &lt;map&gt; &lt;entry key&#x3D;&quot;admin&quot; value&#x3D;&quot;&quot;&#x2F;&gt; &lt;&#x2F;map&gt; &lt;&#x2F;property&gt; &lt;&#x2F;bean&gt; 效果图： cas客户端验证注：项目中需要引入cas-client-core-{version}.jar 验证过程采用原生的方式配置，需要在项目的web.xml中配置（主要是用户认证和票据认证） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;!-- 用于单点退出，该过滤器用于实现单点登出功能，可选配置 --&gt; &lt;listener&gt; &lt;listener-class&gt;org.jasig.cas.client.session.SingleSignOutHttpSessionListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- 该过滤器用于实现单点登出功能，可选配置 --&gt; &lt;filter&gt; &lt;filter-name&gt;CAS Single Sign Out Filter&lt;/filter-name&gt; &lt;filter-class&gt;org.jasig.cas.client.session.SingleSignOutFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CAS Single Sign Out Filter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!-- 该过滤器负责用户的认证工作，必须启用它 --&gt; &lt;filter&gt; &lt;filter-name&gt;CASFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.jasig.cas.client.authentication.AuthenticationFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;casServerLoginUrl&lt;/param-name&gt; &lt;param-value&gt;https://localhost:18080/cas/login&lt;/param-value&gt; &lt;!--这里的server是服务端的IP --&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;serverName&lt;/param-name&gt; &lt;param-value&gt;http://localhost:8080/CallBillAnalysis&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CASFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!-- 该过滤器负责对Ticket的校验工作，必须启用它 --&gt; &lt;filter&gt; &lt;filter-name&gt;CAS Validation Filter&lt;/filter-name&gt; &lt;filter-class&gt; org.jasig.cas.client.validation.Cas20ProxyReceivingTicketValidationFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;casServerUrlPrefix&lt;/param-name&gt; &lt;param-value&gt;https://localhost:18080/cas&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;serverName&lt;/param-name&gt; &lt;param-value&gt;http://localhost:8080&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CAS Validation Filter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!-- 该过滤器负责实现HttpServletRequest请求的包裹， 比如允许开发者通过HttpServletRequest的getRemoteUser()方法获得SSO登录用户的登录名，可选配置 --&gt; &lt;filter&gt; &lt;filter-name&gt;CAS HttpServletRequest Wrapper Filter&lt;/filter-name&gt; &lt;filter-class&gt; org.jasig.cas.client.util.HttpServletRequestWrapperFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CAS HttpServletRequest Wrapper Filter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!-- 该过滤器使得开发者可以通过org.jasig.cas.client.util.AssertionHolder来获取用户的登录名。 比如AssertionHolder.getAssertion().getPrincipal().getName() --&gt; &lt;filter&gt; &lt;filter-name&gt;CAS Assertion Thread Local Filter&lt;/filter-name&gt; &lt;filter-class&gt;org.jasig.cas.client.util.AssertionThreadLocalFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CAS Assertion Thread Local Filter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; 然后启动web项目，可以在cas server控制台中看到，单点登录的验证被cas分成了以下四个流程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354552020-11-05 15:02:09,110 INFO [com.github.inspektr.audit.support.Slf4jLoggingAuditTrailManager] - &lt;Audit trail record BEGIN&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;WHO: audit:unknownWHAT: supplied credentials: [admin+password]ACTION: AUTHENTICATION_SUCCESSAPPLICATION: CASWHEN: Thu Nov 05 15:02:09 CST 2020CLIENT IP ADDRESS: 0:0:0:0:0:0:0:1SERVER IP ADDRESS: 0:0:0:0:0:0:0:1&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;2020-11-05 15:02:09,115 INFO [com.github.inspektr.audit.support.Slf4jLoggingAuditTrailManager] - &lt;Audit trail record BEGIN&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;WHO: audit:unknownWHAT: TGT-1-eGvRWwn7rsB49Fll1eubp9vIWPY2G3hgsdsRke6p2rkSBCryRQ-cas01.example.orgACTION: TICKET_GRANTING_TICKET_CREATEDAPPLICATION: CASWHEN: Thu Nov 05 15:02:09 CST 2020CLIENT IP ADDRESS: 0:0:0:0:0:0:0:1SERVER IP ADDRESS: 0:0:0:0:0:0:0:1&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;2020-11-05 15:02:09,122 INFO [org.jasig.cas.CentralAuthenticationServiceImpl] -&lt;Granted service ticket [ST-1-UsZN9ffonNXSOH1B9Qhx-cas01.example.org] for service [http:&#x2F;&#x2F;localhost:8080&#x2F;CallBillAnalysis&#x2F;CallBillAnalysis&#x2F;] for user [admin]&gt;2020-11-05 15:02:09,124 INFO [com.github.inspektr.audit.support.Slf4jLoggingAuditTrailManager] - &lt;Audit trail record BEGIN&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;WHO: adminWHAT: ST-1-UsZN9ffonNXSOH1B9Qhx-cas01.example.org for http:&#x2F;&#x2F;localhost:8080&#x2F;CallBillAnalysis&#x2F;CallBillAnalysis&#x2F;ACTION: SERVICE_TICKET_CREATEDAPPLICATION: CASWHEN: Thu Nov 05 15:02:09 CST 2020CLIENT IP ADDRESS: 0:0:0:0:0:0:0:1SERVER IP ADDRESS: 0:0:0:0:0:0:0:1&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;2020-11-05 15:02:09,156 INFO [com.github.inspektr.audit.support.Slf4jLoggingAuditTrailManager] - &lt;Audit trail record BEGIN&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;WHO: audit:unknownWHAT: ST-1-UsZN9ffonNXSOH1B9Qhx-cas01.example.orgACTION: SERVICE_TICKET_VALIDATEDAPPLICATION: CASWHEN: Thu Nov 05 15:02:09 CST 2020CLIENT IP ADDRESS: 127.0.0.1SERVER IP ADDRESS: 127.0.0.1&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; Service ticket(ST)：服务票据，由KDC的TGS发放。任何一台Workstation都需要拥有一张有效的 Service Ticket 才能访问域内部的应用(Applications)。Ticket Granting tieckt(TGT)：票据授权票据，由KDC的AS发放。即获取这样一张票据后，以后申请各种其他服务票据(ST)便不必再向KDC提交身份认证信息(准确术语是Credentials)。 第一步、第二步,用户通过Authentication service(AS)即认证服务，之后索取credentials，用于发放TGT。 第三步，由于cas-client认证需要ST（票据服务），所以需要由ticket-granting service(TGS)即票据授权服务拿到上一步的TGT，并创建ST。 第四步，cas-client拿到ST之后，将票据和项目启动默认地址提交调用TicketValidator#validate(ST，#{project-start-default-url})提交给cas-server做验证。 票据验证成功后，我们可以拿到用户名以及其它信息，用于系统后续的权限认证。 项目接入cas在此之前，项目里拥有自己的单点登录模块，并重写了cas-client相关验证方法，所以我们沿用之前的配置的时候，难免有些地方会有出入，需要对原有代码进行改造。 ST验证的Serice-url不一致保证cas-server启动的情况下，将项目参数（sso server地址）配置完成，启动项目,成功被cas-server拦截在登录页面。 在输入用户名和密码后，页面一直在重定向跳转(cas-server用户认证成功，但在后续操作中失败导致不停的回滚重试)。 并且服务器端报错，log日志如下： 1234567891011121314152020-11-05 18:11:15,221 ERROR [org.jasig.cas.CentralAuthenticationServiceImpl] - &lt;ServiceTicket [ST-56-jt4cn4404nJEpJgYguD2-cas01.example.org] with service [http:&#x2F;&#x2F;localhost:8080&#x2F;CallBillAnalysis&#x2F;cas] does not match supplied service [http:&#x2F;&#x2F;localhost:8080&#x2F;CallBillAnalysis&#x2F;cas&#x2F;CallBillAnalysis&#x2F;cas]&gt;2020-11-05 18:11:15,222 INFO [com.github.inspektr.audit.support.Slf4jLoggingAuditTrailManager] - &lt;Audit trail record BEGIN&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;WHO: audit:unknownWHAT: ST-56-jt4cn4404nJEpJgYguD2-cas01.example.orgACTION: SERVICE_TICKET_VALIDATE_FAILEDAPPLICATION: CASWHEN: Thu Nov 05 18:11:15 CST 2020CLIENT IP ADDRESS: 127.0.0.1SERVER IP ADDRESS: 127.0.0.1&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; 从服务器日志可以看出，cas-client拿到票据信息向服务端校验的时候失败了，失败原因是http://localhost:8080/CallBillAnalysis/cas和http://localhost:8080/CallBillAnalysis/cas/CallBillAnalysis/cas不匹配，在项目中发现这样一段代码： 1234567public String getCasService() &#123; StringBuffer req = request.getRequestURL(); req.substring(0, req.indexOf(request.getContextPath())); //这里又拼了一次 req.append(request.getContextPath()).append(\"/cas\"); return req.toString(); &#125; 把req.append(request.getContextPath()).append(“/cas”);这段代码注释掉，不再报此问题。 票据验证的超时处理页面仍然疯狂重定向，好巧不巧的我把断点打在了票据验证的方法上，因为需要查看票据验证的内部逻辑，所以有些耗时，而这种操作一般会大于ST票据的默认有效期（10秒），导致cas-server控制台又抛出错误 123456789101112132020-11-05 18:31:44,126 INFO [org.jasig.cas.CentralAuthenticationServiceImpl] -&lt;ServiceTicket [ST-70-QmOkXqbaJcuKkZ5hqkWf-cas01.example.org] has expired.&gt;2020-11-05 18:31:44,130 INFO [com.github.inspektr.audit.support.Slf4jLoggingAuditTrailManager] - &lt;Audit trail record BEGIN&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;WHO: audit:unknownWHAT: ST-70-QmOkXqbaJcuKkZ5hqkWf-cas01.example.orgACTION: SERVICE_TICKET_VALIDATE_FAILEDAPPLICATION: CASWHEN: Thu Nov 05 18:31:44 CST 2020CLIENT IP ADDRESS: 127.0.0.1SERVER IP ADDRESS: 127.0.0.1&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; 从日志中可以看出ServiceTicket has expired 已经过期了。所以我们需要修改cas server票据有效期的默认配置。 修改CAS服务器本身的超时判断时间,在WEB-INF/cas.properties中修改,将st.timeToKillInSeconds（默认10s）参数调大 1st.timeToKillInSeconds&#x3D;500 无法获取到用户名此时如果不出意外的话，TicketValidator#validate会校验成功，server控制台会出现SERVICE_TICKET_VALIDATED校验成功的字段。 12345678910112020-11-05 18:58:15,305 INFO [com.github.inspektr.audit.support.Slf4jLoggingAuditTrailManager] - &lt;Audit trail record BEGIN&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;WHO: audit:unknownWHAT: ST-71-4uniggzr4MdFDUr3R936-cas01.example.orgACTION: SERVICE_TICKET_VALIDATEDAPPLICATION: CASWHEN: Thu Nov 05 18:58:15 CST 2020CLIENT IP ADDRESS: 127.0.0.1SERVER IP ADDRESS: 127.0.0.1&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; 但拿到的casAssertion却无法获取到登录名，调试结果如下： 在一番分析后，定位到AbstractUrlBasedTicketValidator#validate方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public Assertion validate(String ticket, String service) throws TicketValidationException &#123; //这里请求的地址为：http://localhost:18080/cas/validate?ticket=ST-74-ApfoBG1Eed6P4guj3Cb3-cas01.example.org&amp;service=http://localhost:8080/CallBillAnalysis/cas String validationUrl = this.constructValidationUrl(ticket, service); if (this.log.isDebugEnabled()) &#123; this.log.debug(\"Constructing validation url: \" + validationUrl); &#125; try &#123; this.log.debug(\"Retrieving response from server.\"); //这里返回response为：\"yes\\nadmin\\n\" String serverResponse = this.retrieveResponseFromServer(new URL(validationUrl), ticket); if (serverResponse == null) &#123; throw new TicketValidationException(\"The CAS server returned no response.\"); &#125; else &#123; if (this.log.isDebugEnabled()) &#123; this.log.debug(\"Server response: \" + serverResponse); &#125; return this.parseResponseFromServer(serverResponse); &#125; &#125; catch (MalformedURLException var5) &#123; throw new TicketValidationException(var5); &#125; &#125; //TuscTicketValidator#parseResponseFromServer protected Assertion parseResponseFromServer(final String response) throws TicketValidationException &#123; if (!response.startsWith(\"yes\")) &#123; throw new TicketValidationException(\"sso Server could not validate ticket.\"); &#125; try &#123; final BufferedReader reader = new BufferedReader(new StringReader(response)); reader.readLine(); String name = \"\"; String line = \"\"; Map userMap = new HashMap(); //虽然response中包含用户名 但在这里Assertion装载的时候 显然并没有\"=\",导致name=null while ((line = reader.readLine()) != null) &#123; int equalPositon = line.indexOf(\"=\"); if (equalPositon != -1) &#123; String key = line.substring(0, equalPositon); String value = line.substring(equalPositon + 1, line.length()); if (!CommonUtils.isBlank(value)) value = URLDecoder.decode(value, \"UTF-8\"); if (key.equals(\"name\")) &#123; name = value; &#125; userMap.put(key, value); &#125; &#125; Assertion assertion = new AssertionImpl(new AttributePrincipalImpl(name, userMap)); return assertion; &#125; catch (final IOException e) &#123; throw new TicketValidationException(\"Unable to parse response.\", e); &#125;&#125; 但之前验证的demo中是可以获取到用户名的，所以把之前验证的流程又跑了一遍，debug到同处的代码,发现如下的结果 1234567891011validationUrl &#x3D; http:&#x2F;&#x2F;localhost:18080&#x2F;cas&#x2F;serviceValidate?ticket&#x3D;ST-77-H20CVLaec7ndH20J5tIv-cas01.example.org&amp;service&#x3D;http:&#x2F;&#x2F;localhost:8080&#x2F;CallBillAnalysis&#x2F;CallBillAnalysis&#x2F;serverResponse &#x3D; &lt;cas:serviceResponse xmlns:cas&#x3D;&#39;http:&#x2F;&#x2F;www.yale.edu&#x2F;tp&#x2F;cas&#39;&gt; &lt;cas:authenticationSuccess&gt; &lt;cas:user&gt;admin&lt;&#x2F;cas:user&gt; &lt;&#x2F;cas:authenticationSuccess&gt;&lt;&#x2F;cas:serviceResponse&gt; 通过postman调用两种不同的validationUrl，发现后者即以http://localhost:18080/cas/serviceValidate请求的票据验证才会返回这种xml形式的结果。 以此可以定位到两者构造的TicketValidator类不相同，在UIMRealm#doGetAuthenticationInfo方法中 12345678910111213141516171819//方法构造TicketValidatorTicketValidator ticketValidator = ensureTicketValidator();//原生方法 最终会创建Cas20ServiceTicketValidator类对象protected TicketValidator createTicketValidator() &#123; String urlPrefix = this.getCasServerUrlPrefix(); return (TicketValidator)(\"saml\".equalsIgnoreCase(this.getValidationProtocol()) ? new Saml11TicketValidator(urlPrefix) : new Cas20ServiceTicketValidator(urlPrefix));&#125;Cas20ServiceTicketValidator#getUrlSuffix() -&gt; return \"serviceValidate\"//平台改造重写了createTicketValidator()方法@Overrideprotected TicketValidator createTicketValidator() &#123; String urlPrefix = getCasServerUrlPrefix(); return new TuscTicketValidator(urlPrefix);&#125;TuscTicketValidator#getUrlSuffix() -&gt; return \"validate\" 最后将此实例构造类替换为Cas20ServiceTicketValidator，这样就能够正确解析到用户名了。 12345protected TicketValidator createTicketValidator() &#123; String urlPrefix = getCasServerUrlPrefix(); return new Cas20ServiceTicketValidator(urlPrefix); //return new TuscTicketValidator(urlPrefix);&#125; LAST BUT NOT LEAST通过获取到的用户名，查询数据库内人员组织信息，放入shiro中作权限管理 （no longer show it）","categories":[{"name":"sso","slug":"sso","permalink":"https://sillybilly-share.top/categories/sso/"},{"name":"cas","slug":"cas","permalink":"https://sillybilly-share.top/categories/cas/"}],"tags":[{"name":"sso","slug":"sso","permalink":"https://sillybilly-share.top/tags/sso/"}]},{"title":"记一次内存溢出的解决方案","slug":"记一次内存溢出的解决方案","date":"2020-07-15T11:39:44.000Z","updated":"2022-11-24T01:35:09.631Z","comments":true,"path":"记一次内存溢出的解决方案.html","link":"","permalink":"https://sillybilly-share.top/%E8%AE%B0%E4%B8%80%E6%AC%A1%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.html","excerpt":"前提在前文netty ButeBuf使用中可以了解到JVM主要由堆、方法区、虚拟机栈、本地方法栈、程序计数器组成。由于在最近的项目中遇到了堆/堆外内存溢出(Java heap space/Direct buffer memory),所以这里结合自身对JVM的了解，讲述如果遇到内存溢出情况，我们应该如何解决。再次引入jvm内存结构图","text":"前提在前文netty ButeBuf使用中可以了解到JVM主要由堆、方法区、虚拟机栈、本地方法栈、程序计数器组成。由于在最近的项目中遇到了堆/堆外内存溢出(Java heap space/Direct buffer memory),所以这里结合自身对JVM的了解，讲述如果遇到内存溢出情况，我们应该如何解决。再次引入jvm内存结构图 JVM类加载编译的过程不多做解释，我们都知道JVM的编译过程是将我们程序员编写的.java文件通过javac命令编译为与平台无关的.class文件(与平台无关的字节码),然后通过JVM的java命令解释执行。 JVM的类加载过程，是将编译完成后的.class文件加载到内存，并且经过一系列的数据校验、解析、初始化，最终形成JVM可以直接使用的java类型的过程。 二进制的.class文件字节码加载到内存，并将这些静态数据转换为方法区中的运行时数据结构，然后在堆中生成一个代表这个类的java.lang.Class对象，作为方法区数据的访问入口，这也时JVM反射java.lang.reflect得以实现的根本原因。 验证，确保加载的类信息符合JVM规范，并且没有安全方面的问题。 准备，在方法区正式为被static修饰的类变量分配内存并设置内变量初始值,通常是0值。 解析，虚拟机常量池内的符号引用替换为直接引用的过程。 初始化，初始化是执行类构造器()方法的过程。 所以我们一般在程序中定义一个变量 A a;这时的a会被压入虚拟机栈，当我们去实例化A对象时 A a = new A(),就会在堆中开辟一个A对象的空间，栈中的a就是该对象的引用，假设A中存在A#getA()方法，那么当写到a.getA()时，JVM会从方法区中找到A的二进制数据并调用getA()方法。 内存溢出实例java heap spacejava heap space即堆内存溢出，大多数情况下是一次性加载过多的数据到内存中，导致Major GC时来不及释放所致的内存溢出。 在项目开发中，本人有幸遇到过两种场景出现过此类问题，还好在测试环境测修复了。 第一次遇到的是仿制logstash同步mysql数据到elasticsearch，需求的功能是和logstash一样，提供全量更新和增量更新两种实现方式（增量更新通过Spring quartz轮询updateTime or id），在全量更新时由于自己的疏忽，没有做切片,在开发环境的几百条数据没有问题，一到测试环境上万条数据全量查出来（包含mediumtext字段）上传到es，出现connection timeout还好处理，但瞬时的内存飙升，添加限制-Xmx1024m -Xms1024m，马上抛出OutOfMemory。即使同步功能是后台处理，不影响用户访问，这也是不可取的，所以需要按照实际的内存，设计切片大小，给每次同步的数据做切片，针对mysql数据库来说就是要分页查询，这样才能有效避免内存溢出。 第二次遇到的是大文件的下载，我们会用BufferedInputStream/BufferedOutputStream，一次性读写几kb而不是整个流全读取出来，这样避免大文件流一次性加载到内存，不仅前端浏览器一直处于阻塞状态影响用户体验，同样的如果内存分配不足也会造成内存溢出的情况。简单的代码实现可以是这样的： 12345678910111213141516@GetMapping(value = \"download\") public void download(HttpServletResponse response)&#123; response.addHeader(\"content-disposition\",\"attachment;filename=test.wmv\"); File file = new File(\"E:\\\\上【电影圈吧】.wmv\"); try(BufferedInputStream inputStream = new BufferedInputStream(new FileInputStream(file)); BufferedOutputStream outputStream = new BufferedOutputStream(response.getOutputStream())) &#123; int len = 0 ; byte[] bytes = new byte[1024]; while ((len = inputStream.read(bytes)) != -1)&#123; outputStream.write(bytes,0,len); outputStream.flush(); &#125; &#125;catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; 然而在实际开发中，我发现即使这样处理了，在上传大文件时浏览器仍然会一直处于阻塞状态，后端也会出现内存溢出。最后顺藤摸瓜发现平台在security模块，用ContentCachingResponseWrapper缓存了一份响应数据用作监测。。。，修改了部分逻辑后，终于就能够正常分片下载了。 Direct buffer memory描述Direct buffer memory即堆外内存溢出，类似于netty那种NIO在堆外申请一片内存，存储在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作，目前的堆外内存的回收是通过system.gc()来处理，依赖于gc机制。young GC时，如果这块内存的对象在堆内仍然被引用，导致一直未被回收，从而DirectByteBuffer对象进入年老代。下次young GC时，处于年老代的对象没有被释放，引用所指向的堆外内存就一直不被释放，就会导致堆外内存溢出。 实际场景在大文件上传时，都需要分片上传。前端将分片后的文件以异步的ajax传给后端服务器，考虑到并发情况，如果同一时间上传的人过多服务器就会出现堆外内存溢出的情况。 解决方案 JVM调优 增大堆外内存参数（-XX：MaxDirectMemorySize） 增大JVM内存(-Xms，-Xmm)，因为JVM堆内存增大，年轻代Eden区(也可以通过-Xmn设置占比)随着的增大，可以保证young GC次数减少,Eden区ByteBuf对象可以在足够的时间内处理完等待释放，而不用转到Old区。 代码调优(时间换空间) 将前端传输异步改成同步，如果当前上传人数并不多并且服务器资源足够，这样极易影响用户上传体验，不推荐 采用信号量机制（Semaphore）,根据内存大小设定同一时间可访问接口的线程数，类似于做一个熔断阻塞的操作 最后最近开始迷惘，经常涉猎多个中间件却只是站在巨人的肩旁上看世界，自己并没有一次深入研究，脱离了封装好的API，甚至有些轮子都造不出。学习的方式是选择”广度优先”还是”深度优先”，我一直没有找到合适的切入点，希望尽快脱离这种状态吧 current time:2020.7.15 20:00:01","categories":[{"name":"java","slug":"java","permalink":"https://sillybilly-share.top/categories/java/"},{"name":"jvm调优","slug":"jvm调优","permalink":"https://sillybilly-share.top/categories/jvm%E8%B0%83%E4%BC%98/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://sillybilly-share.top/tags/jvm/"},{"name":"DirectByteBuffer","slug":"DirectByteBuffer","permalink":"https://sillybilly-share.top/tags/DirectByteBuffer/"},{"name":"heap","slug":"heap","permalink":"https://sillybilly-share.top/tags/heap/"}]},{"title":"JSR310日期类api解析","slug":"JSR310日期类api解析","date":"2020-06-30T02:06:48.000Z","updated":"2022-11-24T01:35:09.626Z","comments":true,"path":"JSR310日期类api解析.html","link":"","permalink":"https://sillybilly-share.top/JSR310%E6%97%A5%E6%9C%9F%E7%B1%BBapi%E8%A7%A3%E6%9E%90.html","excerpt":"前提之前在项目中零零散散的用到过java8新推的JSR310的日期规范，主要是rt.jar下的java.time的使用，因为实在是太好用了，所以本人誓要抽空系统的整理一遍。 时区的理解1863年，国际上首次出现时区的概念。时区通过设立一个区域的标准时间部分地解决了这个问题。世界各国位于地球不同位置上，因此不同国家，特别是东西跨度大的国家日出、日落时间必定有所偏差，这些偏差就是所谓的时差。 全球分为24个时区，东西各12个时区（中国位于东八区即北京时间）。 如果时间是以协调世界时UTC表示，则在时间后面直接加上一个“Z”（不加空格）。“Z”是协调世界时中0时区的标志。因此，“09:30 UTC”就写作“09:30Z”或是“0930Z”。“14:45:15 UTC”则为“14:45:15Z”或“144515Z”。UTC时间也被叫做祖鲁时间，因为在北约音标字母中用“Zulu”表示“Z”。 同样的，格林尼治标准时间GMT的正午是指当平太阳横穿格林尼治子午线时（也就是在格林尼治上空最高点时）的时间。 GMT+8或者UTC+8均可视为中国时间，不过推荐用UTC+8因为地球每天的自转是有些不规则的，而且正在缓慢减速，因此格林尼治平时基于天文观测本身的缺陷，已经被原子钟报时的协调世界时（UTC）所取代。","text":"前提之前在项目中零零散散的用到过java8新推的JSR310的日期规范，主要是rt.jar下的java.time的使用，因为实在是太好用了，所以本人誓要抽空系统的整理一遍。 时区的理解1863年，国际上首次出现时区的概念。时区通过设立一个区域的标准时间部分地解决了这个问题。世界各国位于地球不同位置上，因此不同国家，特别是东西跨度大的国家日出、日落时间必定有所偏差，这些偏差就是所谓的时差。 全球分为24个时区，东西各12个时区（中国位于东八区即北京时间）。 如果时间是以协调世界时UTC表示，则在时间后面直接加上一个“Z”（不加空格）。“Z”是协调世界时中0时区的标志。因此，“09:30 UTC”就写作“09:30Z”或是“0930Z”。“14:45:15 UTC”则为“14:45:15Z”或“144515Z”。UTC时间也被叫做祖鲁时间，因为在北约音标字母中用“Zulu”表示“Z”。 同样的，格林尼治标准时间GMT的正午是指当平太阳横穿格林尼治子午线时（也就是在格林尼治上空最高点时）的时间。 GMT+8或者UTC+8均可视为中国时间，不过推荐用UTC+8因为地球每天的自转是有些不规则的，而且正在缓慢减速，因此格林尼治平时基于天文观测本身的缺陷，已经被原子钟报时的协调世界时（UTC）所取代。 有很多用缩写字母表示的时区，例如“EST、WST、CST”等。但是它们并不是ISO 8601标准的一部分，不应单独用它们作为时区的标识,其中 CST (China Standard Time）即中国标准时间，CST = UCT+8/GMT+8 jdk时区的使用时区ID，例如Europe/Paris、Asia/Shanghia。ZoneId用于标识用于在Instant和之间转换的规则LocalDateTime。有两种不同的ID类型： 固定偏移量-与UTC /格林威治标准时间完全抵消的偏移量，所有本地日期时间都使用相同的偏移量 地理区域-适用于从UTC /格林威治中查找偏移量的一组特定规则的区域 大多数固定偏移量由ZoneOffset表示，它是以UTC/GMT为基准的偏移时间量，它有两种类型的表达方式 固定偏移量-ZoneOffset它可以由“ Z”和以“ +”或“-”开头的ID组成 123456Z（即表示UTC&#x2F;GMT）+h&#x2F;-h (在UTC基础上偏移几个小时，比如中国位于东八区则表示为+8)+hh&#x2F;-hh +hh:mm&#x2F;-hh:mm+hh:mm:ss&#x2F;-hh:mm:ss+hhmmss&#x2F;-hhmmss 以jdk中ZoneOffset#of(String zoneId)举几个例子: 123456//协调世界时ZoneOffset zoneOffset = ZoneOffset.of(\"Z\");//东八区zoneOffset = ZoneOffset.of(\"+08:00\");//西八区zoneOffset = ZoneOffset.of(\"-8\"); 当然也可以用静态方法ZoneId#of(String zoneId)，它会逐步解析入参规则，匹配固定偏移量或者地理区域 123456789101112static ZoneId of(String var0, boolean var1) &#123; Objects.requireNonNull(var0, \"zoneId\"); if (var0.length() &gt; 1 &amp;&amp; !var0.startsWith(\"+\") &amp;&amp; !var0.startsWith(\"-\")) &#123; if (!var0.startsWith(\"UTC\") &amp;&amp; !var0.startsWith(\"GMT\")) &#123; return (ZoneId)(var0.startsWith(\"UT\") ? ofWithPrefix(var0, 2, var1) : ZoneRegion.ofId(var0, var1)); &#125; else &#123; return ofWithPrefix(var0, 3, var1); &#125; &#125; else &#123; return ZoneOffset.of(var0); &#125; &#125; 地理区域-ZoneRegion地址区域表示类java.time.ZoneRegion,不过其ZoneRegion#ofId是default修饰，所以我们只能通过ZoneId#of方法去设置地理区域，常用格式为：洲(州、国家)/城市. 12ZoneId zoneId = ZoneId.systemDefault();System.out.println(zoneId); 本人在上海，所以这里会打印出来Asia/Shanghai JSR310常用Api在说JSR310的新特性之前不得不吐槽jdk8之前日期类非人类的设计，比如 12Date date = new Date(2020,7,1);System.out.println(date); 这里打印出来的是：Sun Aug 01 00:00:00 CST 3920,我这里year还得减去1900…同样的定义的7月份输出却是8月份(Aug)，可读性极差。所以我们不得不去Calendar类去表示 12Calendar calendar = Calendar.getInstance();calendar.set(2020, Calendar.JULY, 1); 我们不必去考虑年份减去1900,然而Calendar.JULY代表着7月，数字却是6… 123456789101112public static final int JANUARY = 0;public static final int FEBRUARY = 1;public static final int MARCH = 2;public static final int APRIL = 3;public static final int MAY = 4;public static final int JUNE = 5;public static final int JULY = 6;public static final int AUGUST = 7;public static final int SEPTEMBER = 8;public static final int OCTOBER = 9;public static final int NOVEMBER = 10;public static final int DECEMBER = 11; 这种令人无语的设计，让我代码写着都膈应。当然最重要的是，JSR310之前的设计很多类的属性都是可变的，而新增的日期时间类都是不可变类，每次通过其方法更变或者修改都是返回一个全新的对象，因此它们都是线程安全的。 Clockclock即时钟，用于使用时区访问当前时刻，日期和时间。此类的实例用于查找当前时刻,可以使用存储的时区来解释当前时刻以查找当前日期和时间。因此,可以使用时钟代替System.currentTimeMillis() 和TimeZone.getDefault()。java.time.Clock提供以下的实例方法 12345678//获取用于创建日期和时间的时区public abstract ZoneId getZone()//获取时钟的当前时刻public abstract Instant instant()//获取时钟的当前毫秒瞬间public long millis()//返回带有不同时区的此时钟的副本public abstract Clock withZone(ZoneId zoneId); clock包含了四个实现类FixedClock、OffsetClock、SystemClock、TickClock,下面的静态方法都源于这四个实现。 12345678910111213141516//获得始终返回相同时刻的时钟static Clock fixed(Instant fixedInstant, ZoneId zone)//获取一个时钟，该时钟从基础时钟返回瞬时值，并添加指定的时间偏移量static Clock offset(Clock baseClock, Duration offsetDuration)//获得指定时区的时钟static Clock system(ZoneId zone)//获取当前时刻的时钟，并使用默认时区将其转换为日期和时间static Clock systemDefaultZone()//获取当前时刻的时钟，并使用UTC时区转换为日期和时间static Clock systemUTC()//获取一个时钟，该时钟返回从指定时钟被截断到指定持续时间的最接近值的瞬间static Clock tick(Clock baseClock, Duration tickDuration)//获得一个时钟，该时钟使用指定时区并返回整分钟的当前时刻的时钟static Clock tickMinutes(ZoneId zone)//获取一个时钟，该时钟使用指定时区并返回整秒内的当前时刻的时钟static Clock tickSeconds(ZoneId zone) 看上去tickMinutes/tickSeconds的api注释比较拗口 其实tickSeconds计量到秒，tickMinutes计量到分（秒部分会置为0） Instant、LocalDate、LocalTime、LocalDateTime Instant: 瞬时时间，等价于以前的System.currentTimeMillis()。 LocalDate: ISO-8601日历系统中没有时区的日期，例如2020-07-01,只代表年-月-日 LocalTime: ISO-8601日历系统中没有时区的时间，例如20:00:00，只代表时-分-秒 LocalDateTime: ISO-8601日历系统中没有时区的日期时间，例如2020-07-01T20:00:00，通常被视为年-月-日-时-分-秒 我们经常需要将Date类型转化为JSR310中的日期类计算 1234567891011public static LocalDate getLocalDate(Date date) &#123; return Instant.ofEpochMilli(date.getTime()).atZone(ZoneId.of(\"+8\")).toLocalDate();&#125;public static LocalTime getLocalTime(Date date) &#123; return Instant.ofEpochMilli(date.getTime()).atZone(ZoneId.of(\"+8\")).toLocalTime();&#125;public static LocalDateTime getLocalDateTime(Date date) &#123; return Instant.ofEpochMilli(date.getTime()).atZone(ZoneId.of(\"+8\")).toLocalDateTime();&#125; 我们可以利用JSR310新增的类用来比较两个日期是否处于同一天 12345public static boolean compareTo(Date date1,Date date2) &#123; LocalDate time1 = getLocalDate(date1); LocalDate time2 = getLocalDate(date2); return time2.getYear() == time1.getYear() &amp;&amp; time2.getMonth().compareTo(time1.getMonth()) == 0 &amp;&amp; time2.getDayOfMonth() == time1.getDayOfMonth();&#125; 我们也可以处理String转Date、Date转String的格式处理 12345678910public static Date getDate(String date)&#123; DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\"EEE MMM dd HH:mm:ss zzz yyyy\",Locale.CHINA); LocalDateTime time = LocalDateTime.parse(date,formatter); return Date.from(time.atZone(ZoneId.systemDefault()).toInstant());&#125;public static String getString(Date date)&#123; LocalDateTime time = LocalDateTime.ofInstant(date.toInstant,ZoneId.systemDefault()); return DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\").format(time);&#125; 等等…参照jkd8 api文档，这里就不一一列举了。 OffsetTime、OffsetDateTime、ZonedDateTime OffsetTime: ISO-8601日历系统中的UTC/GMT带偏移量的时间，例如20:00:00+08:00 OffsetDateTime: ISO-8601日历系统中的UTC/GMT带偏移量的时间，例如2020-07-01T20:00:00+08:00 (不支持ZoneRegion的时区格式) ZonedDateTime: ISO-8601日历系统中带有时区的日期时间，例如2020-07-01T20:00:00+08:00 Europe/Paris (支持ZoneRegion的时区格式) OffsetTime可以类比LocalTime,OffsetDateTime/ZonedDateTime可以类比LocalDateTime，相比之下，他们多存储了一个时区时间偏移量(zone offset)属性，其余的api方法相差不大。 Durationduration是一个基于时间的时间量，例如’34.5 seconds’，它用来表示两个瞬时时间的时间段。 举个最基本的例子 123456789101112131415//1天时差 类似的还有如ofHours() Duration d2 = Duration.ofDays(1); System.out.println(d2.toDays()); console print: 1//比较两个日期的时间差long now = System.currentTimeMillis();Instant instant1 = Instant.ofEpochMilli(now-1);Instant instant2 = Instant.ofEpochMilli(now);Duration duration = Duration.between(instant1,instant2);System.out.println(duration.toMillis());console print: 1 Year、YearMonth、MonthDay、Period Year: 基于ISO-8601日期系统下表示年份，例如2020 YearMonth: ISO-8601日历系统中的一年月，例如2020-07 MonthDay: ISO-8601日历系统中的一个月日，例如–07-01 Period: ISO-8601日历系统中基于日期的时间量，例如”2年，3个月和4天” 这里主要针对Period即周期做个简单的例子 1234567891011//表示前1天Period period1 = Period.ofDays(1); System.out.println(period1);console print: P1D//2年5个月前 Period period2 = Period.of(2, 5, 0); System.out.println(period2);console print: P2Y5M ChronologyChronology:主日期和时间API建立在ISO日历系统上,年表在后台进行操作，以表示日历系统的一般概念。主要用于对年历系统的支持，是java.util.Calendar的替代者。使用方法： 12345Chronology c = HijrahChronology.INSTANCE; ChronoLocalDateTime d = c.localDateTime(LocalDateTime.now()); System.out.println(d);console.print: Hijrah-umalqura AH 1441-11-10T18:10:35.528 Spring对JSR310的支持Spring Framework 4.0提供了对java.time（JSR-310）的相关类的支持 在springboot工程为背景，我们定义一个实体类如下 123456789101112@Datapublic class Time &#123; @DateTimeFat(pattern = \"yyyy-MM-dd HH:mm:ss\") private LocalDateTime localDateTime; @DateTimeFormat(pattern = \"yyyy-MM-dd\") private LocalDate localDate; @DateTimeFormat(pattern = \"HH:mm:ss\") private LocalTime localTime;&#125; 编写web层demo,调用localhost:8080/test?localDateTime=2020-07-02 20:00:00&localDate=2020-07-02&localTime=20:00:00，spring会自动进行类型转化。 12345@GetMapping(value = \"/test\")@ResponseBodypublic Time getTime(Time time)&#123; return time;&#125; postMan测试: 或者我们可以使用Spring默认使用Jackson作为json的序列化工具，例如： 123456789101112131415@Datapublic class Time &#123; @JsonDeserialize(using = LocalDateTimeDeserializer.class) @JsonSerialize(using = LocalDateTimeSerializer.class) private LocalDateTime localDateTime; @JsonDeserialize(using = LocalDateDeserializer.class) @JsonSerialize(using = LocalDateSerializer.class) private LocalDate localDate; @JsonDeserialize(using = LocalTimeDeserializer.class) @JsonSerialize(using = LocalTimeSerializer.class) private LocalTime localTime;&#125; 补充说明: 对于常用的ORM框架，新版的mybatis也已经内置了mybatis-typehandlers-jsr310的依赖，所以对于数据库的增删改查也可以无感使用JSR310日期类开发啦！ 参考 oracle java.time api 维基百科-时区的定义","categories":[{"name":"java","slug":"java","permalink":"https://sillybilly-share.top/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://sillybilly-share.top/tags/java/"},{"name":"date","slug":"date","permalink":"https://sillybilly-share.top/tags/date/"}]},{"title":"聊一聊分布式锁的不同实现","slug":"聊一聊分布式锁的不同实现","date":"2020-06-15T07:10:10.000Z","updated":"2022-11-24T01:35:09.630Z","comments":true,"path":"聊一聊分布式锁的不同实现.html","link":"","permalink":"https://sillybilly-share.top/%E8%81%8A%E4%B8%80%E8%81%8A%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E4%B8%8D%E5%90%8C%E5%AE%9E%E7%8E%B0.html","excerpt":"前提在平时遇到资源抢占的问题时，我们经常使用synchronized加锁的方式去实现资源同步，简单粗暴，并且在对性能要求不高的业务中实现起来屡试不爽。然而就目前而言，大部分的线上项目，为了避免单点故障，都实现了双击部署（or more），因此一些业务单靠线程加锁的实现方式是不完全可行的。所以，本文主要讲述自身在过去项目中使用的一些分布锁的使用与个人理解。 mysql实现基于mysql的乐观锁乐观锁乐观锁假设认为数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则返回给用户错误的信息。 设计思路mysql中基于version版本号实现，服务A、B同时查询数据库对应的lock_verion信息，在更新时将version=oldversion+1,并将oldversion作为条件更新记录。若最终影响行数不为0则更新成功，否则更新失败。","text":"前提在平时遇到资源抢占的问题时，我们经常使用synchronized加锁的方式去实现资源同步，简单粗暴，并且在对性能要求不高的业务中实现起来屡试不爽。然而就目前而言，大部分的线上项目，为了避免单点故障，都实现了双击部署（or more），因此一些业务单靠线程加锁的实现方式是不完全可行的。所以，本文主要讲述自身在过去项目中使用的一些分布锁的使用与个人理解。 mysql实现基于mysql的乐观锁乐观锁乐观锁假设认为数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则返回给用户错误的信息。 设计思路mysql中基于version版本号实现，服务A、B同时查询数据库对应的lock_verion信息，在更新时将version=oldversion+1,并将oldversion作为条件更新记录。若最终影响行数不为0则更新成功，否则更新失败。 图解 代码实现尽量不参杂任务业务逻辑，我们在数据库新建一张表 1234567891011121314151617181920212223SET NAMES utf8mb4;SET FOREIGN_KEY_CHECKS &#x3D; 0;-- ------------------------------ Table structure for optimistic_lock-- ----------------------------DROP TABLE IF EXISTS &#96;optimistic_lock&#96;;CREATE TABLE &#96;optimistic_lock&#96; ( &#96;id&#96; int(11) NOT NULL AUTO_INCREMENT COMMENT &#39;id&#39;, &#96;lock_name&#96; varchar(50) CHARACTER SET utf8 COLLATE utf8_bin NULL DEFAULT NULL COMMENT &#39;乐观锁名称&#39;, &#96;version&#96; int(255) NULL DEFAULT 0 COMMENT &#39;版本&#39;, &#96;is_delete&#96; tinyint(2) NULL DEFAULT 0 COMMENT &#39;是否删除&#39;, &#96;update_time&#96; datetime(0) NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP(0) COMMENT &#39;更新时间&#39;, &#96;create_time&#96; datetime(0) NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;, PRIMARY KEY (&#96;id&#96;) USING BTREE) ENGINE &#x3D; InnoDB AUTO_INCREMENT &#x3D; 2 CHARACTER SET &#x3D; utf8 COLLATE &#x3D; utf8_bin ROW_FORMAT &#x3D; Dynamic;-- ------------------------------ Records of optimistic_lock-- ----------------------------INSERT INTO &#96;optimistic_lock&#96; VALUES (1, &#39;try_lock&#39;, 15, 0, &#39;2020-06-15 14:22:18&#39;, &#39;2020-06-15 14:22:18&#39;);SET FOREIGN_KEY_CHECKS &#x3D; 1; 新建一个springBoot工程,添加mysql驱动和mybatis-plus jar 12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.3.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus&lt;/artifactId&gt; &lt;version&gt;3.3.2&lt;/version&gt;&lt;/dependency&gt; 添加yml配置信息 1234567891011121314151617181920212223spring: # MySQL datasource: url: jdbc:mysql://localhost:3306/test?useUnicode=true&amp;characterEncoding=utf-8&amp;serverTimezone=GMT%2B8 username: root password: 123456 driver-class-name: com.mysql.cj.jdbc.Driver druid: initial-size: 5 max-active: 20 mybatis: mapper-locations: - \"classpath:/mapper/*Mapper.xml\" - \"classpath:/mapper/**/*Dao.xml\" type-aliases-package: com.sillybilly.test.lock.domain configuration: jdbc-type-for-null: 'null' map-underscore-to-camel-case: true cache-enabled: true ds-name: $&#123;DS_NAME:dataSource&#125; ds-type: $&#123;DS_TYPE:MySQL&#125; 然后通过代码生成器生成实体类和持久层/mapper.xml文件，然后开始编写service代码： 123456789101112131415161718192021222324252627282930313233343536@Slf4j@Servicepublic class MysqlLockImpl extends ServiceImpl&lt;OptimisticLockDao, OptimisticLock&gt; implements MysqlLock &#123; @Autowired private OptimisticLockDao optimisticLockDao; @Override public boolean getLock(String lockName) &#123; //定义条件构造器 QueryWrapper&lt;OptimisticLock&gt; wrapper = new QueryWrapper&lt;&gt;(); wrapper.eq(\"lock_name\",lockName) .eq(\"is_delete\",0); OptimisticLock lock = optimisticLockDao.selectOne(wrapper); if (null == lock)&#123; //当然为了简单，这里是事先定义好的lockName throw new RuntimeException(\"未创建锁记录\"); //lock=null 同样可以自行创建该lockName的锁记录 &#125; int version = lock.getVersion(); lock.setVersion(version+1); try &#123; Thread.sleep(5000); wrapper.eq(\"id\",lock.getId()) .eq(\"version\",version); int num = optimisticLockDao.update(lock,wrapper); if (num != 0)&#123; return true; &#125; return false; &#125; catch (InterruptedException e) &#123; log.warn(\"thread interruped\",e); return true; &#125; &#125;&#125; 线程睡眠5秒钟，防止线程执行的优先级问题，导致服务AB会有一定的时间差获取锁，让乐观锁失效。方便测试，我们新建一个定时任务执行获取锁的方法 123456789101112131415161718192021@Service@Slf4jpublic class cron &#123; @Autowired private MysqlLock mysqlLock; /** * 每分钟的第0，10，20，30，40，50秒执行 */ @Scheduled(cron = \"0,10,20,30,40,50 * * * * ? \") public void startCron()&#123; String lockName = \"try_lock\"; boolean isLock = mysqlLock.getLock(lockName); if (isLock)&#123; log.info(\"hello world &amp; こんにちは世界\"); &#125; else &#123; log.warn(\"乐观锁加锁失败！lock_name:[&#123;&#125;]\",lockName); &#125; &#125;&#125; 我们开启多个副本，来测试一下效果吧！ 副本A：副本B： 显然从结果中可以看出，每隔10s，有且只有一个副本抢占到乐观锁并执行定时任务，轻松解决分布式环境下的资源抢占问题。 基于mysql的悲观锁悲观锁&emsp;总是假设最坏的情况，每次取数据时都认为其他线程会修改，所以都会加（悲观）锁。一旦加锁，不同线程同时执行时,只能有一个线程执行，其他的线程在入口处等待，直到锁被释放。&emsp;有很多基于悲观锁的广泛应用，比如:synchronized、基于数据库的spring quartz（行锁）等等。 悲观锁实现前提，数据库为InnoDB。所谓的读写锁、行锁、排他锁等都是悲观锁，我们需要关闭mysql数据库的自动提交属性，通过事务控制select (…) for update语句对锁住某条记录，在业务执行完成后commit释放掉锁，在此中间有其他业务查询时，会进入等待状态。俺就不造轮子了，具体参照spring quartz实现（通过triggers表时间戳，乐观锁和悲观锁的结合实现多副本下只执行一次定时任务） 小结123456优势：1、该实现的好处是基于数据库的项目，实现分布式锁可以不用再引入第三方插件，减少jar包依赖的同时也减轻了开发人员学习的负担2、基于乐观锁的实现并不用考虑什么时候释放锁，也完全不用担心死锁的情况劣势：1、由于乐观锁总是在更新时才会校验冲突，需要经常访问数据库，对数据库的压力很大2、目前平台都会依赖redis(除却老旧的系统)，那么用redis这种成熟的分布式锁方案替代数据库会更加合理 redis实现基于jedis的分布式锁从redis 2.6.12开始，set命令提供了可选的复合操作。 1SET key value [expiration EX seconds|PX milliseconds] [NX|XX] 参数解释： 1234EX：设置超时时间，单位是秒。PX：设置超时时间，单位是毫秒。NX：IF NOT EXIST的缩写，只有KEY不存在的前提下才会设置值。XX：IF EXIST的缩写，只有在KEY存在的前提下才会设置值。 这样合并的原子操作，让jedis实现分布式锁变得非常简单。尽管这种分布锁的方案存在很多问题，并且有很多文章剖析描述它的不足与隐患之处，但目前看来已经有很多项目把它应用在了实际的生产环境当中。 代码设计添加jedis的jar包: 1234&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt;&lt;/dependency&gt; 编写简易的java类实现setnx操作： 1234567891011121314151617181920212223242526272829303132333435363738@Slf4j@Servicepublic class JedisCron &#123; private static JedisPool jedisPool = null; static&#123; JedisPoolConfig jpc = new JedisPoolConfig(); jpc.setMaxTotal(100); jedisPool = new JedisPool(jpc,\"127.0.0.1\",6379,5000); &#125; public Jedis getJedis()&#123; return jedisPool.getResource(); &#125; @Scheduled(cron = \"0,10,20,30,40,50 * * * * ? \") public void scheduledMethod()&#123; String lockKey = \"jedis:lock:key\"; boolean lock = false; @Cleanup Jedis jedis = null; try &#123; jedis = getJedis(); SetParams params = new SetParams().ex(300).nx(); String code = jedis.set(lockKey, \"1\", params); // 加锁成功 if (\"OK\".equals(code))&#123; lock = true; // 这里做调度正常业务逻辑 log.info(\"start business\"); &#125; &#125;finally&#123; if (lock)&#123; jedis.del(lockKey); &#125; &#125; &#125;&#125; 事实上我们也确实不用考虑最终的删除操作是否成功，我们可以在finally加一层判断，以防止多余的delete操作。 小结通过jedis调用redis的setnx特性完成分布式锁的设计比较简单直观，当然我们也可以结合spring+jedis来设计，不过目前spring推崇使用lettuce作为默认redis的java客户端（下面会讲述spring集成lettuce+lua脚本实现分布式锁），如果项目中用的jedis,那么还是直接用jedis反而会更便捷一点，spring-data-redis那套反而不太友好。 以上jedis的实现还会存在一些问题 12341、倘若某个操作设置redis锁的超时时间很长，而finally模块因为一些不可抗力导致没有执行（比如执行到finally块之前突然断电，虽然几率相当于坠机概率），那么这个锁就在内存里长时间持有之后哪怕来电重启了服务，持有该锁才能执行的业务逻辑也会陷入长时间的瘫痪2、锁的持有和释放并非由一个操作这决定，A持有锁，同样的B可以恶意去释放该锁，这样显然时不安全的 基于lettuce分布式锁目前大部分项目redis的java客户端都默认使用spring+lettuce的方式，对比jedis，lettuce的文档更加齐全，社区也更加活跃，是替代jedis的不二之选。lettuce github:https://github.com/lettuce-io/lettuce-corelettuce wiki:https://github.com/lettuce-io/lettuce-core/wikilettuce包含同步、异步和响应式的连接方式，在参考jedis和lettuce的pipLine机制的的时候，发现lettuce似乎并没有看到相关API，它通过netty NIO框架有效管理多个连接并实现了底层pipLine机制，这对于我们开发者而言是屏蔽的。另外spring RedisTemplate#executePipelined()有点假，实现速率上远不如jedis的pipline机制。这里就不细说了，有空深入了解一下lettuce的源码。 Spring+lettuce+lualua接口lettuce中的lua接口： 1234567891011121314151617181920public interface RedisScriptingCommands &#123; void scriptFlush(); void scriptKill(); @Nullable String scriptLoad(byte[] var1); @Nullable List&lt;Boolean&gt; scriptExists(String... var1); @Nullable &lt;T&gt; T eval(byte[] var1, ReturnType var2, int var3, byte[]... var4); @Nullable &lt;T&gt; T evalSha(String var1, ReturnType var2, int var3, byte[]... var4); @Nullable &lt;T&gt; T evalSha(byte[] var1, ReturnType var2, int var3, byte[]... var4);&#125; 这里我们使用eval对输入的脚本代码体（body）进行求值，我们可以定义一个静态代码块，for example: 12345678910static &#123; StringBuilder sb = new StringBuilder(); sb.append(\"if redis.call(\\\"get\\\",KEYS[1]) == ARGV[1] \"); sb.append(\"then \"); sb.append(\" return redis.call(\\\"del\\\",KEYS[1]) \"); sb.append(\"else \"); sb.append(\" return 0 \"); sb.append(\"end \"); UNLOCK_LUA = sb.toString(); &#125; 通过lua实现setnx的原子操作，向redis服务器发送请求。 序列化器可选的修改redis存储的序列化器（默认jdk的序列化方式）,我们可以考虑采用redisson的例子实现kryo序列化器：https://github.com/redisson/redisson/blob/master/redisson/src/main/java/org/redisson/codec/KryoCodec.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131public class KryoRedisSerializer&lt;T&gt; implements RedisSerializer&lt;T&gt; &#123; private final KryoPool kryoPool; public KryoRedisSerializer() &#123; this(Collections.&lt;Class&lt;?&gt;&gt;emptyList()); &#125; public KryoRedisSerializer(ClassLoader classLoader) &#123; this(Collections.&lt;Class&lt;?&gt;&gt;emptyList(), classLoader); &#125; public KryoRedisSerializer(ClassLoader classLoader, List&lt;Class&lt;?&gt;&gt; classes) &#123; this(classes, classLoader); &#125; public KryoRedisSerializer(List&lt;Class&lt;?&gt;&gt; classes) &#123; this(classes, null); &#125; public KryoRedisSerializer(List&lt;Class&lt;?&gt;&gt; classes, ClassLoader classLoader) &#123; this(new KryoPoolImpl(classes, classLoader)); &#125; public KryoRedisSerializer(KryoPool kryoPool) &#123; this.kryoPool = kryoPool; &#125; public interface KryoPool &#123; Kryo get(); void yield(Kryo kryo); ClassLoader getClassLoader(); List&lt;Class&lt;?&gt;&gt; getClasses(); &#125; public static class KryoPoolImpl implements KryoPool &#123; private final Queue&lt;Kryo&gt; objects = new ConcurrentLinkedQueue&lt;Kryo&gt;(); private final List&lt;Class&lt;?&gt;&gt; classes; private final ClassLoader classLoader; public KryoPoolImpl(List&lt;Class&lt;?&gt;&gt; classes, ClassLoader classLoader) &#123; this.classes = classes; this.classLoader = classLoader; &#125; @Override public Kryo get() &#123; Kryo kryo = objects.poll(); if (kryo == null) &#123; kryo = createInstance(); &#125; return kryo; &#125; @Override public void yield(Kryo kryo) &#123; objects.offer(kryo); &#125; /** * Sub classes can customize the Kryo instance by overriding this method * * @return create Kryo instance */ protected Kryo createInstance() &#123; Kryo kryo = new Kryo(); if (classLoader != null) &#123; kryo.setClassLoader(classLoader); &#125; kryo.setReferences(false); for (Class&lt;?&gt; clazz : classes) &#123; kryo.register(clazz); &#125; return kryo; &#125; @Override public List&lt;Class&lt;?&gt;&gt; getClasses() &#123; return classes; &#125; @Override public ClassLoader getClassLoader() &#123; return classLoader; &#125; &#125; @Override public byte[] serialize(T in) throws SerializationException &#123; // TODO Auto-generated method stub Kryo kryo = null; try &#123; ByteArrayOutputStream baos = new ByteArrayOutputStream(); Output output = new Output(baos); kryo = kryoPool.get(); kryo.writeClassAndObject(output, in); output.close(); return baos.toByteArray(); &#125; catch (Exception e) &#123; if (e instanceof RuntimeException) &#123; throw (RuntimeException) e; &#125; throw new SerializationException(\"对象序列化失败!\", e); &#125; finally &#123; if (kryo != null) &#123; kryoPool.yield(kryo); &#125; &#125; &#125; @Override public T deserialize(byte[] bytes) throws SerializationException &#123; // TODO Auto-generated method stub Kryo kryo = null; try &#123; kryo = kryoPool.get(); return (T) kryo.readClassAndObject(new Input(new ByteArrayInputStream(bytes))); &#125; catch (Exception e) &#123; if (e instanceof RuntimeException) &#123; throw (RuntimeException) e; &#125; throw new SerializationException(\"对象反序列化失败!\", e); &#125; finally &#123; if (kryo != null) &#123; kryoPool.yield(kryo); &#125; &#125; &#125;&#125; 定义redisConfig文件替换默认的jdk序列化机制 1234567891011121314151617181920212223242526@Configuration@EnableCaching//开启缓存public class RedisConfig &#123; // 自由根据场景选择 @Bean(value = \"redisTemplate\") public RedisTemplate&lt;Object, Object&gt; redisTemplate(RedisConnectionFactory connectionFactory) &#123; RedisTemplate&lt;Object, Object&gt; template = new RedisTemplate&lt;&gt;(); template.setConnectionFactory(connectionFactory); //（默认使用JDK的序列化方式） template.setValueSerializer(new KryoRedisSerializer&lt;&gt;()); //使用StringRedisSerializer来序列化和反序列化redis的key值 template.setKeySerializer(new StringRedisSerializer()); template.afterPropertiesSet(); return template; &#125; @Bean public StringRedisTemplate stringRedisTemplate(RedisConnectionFactory factory) &#123; StringRedisTemplate stringRedisTemplate = new StringRedisTemplate(); stringRedisTemplate.setConnectionFactory(factory); //启动redis事务 stringRedisTemplate.setEnableTransactionSupport(true); return stringRedisTemplate; &#125;&#125; 分布式锁设计123456789public boolean setRedis(String key,String identityId,final long expire) &#123; try &#123; RedisCallback&lt;Boolean&gt; callback = (connection) -&gt; connection.set(key.getBytes(Charset.forName(\"UTF-8\")), identityId.getBytes(Charset.forName(\"UTF-8\")), Expiration.milliseconds(expire), RedisStringCommands.SetOption.SET_IF_ABSENT); return redisTemplate.execute(callback); &#125; catch (Exception e) &#123; log.error(\"redis lock error.exception:\", e); &#125; return false; &#125; 通过调用lua脚本实现了set if not exist的事件，当然如果需要添加重试机制，我们可以完善上面的代码，如下： 1234567891011121314public boolean tryMutilock(String key, String identityId,long expire, int retryTimes, long sleepMillis) &#123; boolean result = setRedis(key,identityId,expire); // 如果获取锁失败，按照传入的重试次数进行重试 while ((!result) &amp;&amp; retryTimes-- &gt; 0) &#123; try &#123; log.debug(\"lock failed, retrying lock...，available retryTimes：&#123;&#125;\",retryTimes); Thread.sleep(sleepMillis); &#125; catch (InterruptedException e) &#123; return false; &#125; result = setRedis(key,identityId,expire); &#125; return result; &#125; 在业务执行完成后的finally块中执行释放锁的操作，具体方法如下： 12345678910public boolean releaseLock(String key,String identityId) &#123; // 释放锁的时候，有可能因为持锁之后方法执行时间大于锁的有效期，此时有可能已经被另外一个线程持有锁，所以不能直接删除 try &#123; RedisCallback&lt;Boolean&gt; callback = (connection) -&gt; connection.eval(UNLOCK_LUA.getBytes(), ReturnType.BOOLEAN, 1, key.getBytes(Charset.forName(\"UTF-8\")), identityId.getBytes(Charset.forName(\"UTF-8\"))); return redisTemplate.execute(callback); &#125; catch (Exception e) &#123; log.error(\"release lock occured an exception,exception:\", e); &#125; return false; &#125; 在代码中的identity字段用于身份识别，防止A用户持有的锁被B用户释放，我们可以用UUID生成该身份标识，这样完美解决了上面说的jedis锁被恶意释放的问题。 问题我们在创建锁的同时还需要设计好锁失效时间，若设计的redis失效时间小于业务处理的时间，这时业务A仍未处理完该数据但锁已被释放，业务B进来会获取到该锁，这样违背了同步的原则，会导致业务数据混乱，甚至代码报错。 基于redisson的分布式锁redisson简介Redisson采用了基于NIO的Netty框架，不仅能作为Redis底层驱动客户端，具备提供对Redis各种形式的连接功能，同样包含同步、异步、流、pipline、lua脚本连接处理redis数据。Redisson还实现了Redis文档中提到像分布式锁Lock这样的更高阶应用场景。事实上Redisson并没有不止步于此，在分布式锁的基础上还提供了联锁（MultiLock），读写锁（ReadWriteLock），公平锁（Fair Lock），红锁（RedLock），信号量（Semaphore），可过期性信号量（PermitExpirableSemaphore）和闭锁（CountDownLatch）这些实际当中对多线程高并发应用至关重要的基本部件，这里主要redisson分布式锁的设计展开讨论。 Redisson目前支持Redis 2.8以上版本，支持Java1.6+以上版本 当前时间:2020/6/16 redisson加锁流程图我用pd大致描绘了一下redisson的加锁机制： 可以看见，redisson相比与lettuce较好了一点在于，它有一个类似于看门狗的轮询机制，它的作用是在Redisson实例被关闭前，不断的延长锁的有效期。默认情况下，看门狗的检查锁的超时时间是30秒钟，也可以通过修改Config.lockWatchdogTimeout来另行指定。[注]：watchdog的默认超时时间为30000毫秒，且只适用于分布式锁的加锁请求中未明确使用leaseTimeout参数的情况。watchdog有点影响性能，如果能明确业务处理时间，最好指定缓存的失效时间 代码实现首先添加redisson的jar包 123456// 引入依赖&lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;最新版本&lt;/version&gt;&lt;/dependency&gt; Redisson的分布式锁设计是可重入式锁RLock，它实现了java.util.concurrent.locks.Lock接口，一般性常见的使用方法： 12RLock lock = redisson.getLock(\"anyLock\");lock.lock(); 这里不设置锁的超时时间，会启动看门狗每隔10秒监测redisson实例，防止业务逻辑未处理完锁被主动释放。然而一般我们推荐设置过期时间，通过leaseTime参数指定加锁时间，尽量减少因为看门狗的轮询执行而影响业务效率，伪代码如下： 12345678910111213// 加锁以后10秒钟自动解锁// 无需调用unlock方法手动解锁lock.lock(10, TimeUnit.SECONDS);// 尝试加锁，最多等待100秒，上锁以后10秒自动解锁boolean res = lock.tryLock(100, 10, TimeUnit.SECONDS);if (res) &#123; try &#123; ... &#125; finally &#123; lock.unlock(); &#125;&#125; redisson和lettuce一样，也支持异步的加锁方式，代码如下： 1234RLock lock = redisson.getLock(\"anyLock\");lock.lockAsync();lock.lockAsync(10, TimeUnit.SECONDS);Future&lt;Boolean&gt; res = lock.tryLockAsync(100, 10, TimeUnit.SECONDS); redisson同样不会存在jedis那样的恶意释放锁的情况，如果进程A创建了该锁，B去释放锁时会抛出IllegalMonitorStateException。如果需要其他进程也能释放锁，那么可以考虑采用分布式信号量Semaphore对象。 小结个人认为如果项目中以redis作为公共组件，并且集成了redisson作为java客户端的话，推荐使用redisson实现分布式加锁，实际生产环境中应该尽量使用主流的可靠的类库，在我编写本文的时候，redisson的star数已经到13.4K了，相关性的问题都能得到即时的反馈。特别在分布式锁的设计上，redisson考虑比较全面，避免了开发者悲催的重复造轮子,开发者也可以根据项目中的应用场景选用redisson不同的加锁实现。 zookeeper实现简介zookeeper(又名动物园园长)是一个分布式的高性能协调服务，zookeeper本身支持集群部署以选举的方式选择master节点，保证服务的高可用性。 同时它支持文件配置的统一管理、分布式锁、集群管理以及发布与订阅功能等等。我们都知道ZooKeeper提供的名称空间与标准文件系统的名称空间非常相似。名称是由斜杠（/）分隔的一系列路径元素。ZooKeeper命名空间中的每个节点都由路径标识，它的层次命名空间： 与标准文件系统不同，ZooKeeper命名空间中的每个节点都可以具有与其关联的数据以及子节点。就像拥有一个文件系统一样，该文件系统也允许文件成为目录。（ZooKeeper旨在存储协调数据：状态信息，配置，位置信息等，因此每个节点上存储的数据通常很小，在字节到千字节范围内。）我们使用术语znode来明确表示在谈论ZooKeeper数据节点，它包含以下几种节点创建类型： 1234PERSISTENT 持久化节点PERSISTENT_SEQUENTIAL 顺序自动编号持久化节点，这种节点会根据当前已存在的节点数自动加 1EPHEMERAL 临时节点， 客户端session超时这类节点就会被自动删除EPHEMERAL_SEQUENTIAL 临时自动编号节点 在这里，我们可以利用zookeeper节点的临时有序的特性实现分布式锁,即EPHEMERAL_SEQUENTIAL节点类型。 流程设计 代码设计添加pom依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.101tec&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;最新版本&lt;/version&gt;&lt;/dependency&gt; 前提你有zookeeper的环境，无论本地或者远程测试。如何安装和启动这里不赘述了，启动服务后，我们可以获取一个ZkClient对象 123public static ZkClient getZkClient(ZkSerializer zkSerializer)&#123; return new ZkClient(IP_PORT,SESSION_TIMEOUT,CONNECTIOIN_TIMEOUT,zkSerializer);&#125; 每一个服务获取锁的时候，需要在预定义的根目录创建一个临时有序的节点，伪代码如下： 123456789101112131415161718192021222324252627boolean isDone = false;int retryCount = 0;// 网络问题重试while (!isDone) &#123; isDone = true; try &#123; try &#123; // 创建临时有序子节点 finalCurrentNodePath = zkClient.createEphemeralSequential(rootName/$&#123;子节点前缀&#125;, \"testLock\"); &#125; catch (ZkNoNodeException e) &#123; // 如果有父节点不存在，那么先创建父节点,父节点路径即为:rootName myZkClient.createPersistent(rootName, true); // 再次创建临时有序子节点 finalCurrentNodePath = zkClient.createEphemeralSequential(rootName/$&#123;子节点前缀&#125;, \"testLock\"); &#125; catch (ZkNodeExistsException e) &#123; // 由于网络闪断？？ &#125; //TODO 判断当前节点是否为最小节点 true-&gt;加锁成功 &#125; catch (ZkNoNodeException e) &#123; if (retryCount++ &lt; $&#123;最大重试次数&#125;) &#123; isDone = false; &#125; else &#123; throw e; &#125; &#125;&#125; 当前拿到的finalCurrentNodePath结果是${rootName}/${子节点前缀}0000000001,后面的一串数字即为有序的临时节点号，当下次有某个服务过来抢占该rootName的锁时，它创建的临时结点为：${rootName}/${子节点前缀}0000000002。这时候我们需要判断当前服务拿到的节点号的序列是否为最小序列，所以我们需要把rootName下所有子节点排序，我们可以这样做： 123456789101112private List&lt;String&gt; getSortedChildren() &#123; try &#123; List&lt;String&gt; children = zkClient.getChildren(rootName); children.sort(Comparator.comparing(String::valueOf)); return children; &#125; catch (ZkNoNodeException e) &#123; //没有父节点时，创建父节点 myZkClient.createPersistent(rootName, true); //递归调用 return getSortedChildren(); &#125;&#125; 然后我们拿着排序后的子节点和当前节点比对，如果当前节点是最小的节点则获取锁成功，否则需要监听比它次小的节点，伪代码实现如下： 12345678910111213// 获取当前客户端对应的节点 所在集合中的位置int ourIndex = children.indexOf($&#123;当前客户端对应的节点序号&#125;);// 如果集合中不存在该节点，那么抛出异常if (ourIndex &lt; 0) &#123; throw new ZkNoNodeException(\"此节点不存在: \" + $&#123;当前客户端对应的节点序号&#125;);&#125;// 当前客户端对应的节点 排在集合开头时，表示该此客户端获得锁boolean isLock = ourIndex == 0;// 当前客户端 应该监视的节点的名字if (isLock) &#123; //加锁成功 执行业务代码 doBusiness()&#125; 如果没有获取到锁，我们可以通过一个jdk自带的闭锁来实现等待前置锁释放 12345678910111213// 倒计时锁final CountDownLatch latch = new CountDownLatch(1);// 创建监听器 阻塞一直等到监听节点消失 即 计数器值为0final IZkDataListener previousListener = new IZkDataListener() &#123; @Override public void handleDataDeleted(String dataPath) &#123; latch.countDown(); &#125; @Override public void handleDataChange(String dataPath, Object data) &#123; // ignore &#125;&#125;; 获取前置子节点全路径，并开启监听 1234567// 当前客户端 应该监视的节点的名字String watchName = shouldGetTheLock ? null : children.get(ourIndex - 1);// 组装当前客户端 应该监视的节点的路径String realPath = $&#123;rootName&#125;.concat(\"/\").concat(watchName);// 如果节点不存在会出现异常（需要使用重写了ZkClient类的watchForData方法的客户端）// 添加监听器 zkClient.subscribeDataChanges(realPath, previousListener); 当然这样进程会一直阻塞等待获取zk锁，我们可以优化代码，添加抢锁的最大等待时间 12// 超时 自动解除闭锁状态latch.await($&#123;等待时长&#125;, TimeUnit.MICROSECONDS); 最终在finally块中我们需要取消监听 12//取消监听zkClient.unsubscribeDataChanges(realPath, previousListener); 获取锁的服务在业务执行完成后调用 zkClient.delete(${当前服务节点全路径});,就释放了锁，这时下一个最小节点的服务就能抢占到资源。当然因为是临时的节点的原因，在zkclient连接关闭后，对应zookeeper上的节点也会删除，所以不用担心节点被持久化，服务一直处于等待状态。这样一个基于zookeeper的分布式锁就已经实现了，但美中不足的是并没有实现可重入、也无法防止恶意解锁。 进阶恶意解锁问题思路为了解决只有持有锁的对象才能释放锁的问题，我们可以在服务内部新建一个ConcurrentMap对象用于保存zk客户端和节点信息 1private final ConcurrentMap&lt;ZkClient, NodeInfo&gt; zkClientInfo = new ConcurrentHashMap&lt;&gt;(8); 在每次取得锁的同时，保存服务与节点的对应关系，在释放锁时候加个验证，如果本地缓存并没有找到关联信息，则无法释放，伪代码可以这样写 12345678910NodeInfo nodeInfo = zkClientInfo.get($&#123;客户端信息&#125;);if (nodeInfo == null) &#123; throw new IllegalMonitorStateException(\"你不是锁: \" + $&#123;rootName&#125; + \"的拥有者,无法执行此操作！\");&#125;try &#123; //正常释放锁 releaseLock($&#123;节点全路径&#125;);&#125; finally &#123; zkClientInfo.remove($&#123;客户端信息&#125;);&#125; 实现重入锁思路为了实现锁的可重入，我们可以在定义NodeInfo的时候，添加一个计数器 1234567891011121314151617class NodeInfo &#123; /** * NodeInfo类的构造器 * @param nodePath */ private NodeInfo(String nodePath) &#123; this.nodePath = nodePath; &#125; /** * 对应的节点路径 */ final String nodePath; /** *该客户端内,使用该锁资源的线程数 计数器 */ final AtomicInteger lockCount = new AtomicInteger(1);&#125; 每次获取锁的时候，先从zkClientInfo对象中找，若该服务已获取到zk锁，则使计数器+1,获取锁逻辑返回true 并执行业务逻辑 123456NodeInfo nodeInfo = zkClientInfo.get($&#123;客户端信息&#125;);if (nodeInfo != null) &#123; // 如果此线程已经获取了锁 System.out.println($&#123;客户端信息&#125; + \"已经获得了该锁了！\"); nodeInfo.lockCount.incrementAndGet(); //计数器加一 return true;&#125; 在释放锁的时候，也是需要注意:仅当lockCount.decrementAndGet=0时，才会正常释放锁,所以需要在之前释放锁的逻辑上稍加修改 12345678910111213141516171819NodeInfo nodeInfo = zkClientInfo.get($&#123;客户端信息&#125;);if (nodeInfo == null) &#123; throw new IllegalMonitorStateException(\"你不是锁: \" + $&#123;rootName&#125; + \"的拥有者,无法执行此操作！\");&#125;//计数器-1int count = nodeInfo.lockCount.decrementAndGet();// 当还有其他线程在使用锁时，那么还不能释放if (count &gt; 0) &#123; return;&#125;if (count &lt; 0) &#123; throw new IllegalMonitorStateException(\"锁计数器为负数: \" + $&#123;rootName&#125;);&#125;try &#123; //只有当计数器为0时 正常释放锁 releaseLock($&#123;节点全路径&#125;);&#125; finally &#123; zkClientInfo.remove($&#123;客户端信息&#125;);&#125; 小结基于zookeeper的实现比较复杂，考虑的东西也比较多，如果不是特别熟悉zk的架构，最好还是用redis这种封装好的api应用到代码开发中去。因为年前做通信网关时用到zookeeper这个组件，当时主要用来做服务的注册监听与路由转发，顺带考虑了用它来实现分布式加锁的方案,期间参考了官网和一些博客(虽然最后还是用的redis(～￣▽￣)～)，但不妨碍它在分布式集群的中的广泛应用（比如kafka啦，每次装kafka都要先装zookeeper 蛋疼哦…）,可能以后会有场景用到吧！ 参考1、lettuce Guide2、redisson Guide3、zookeeper Guide","categories":[{"name":"distributed system","slug":"distributed-system","permalink":"https://sillybilly-share.top/categories/distributed-system/"},{"name":"lock","slug":"lock","permalink":"https://sillybilly-share.top/categories/lock/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://sillybilly-share.top/tags/mysql/"},{"name":"distributed-lock","slug":"distributed-lock","permalink":"https://sillybilly-share.top/tags/distributed-lock/"},{"name":"redis","slug":"redis","permalink":"https://sillybilly-share.top/tags/redis/"},{"name":"zookeeper","slug":"zookeeper","permalink":"https://sillybilly-share.top/tags/zookeeper/"}]},{"title":"cxf动态构建webservice","slug":"cxf动态构建webservice","date":"2020-06-11T01:58:55.000Z","updated":"2022-11-24T01:35:09.627Z","comments":true,"path":"cxf动态构建webservice.html","link":"","permalink":"https://sillybilly-share.top/cxf%E5%8A%A8%E6%80%81%E6%9E%84%E5%BB%BAwebservice.html","excerpt":"前提平台需要提供一个可配置的webservice接口，用于其他服务的远程调用，并且可以依照项目不同的业务意义自定义webservice接口的上下文。本文主要描述如何通过cxf动态构建webservice接口。维基百科上基于web服务的体系结构流程： 12341、服务提供者将WSDL文件发送到UDDI。2、服务请求者联系UDDI以找出谁是其所需数据的提供者，然后使用SOAP协议联系服务提供者。3、服务提供者使用SOAP协议验证服务请求并以XML文件发送结构化数据。4、服务请求者将使用XSD文件再次验证该XML文件。 大概的流程图：","text":"前提平台需要提供一个可配置的webservice接口，用于其他服务的远程调用，并且可以依照项目不同的业务意义自定义webservice接口的上下文。本文主要描述如何通过cxf动态构建webservice接口。维基百科上基于web服务的体系结构流程： 12341、服务提供者将WSDL文件发送到UDDI。2、服务请求者联系UDDI以找出谁是其所需数据的提供者，然后使用SOAP协议联系服务提供者。3、服务提供者使用SOAP协议验证服务请求并以XML文件发送结构化数据。4、服务请求者将使用XSD文件再次验证该XML文件。 大概的流程图： 摘要webserviceWeb Service也叫XML Web Service WebService。它是一种构建应用程序的普遍模型,可以在任何支持网络通信的操作系统中实施运行;它是一种新的web应用程序分支，是自包含、自描述、模块化的应用，可以发布、定位、通过web调用。WebService是一个应用组件,它逻辑性的为其他应用程序提供数据与服务.各应用程序通过网络协议和规定的一些标准数据格式（Http，XML，Soap)来访问WebService,通过WebService内部执行得到所需结果.WebService可以执行从简单的请求到复杂商务处理的任何功能。一旦部署以后，其他WebService应用程序可以发现并调用它部署的服务。 WSDL简介：1、WSDL 文档的组成部分 [portType]：web service 执行的操作 [message]：web service 使用的消息 [types]：web service 使用的数据类型 [binding]：web service 使用的通信协议2、WSDL元素介绍 WSDL规范为了不会产生歧义，定义了特有名词来表述功能与服务。 &emsp;&emsp;[portType]：[portType]元素是最重要的 WSDL 元素。它可描述一个 Web Service、可被执行的操作，以及相关的消息。 可以把 [portType]元素比作传统编程语言中的一个函数库（或一个模块、或一个类）。 [operation]：[operation]是对服务中所支持的操作的抽象描述，一般单个Operation描述了一个访问入口的请求/响应消息对。 [message]：[message]元素定义一个操作的数据元素。 每个消息均由一个或多个部件组成。可以把这些部件比作传统编程语言中一个函数调用的参数。 通信消息的数据结构的抽象类型化定义。使用Types所定义的类型来定义整个消息的数据结构。 [types]： [types]元素定义WebService 使用的数据类型。为了最大程度的平台中立性，WSDL 使用 XML Schema 语法来定义数据类型。 [binding]： [binding]元素为每个端口定义消息格式和协议细节。 cxfapache cxf 用户指南 http://cxf.apache.org/docs/index.html Apache CXF™是一个开放源代码服务框架。可以通过编程API（例如JAX-WS和JAX-RS）来构建和开发服务，这些服务例如SOAP，XML / HTTP，RESTful HTTP或CORBA，并且可以通过各种传输方式（例如HTTP，JMS或JBI）工作。 CXF包含广泛的功能集，但主要集中在以下领域: Web服务标准支持： CXF支持各种Web服务标准，包括SOAP，WS-I基本配置文件，WSDL，WS-Addressing，WS-Policy，WS-ReliableMessaging，WS-Security，WS-SecurityPolicy，WS-SecureConverstation和WS-Trust（部分）。 前端模板： CXF支持多种“前端”编程模型。CXF实现了JAX-WS API。与参考实现相比，CXF JAX-WS支持包括对该标准的一些扩展，使其大大易于使用：它会自动为请求和响应bean类生成代码，对于简单情况不需要WSDL。它还包括一个“简单前端”，该前端允许创建没有注释的客户端和端点。CXF支持使用WSDL进行合同优先开发和从Java开始的代码优先开发。对于REST，CXF还支持JAX-RS: 易用性： CXF旨在直观易用。有简单的API可以快速构建代码优先服务，Maven插件使工具集成变得容易，JAX-WS API支持，Spring 2.x XML支持使配置变得简单，等等。 二进制和旧版协议支持： CXF旨在提供一种可插拔的体系结构，该体系结构不仅支持XML，而且还支持非XML类型的绑定（例如JSON和CORBA）以及任何类型的传输。 为什么使用cxf构建webServiceCXF实现了JAX-WS API，使构建Web服务变得容易。JAX-WS包含许多不同的领域： 1、从Java类生成WSDL，并从WSDL生成Java类(自底向上、自顶向下的开发模型) 2、提供程序API，使您可以创建简单的消息接收服务器端点 3、调度API，使您可以将原始XML消息发送到服务器端点除此之外CXF还支持各种Web服务规范，包括WS-Addressing，WS-Policy，WS-ReliableMessaging和WS-Security。最重要的一点，作为Apache的顶级项目，spring是cxf的头等公民，它支持Spring2.0XML语法，使得cxf基于spring构建webService接口变得非常简单。 code view因为该工程是作为平台jar包依赖到其他项目中去的，所以只需要新建一个maven工程就可以了。 maven jar包依赖12345&lt;dependency&gt; &lt;groupId&gt;org.apache.cxf&lt;/groupId&gt; &lt;artifactId&gt;cxf-spring-boot-starter-jaxws&lt;/artifactId&gt; &lt;version&gt;3.3.6&lt;/version&gt;&lt;/dependency&gt; [tip]这里选用的是2020年3月30日发布的最新3.3.6版本,之前验证的时候，本地springBoot version 是2.3.0.RELEASE，运行各种报错，然后才发现最新的cxf springboot2.3.0.RELEASE 还未适配.. 幸好平台的所有项目springboot的版本号都不高,只要是2.1.13以下的服务集成该jar都能正常运行。 webserver接口定义WebService的订阅接口 12345678910111213141516171819202122232425/** * KpiService * webService 属性： * [name]：此属性的值包含XML Web Service的名称。在默认情况下，该值是实现XML Web Service的类的名称，wsdl:portType 的名称。缺省值为 Java 类的简单名称 + Service。 * [targetNamespace]：默认的值为 \"http://&#123;packageName&#125;/\" ，可以通过此变量指定一个自定义的上下文。 * [serviceName]：对外发布的服务名，指定Web Service的服务名称：wsdl:service。缺省值为 Java 类的简单名称 + Service。 * [endpointInterface]：接口的包路径 * [portName]：wsdl:portName的值。缺省值为WebService.name+Port * [wsdlLocation]：指定用于定义 Web Service 的 WSDL 文档的 Web 地址 * @blame xm */@WebServicepublic interface CxfWebService &#123; /** * webMethod 属性： * [operationName]：指定与此方法相匹配的wsdl:operation 的名称。缺省值为 Java 方法的名称。 * [action]：定义此操作的行为。对于 SOAP 绑定，此值将确定 SOAPAction 头的值。缺省值为 Java 方法的名称。 * [exclude]：指定是否从 Web Service 中排除该方法。缺省值为 false。 * @param param xml文档 * @return */ @WebMethod(operationName = \"operationName\") String getValue(@WebParam(name = \"param\") String param);&#125; 123456789@WebService(name = \"test\", targetNamespace = \"test\", endpointInterface = \"com.sillybilly.test.cxf.service.CxfWebService\", serviceName = \"CxfWebService\")public class CxfWebServiceImpl implements CxfWebService &#123; @Override public String getValue(String param) &#123; //todo parse xml return \"hello world\"; &#125;&#125; 定义接口配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384@Configuration@Slf4j@ComponentScan(value = \"com.sillybilly.test.cxf\")public class CxfWebServiceConfig &#123; @Value(\"$&#123;common.sysName&#125;\") private String sysName; @Value(\"$&#123;common.name&#125;\") private String serviceName; @Value(\"$&#123;common.targetNamespace&#125;\") private String targetNamespace; @Value(\"$&#123;common.operationName&#125;\") private String operationName; @Bean(name = Bus.DEFAULT_BUS_ID) public SpringBus springBus() &#123; SpringBus springBus = new SpringBus(); return springBus; &#125; @Bean public Endpoint endpoint() &#123; EndpointImpl endpoint = new EndpointImpl(springBus(), newServiceInstance()); endpoint.publish(\"/common\"); return endpoint; &#125; /** * 为了防止与springmvc的DispatcherServlet冲突 需要重定义bean名称 * 且只能为cxfServletRegistration * @return */ @Bean(\"cxfServletRegistration\") public ServletRegistrationBean dispatcherServlet() &#123; //注册servlet 拦截/ws 开头的请求 不设置 默认为：/services/* return new ServletRegistrationBean(new CXFServlet(), \"/\" + sysName + \"/services/*\"); &#125; public CxfWebService newServiceInstance() &#123; try &#123; //修改webservice注解 //name、endpointInterface、targetNamespace Map&lt;String, Object&gt; webServiceConfig = new HashMap&lt;&gt;(4); webServiceConfig.put(\"name\", serviceName); webServiceConfig.put(\"targetNamespace\", targetNamespace); WebService webService = CxfWebService.class.getAnnotation(WebService.class); changeAnnotationValue(webService, webServiceConfig); //修改method注解 Map&lt;String, Object&gt; methodConfig = new HashMap&lt;&gt;(4); methodConfig.put(\"operationName\", operationName); Method method = CxfWebService.class.getMethod(\"getValue\", String.class); WebMethod webMethod = method.getAnnotation(WebMethod.class); changeAnnotationValue(webMethod, methodConfig); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; CxfWebService kpiService = new CxfWebServiceImpl(); return kpiService; &#125; public static void changeAnnotationValue(Annotation annotation, Map&lt;String, Object&gt; newValues) throws Exception &#123; log.info(\"加载注解 [&#123;&#125;]\",annotation.annotationType().getCanonicalName()); InvocationHandler handler = Proxy.getInvocationHandler(annotation); Field f; try &#123; f = handler.getClass().getDeclaredField(\"memberValues\"); &#125; catch (Exception e) &#123; e.printStackTrace(); throw new IllegalStateException(e); &#125; f.setAccessible(true); Map&lt;String, Object&gt; memberValues; memberValues = (Map&lt;String, Object&gt;) f.get(handler); for (String key : newValues.keySet()) &#123; Object newValue = newValues.get(key); memberValues.put(key, newValue); &#125; memberValues.entrySet().forEach(c-&gt;log.info(\"[&#123;&#125;]-&gt;[&#123;&#125;]\",c.getKey(),c.getValue())); &#125;&#125; 最终WSDL 接口访问地址应该是 ip:port/{sysName}/services/common?wsdl ,这样一个webService的上下文就已经定义好了。 测试新建一个SpringBoot工程，引入该jar包，配置相关yaml文件： 12345common: name: testservice targetNamespace: http://pulish.address/test operationName: testInterface sysName : testSys 运行之后，控制台打印：访问localhost:8080/testSys/services/common?wsdl 通过现有WSDL自顶向下生成类框架为了测试接口的可用性，我们需要编写客户端代码测试。为了方便快捷，我这里使用idea自带的webService代码生成器。因为服务端是用cxf构建的，所以这里我们需要下载cxf,下载地址:http://cxf.apache.org/download.html ，然后在idea中引入，如图：输入webservice接口地址：点击ok后，最终生成的java文件 找到Client主类，就能拿到服务端返回的结果了，运行效果图： LAST BUT NOT LEAST在webService接口中的数据传输对象都是xml格式的，所以我们需要将xml转换为我们日常使用的java业务对象，一般性的我们使用JAXB，类似的实现： 12345678910111213141516171819202122232425262728293031/** * java对象转换为xml文件 * * @param obj java对象 * @param load java对象.Class * @return xml文件的String * @throws JAXBException */ public static String beanToXml(Object obj, Class&lt;?&gt; load) throws JAXBException &#123; JAXBContext context = JAXBContext.newInstance(load); Marshaller marshaller = context.createMarshaller(); marshaller.setProperty(Marshaller.JAXB_FORMATTED_OUTPUT, false); StringWriter writer = new StringWriter(); marshaller.marshal(obj, writer); return writer.toString(); &#125; /** * xml文件配置转换为对象 * * @param param xml * @param load java对象.Class * @return java对象 * @throws JAXBException */ @SuppressWarnings(\"unchecked\") public static &lt;T&gt; T xmlToBean(String param, Class&lt;T&gt; load) throws JAXBException &#123; JAXBContext context = JAXBContext.newInstance(load); Unmarshaller unmarshaller = context.createUnmarshaller(); return (T) unmarshaller.unmarshal(new StringReader(param)); &#125; 然后不出意外的在解析xml文件时发生异常:javax.xml.bind.UnmarshalException: 意外的元素 (uri:””, local:””) 存在的解决方法是:将待解析的java实体类上加上@XmlRootElement(namespace=”${targetNamespace}”)注解 这里的namespace是webService上下文的targetNamespace变量。当然也可以和上面的实现一样，根据配置动态加载： 123456//修改XmlRootElement注解Map&lt;String,Object&gt; xmlConfig = new HashMap&lt;&gt;(4);xmlConfig.put(\"namespace\",targetNamespace);XmlRootElement xmlRootElement = Info.class.getAnnotation(XmlRootElement.class);//changeAnnotationValue 在CxfWebServiceConfig配置类已经定义changeAnnotationValue(xmlRootElement,xmlConfig); 至此，webservice接口定下来之后，就可以愉快的实现业务逻辑了。","categories":[{"name":"webservice","slug":"webservice","permalink":"https://sillybilly-share.top/categories/webservice/"},{"name":"cxf","slug":"cxf","permalink":"https://sillybilly-share.top/categories/cxf/"},{"name":"RPC","slug":"RPC","permalink":"https://sillybilly-share.top/categories/RPC/"}],"tags":[{"name":"cxf","slug":"cxf","permalink":"https://sillybilly-share.top/tags/cxf/"},{"name":"webservice","slug":"webservice","permalink":"https://sillybilly-share.top/tags/webservice/"},{"name":"xml/http","slug":"xml-http","permalink":"https://sillybilly-share.top/tags/xml-http/"}]},{"title":"elasticsearch-high-level-client","slug":"elasticsearch-high-level-client","date":"2020-05-18T13:17:36.000Z","updated":"2022-11-24T01:35:09.627Z","comments":true,"path":"elasticsearch-high-level-client.html","link":"","permalink":"https://sillybilly-share.top/elasticsearch-high-level-client.html","excerpt":"前提项目中需要对新闻发布内容做全文检索，基于原本的mysql数据库已经无法满足现有的需求了，所以需要用到es+ik分词器作为技术栈，经过调研发现适用于es的java客户端主流的有三种：Java High Level REST Client、JestClient、spring-data-elasticsearch。（当然还有es版本弃子：Java Low Level REST Client，底层是基于transport完成数据访问，而es7.0之后不在支持transport故不在考虑范围内）。去同性交友网站看了下spring-data-es，发现它本身也是推荐JestClient，再然后才是自家的java客户端。对比JestClient和Java-High-Level-REST-Client： 12JestClient:底层基于HttpClient+GSON提供集群访问与数据映射,在ES操作易用性方面与Java High Level REST Client部分伯仲，但是其多版本兼容性比后者强很多。虽然使用有龟速之称的GSON切不能替换，但是其性能应该能满足大部分业务场景。Java-High-Level-REST:很多设计也借鉴了Jest,虽然有严格的版本控制，但有默认的调优参数，其性能会更加优秀。 在综合考虑之下。选用了Java High Level REST作为java client,毕竟es自己的客户端，更新迭代比jestClient快，而且社区活跃，文档齐全。api文档","text":"前提项目中需要对新闻发布内容做全文检索，基于原本的mysql数据库已经无法满足现有的需求了，所以需要用到es+ik分词器作为技术栈，经过调研发现适用于es的java客户端主流的有三种：Java High Level REST Client、JestClient、spring-data-elasticsearch。（当然还有es版本弃子：Java Low Level REST Client，底层是基于transport完成数据访问，而es7.0之后不在支持transport故不在考虑范围内）。去同性交友网站看了下spring-data-es，发现它本身也是推荐JestClient，再然后才是自家的java客户端。对比JestClient和Java-High-Level-REST-Client： 12JestClient:底层基于HttpClient+GSON提供集群访问与数据映射,在ES操作易用性方面与Java High Level REST Client部分伯仲，但是其多版本兼容性比后者强很多。虽然使用有龟速之称的GSON切不能替换，但是其性能应该能满足大部分业务场景。Java-High-Level-REST:很多设计也借鉴了Jest,虽然有严格的版本控制，但有默认的调优参数，其性能会更加优秀。 在综合考虑之下。选用了Java High Level REST作为java client,毕竟es自己的客户端，更新迭代比jestClient快，而且社区活跃，文档齐全。api文档 es安装es下载地址: https://www.elastic.co/cn/downloads/elasticsearchik分词器下载地址：https://github.com/medcl/elasticsearch-analysis-ik/releases es解压后运行/bin目录下的elasticsearch.bat即可。在es plugins下创建ik文件夹，将下载的ik分词器解压到该目录，运行es,效果图： 在浏览器输入localhost:9200即可查看es的版本信息：通过 “192.168.66.128:9200/_cat/indices?v” 可以查看es索引情况通过 “localhost:9200/_search” 查看 es 中的所有数据 ，当然也可以指定es索引(localhost:9200/{index}/_search),如果是多个索引以逗号分开{index1,index2}如图： kibana下载地址：https://www.elastic.co/cn/downloads/kibana默认解压后即可运行：通过kibana客户端访问：localhost:5601 测试分词结果： 默认的分词（standard）：ik_max_word:ik_smart: 显然，es默认的分词器对中文非常不友好，所以推荐用ik_max_word对检索文档进行细粒度分词，再用ik_smart匹配检索。 基于Java High Level REST esJava客户端使用maven jar添加新建Springboot项目，添加jar包： 123456789101112&lt;!--es java客户端--&gt;&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt; &lt;version&gt;7.4.0&lt;/version&gt;&lt;/dependency&gt;&lt;!--es检索--&gt;&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt; &lt;version&gt;7.4.0&lt;/version&gt;&lt;/dependency&gt; 这里的version版本需要和自己安装的es版本保持一致。 pom文件12345elasticsearch: host: $&#123;ES_HOST:localhost&#125; port: $&#123;ES_PORT:9200&#125; username: password: 定义es的ip:port，如果有账号密码也可自行添加。es集群则ip以’,’分开。 java实现获取配置信息，创建client12345678910111213141516171819202122232425262728293031323334@Configurationpublic class EsConfig &#123; @Value(\"$&#123;elasticsearch.host&#125;\") private String host; @Value(\"$&#123;elasticsearch.port&#125;\") private int port; @Value(\"$&#123;elasticsearch.username&#125;\") private String userName; @Value(\"$&#123;elasticsearch.password&#125;\") private String password; @Bean(destroyMethod = \"close\") public RestHighLevelClient restClient() &#123; //es集群ip以','分开 HttpHost[] httpHosts = Arrays.stream(host.split(\",\")).map(m-&gt;new HttpHost(m,port)).filter(Objects::nonNull).toArray(HttpHost[]::new); final CredentialsProvider credentialsProvider = new BasicCredentialsProvider(); credentialsProvider.setCredentials(AuthScope.ANY, new UsernamePasswordCredentials(userName, password)); RestClientBuilder builder = RestClient.builder(httpHosts) .setHttpClientConfigCallback(httpClientBuilder -&gt; httpClientBuilder.setDefaultCredentialsProvider(credentialsProvider)); RestHighLevelClient client = new RestHighLevelClient(builder); return client; &#125;&#125; 基于es的索引api调用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081@Service@Slf4jpublic class EsIndexService &#123; @Autowired private RestHighLevelClient client; /** * 创建索引 * * @param index * type:keyword不分词，text分词 * @throws IOException */ public void createEsIndex(String index) throws IOException &#123; XContentBuilder builder = XContentFactory.jsonBuilder() .startObject() .field(\"properties\") .startObject() .field(\"newsId\").startObject().field(\"index\", \"true\").field(\"type\", \"integer\").endObject() .field(\"newsAuthor\").startObject().field(\"index\", \"true\").field(\"type\", \"text\").endObject() .field(\"newsPublishTime\").startObject().field(\"index\", \"true\").field(\"type\", \"date\").field(\"format\", \"strict_date_optional_time||epoch_millis\").endObject() .field(\"newsUpdateTime\").startObject().field(\"index\", \"true\").field(\"type\", \"date\").field(\"format\", \"strict_date_optional_time||epoch_millis\").endObject() .field(\"clob\").startObject().field(\"index\",\"true\").field(\"type\",\"text\").field(\"analyzer\",\"ik_max_word\").endObject() .endObject() .endObject(); CreateIndexRequest createIndexRequest = new CreateIndexRequest(index); createIndexRequest.mapping(builder); client.indices().createAsync(createIndexRequest, RequestOptions.DEFAULT, new ActionListener&lt;CreateIndexResponse&gt;() &#123; @Override public void onResponse(CreateIndexResponse createIndexResponse) &#123; log.info(\"EsIndexService.createIndex index:&#123;&#125; status:&#123;&#125;\", index, createIndexResponse.isShardsAcknowledged()); &#125; @Override public void onFailure(Exception e) &#123; log.error(\"EsIndexService.createIndex exception\", e); &#125; &#125;); &#125; /** * 删除索引 * * @param index * @return */ public boolean delEsIndex(String index)&#123; boolean acknowledged = false; try &#123; DeleteIndexRequest deleteIndexRequest = new DeleteIndexRequest(index); //设置IndicesOptions 解决不可用的索引以及如何扩展通配符表达式 deleteIndexRequest.indicesOptions(IndicesOptions.LENIENT_EXPAND_OPEN); AcknowledgedResponse delete = client.indices().delete(deleteIndexRequest, RequestOptions.DEFAULT); acknowledged = delete.isAcknowledged(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return acknowledged; &#125; /** * 判断索引是否存在 * * @param index * @return */ public boolean isIndexExists(String index) &#123; boolean exists = false; try &#123; GetIndexRequest getIndexRequest = new GetIndexRequest(index); getIndexRequest.humanReadable(true); exists = client.indices().exists(getIndexRequest,RequestOptions.DEFAULT); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return exists; &#125;&#125; es的索引相当于oracle/mysql中的数据库，所以可以在配置文件中预定es index，在spring bean都实例化后，判断索引是否创建，若没有该索引则创建。很重要的一点，当我们调用GET ip:9200/mappping中字段的type为text才会进行分词，而es内置的分词器对中文并不友好，所以中文检索的字段需要添加ik_max_word（最大细度）分词。for example: es文档的增删（包含批量操作）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187@Service@Slf4jpublic class EsCommonService &#123; @Autowired private RestHighLevelClient client; ObjectMapper objectMapper; EsCommonService() &#123; objectMapper = new ObjectMapper(); &#125; /** * 创建索引 并插入数据 * es7.0之前可以设置type(每个type具有相同的文档结构) * es6.0后type废除 * es7.0后 每个索引对应一个默认的Type:\"_doc\" * 索引内文档id不存在 response.status = create * 若索引内文档id存在 response.status = update * * @param newsInfo 新闻检索内容 * @param index 索引名称 * @return */ public void insertEsDocument(NewsInfo newsInfo, String index) &#123; //创建索引index,指定文件编号id,存入文档source IndexRequest indexRequest = new IndexRequest(index) .id(String.valueOf(newsInfo.getNewsId())) .source(convertNewsInfoToMap(newsInfo), XContentType.JSON); //服务器超时或无响应时-同步api会引发ResponseException //IndexResponse response = client.index(indexRequest, RequestOptions.DEFAULT); //异步响应 错误时记录日志信息 client.indexAsync(indexRequest, RequestOptions.DEFAULT, new ActionListener&lt;IndexResponse&gt;() &#123; @Override public void onResponse(IndexResponse indexResponse) &#123; log.info(\"EsCommonService.createEsIndex newsId:&#123;&#125; index:&#123;&#125; status:&#123;&#125;\", newsInfo.getNewsId(), index, indexResponse.getResult().name()); // 如果有分片副本失败，可以获得失败原因信息 ReplicationResponse.ShardInfo info = indexResponse.getShardInfo(); if (info.getFailed() &gt; 0) &#123; for (ReplicationResponse.ShardInfo.Failure failure : info.getFailures()) &#123; String reason = failure.reason(); log.warn(\"cause：\" + reason); &#125; &#125; &#125; @Override public void onFailure(Exception e) &#123; log.error(\"EsCommonServic.createEsIndex exception\", e); &#125; &#125;); &#125; /** * 删除索引中数据 * 索引内文档id存在 response.status = deleted * 若索引内文档id不存在 response.status = not_found * * @param index 索引名称 * @param id 新闻id */ public void deleteEsDocument(String index, String id) &#123; DeleteRequest deleteRequest = new DeleteRequest(index, id); client.deleteAsync(deleteRequest, RequestOptions.DEFAULT, new ActionListener&lt;DeleteResponse&gt;() &#123; @Override public void onResponse(DeleteResponse deleteResponse) &#123; log.info(\"EsCommonService.deleteEsDocument newsId:&#123;&#125; index:&#123;&#125; status:&#123;&#125;\", id, index, deleteResponse.getResult().name()); &#125; @Override public void onFailure(Exception e) &#123; log.error(\"EsCommonServic.onFailure exception\", e); &#125; &#125;); &#125; /** * 批量插入es文档(如果index|id存在则update) * * @param newsInfos 新闻内容列表 * @param index 索引名称 */ public void multiInsertEsDocument(List&lt;NewsInfo&gt; newsInfos, String index) &#123; BulkRequest request = new BulkRequest(index); newsInfos.forEach(newsInfo -&gt; request.add(new IndexRequest() .id(String.valueOf(newsInfo.getNewsId())) .source(convertNewsInfoToMap(newsInfo), XContentType.JSON))); client.bulkAsync(request, RequestOptions.DEFAULT, new ActionListener&lt;BulkResponse&gt;() &#123; @Override public void onResponse(BulkResponse bulkItemResponses) &#123; log.info(\"EsCommonService.MultiInsertEsDocument hasFailures:&#123;&#125;\", bulkItemResponses.hasFailures()); &#125; @Override public void onFailure(Exception e) &#123; log.error(\"EsCommonServic.MultiInsertEsDocument exception\", e); &#125; &#125;); &#125; /** * 批量删除文档 * * @param index 索引名称 * @param ids 文档id列表 */ public void multiDeleteEsDocument(String index, List&lt;String&gt; ids) &#123; BulkRequest request = new BulkRequest(index); ids.forEach(id -&gt; request.add(new DeleteRequest().id(id))); client.bulkAsync(request, RequestOptions.DEFAULT, new ActionListener&lt;BulkResponse&gt;() &#123; @Override public void onResponse(BulkResponse bulkItemResponses) &#123; log.info(\"EsCommonService.MultiDeleteEsDocument hasFailures:&#123;&#125;\", bulkItemResponses.hasFailures()); &#125; @Override public void onFailure(Exception e) &#123; log.error(\"EsCommonServic.MultiDeleteEsDocument exception\", e); &#125; &#125;); &#125; /** * 中文检索 * * @param document 查询入参 * @param index 索引内容 * @return SearchResponse * @throws IOException */ public SearchResponse searchEsDocument(ProfileDocument document, String... index) throws IOException &#123; SearchRequest request = new SearchRequest(index); SearchSourceBuilder builder = new SearchSourceBuilder(); builder.query(getQueryBuilder(document)); //自定义排序机制按照id降序 默认 sort by _score builder.sort(new FieldSortBuilder(\"_id\").order(SortOrder.DESC)); //细粒度排除检索字段 //builder.fetchSource(includes,excludes); //设置检索偏移量和显示条数 builder.from(document.getOffset()); builder.size(document.getPerSize()); //控制最大检索时间 builder.timeout(new TimeValue(60, TimeUnit.SECONDS)); request.source(builder); //执行检索 超时抛出IO异常 服务器返回4xx or 5xx会引发ElasticsearchException SearchResponse searchResponse = client.search(request, RequestOptions.DEFAULT); return searchResponse; &#125; /** * 根据查询条件构建QueryBuilder * * @param document * @return */ private BoolQueryBuilder getQueryBuilder(ProfileDocument document) &#123; BoolQueryBuilder boolQueryBuilder = new BoolQueryBuilder(); //must:and多条件查询 should:or查询 Object authorBuilder = getNewsAuthorBuilder(document); Object publishBuilder = rangeNewsPublishTime(document); Object updateBuilder = rangeNewsUpdateTime(document); Object contentBuilder = getContentBuilder(document); //设置默认元素\"null\",防止builder为空导致创建流失败 Flux.just(authorBuilder, publishBuilder, updateBuilder, contentBuilder) .filter(f-&gt;!\"null\".equals(f)) .doOnNext(builder -&gt; boolQueryBuilder.must((QueryBuilder) builder)).subscribe(); return boolQueryBuilder; &#125; /** * Jackson对象转map * * @param newsInfo * @return */ private Map&lt;String, Object&gt; convertNewsInfoToMap(NewsInfo newsInfo) &#123; return objectMapper.convertValue(newsInfo, Map.class); &#125;&#125; 在es大多数操作中都包含同步和异步两种，这里是基于异步的操作，将同步的异常处理通过listener的形式体现出来，然后由我们自己指定如何处理响应或潜在的失败。NewsInfo和ProfileDocument两个实体类,分别定义了es文档内容、es联合检索条件(包含偏移量和pageSize)。 检索条件Builder工具类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public class QueryBuilderUtils &#123; /** * 新闻作者 精确匹配 * @param document * @return */ public static Object getNewsAuthorBuilder(ProfileDocument document)&#123; String newsAuthor = document.getNewsAuthor(); if (null == newsAuthor)&#123; return \"null\"; &#125; return QueryBuilders.termQuery(\"newsAuthor\",newsAuthor); &#125; /** * 发布时间 范围匹配 * * @param document * @return */ public static Object rangeNewsPublishTime(ProfileDocument document)&#123; Date startTime = document.getStartNewsPublishTime(); Date endTime = document.getEndNewsPublishTime(); if (null == startTime || null == endTime)&#123; return \"null\"; &#125; return QueryBuilders.rangeQuery(\"newsPublishTime\").from(startTime).to(endTime).format(\"strict_date_optional_time||epoch_millis\"); &#125; /** * 新闻修改时间 范围匹配 * * @param document * @return */ public static Object rangeNewsUpdateTime(ProfileDocument document)&#123; Date startTime = document.getStartNewsUpdateTime(); Date endTime = document.getEndNewsUpdateTime(); if (null == startTime || null == endTime)&#123; return \"null\"; &#125; return QueryBuilders.rangeQuery(\"newsUpdateTime\").from(startTime).to(endTime).format(\"strict_date_optional_time||epoch_millis\"); &#125; /** * content字段匹配 * @param document * @return */ public static Object getContentBuilder(ProfileDocument document)&#123; String clob = document.getCob(); if (null == clob)&#123; return \"null\"; &#125; return QueryBuilders.matchQuery(\"clob\", clob) //启动模糊查询 莱温斯坦距离 AUTO:3,6 .fuzziness(Fuzziness.AUTO) //匹配前缀长度 .prefixLength(0) //最大扩展项 .maxExpansions(50) //使用ik中文分词器 .analyzer(\"ik_smart\"); &#125;&#125; 在使用时调用reactor的Flux.just参数不能为空，故”null”代替null（仅为了写代码方便，不是最佳实践）。 Result用postman对部分字段测试联合检索，例如clob字段包含”处处”，offset=0,分页数=10，索引名=1时，检索内容如下： 加上author=sillybilly时，测试效果：至此，简单的es检索功能就完成了。当然还有很多其他的功能需要完善比如：1、HighlightBuilder类处理的检索字段加亮显示2、es全量同步、增量同步问题（考虑用logstash轮询？还是利用mysql数据库仿logstash造个定时job轮询的车轱辘？）","categories":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://sillybilly-share.top/categories/elasticsearch/"}],"tags":[{"name":"java","slug":"java","permalink":"https://sillybilly-share.top/tags/java/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://sillybilly-share.top/tags/elasticsearch/"},{"name":"db","slug":"db","permalink":"https://sillybilly-share.top/tags/db/"}]},{"title":"nginx本地缓存","slug":"nginx本地缓存","date":"2020-04-14T12:27:44.000Z","updated":"2022-11-24T01:35:09.629Z","comments":true,"path":"nginx本地缓存.html","link":"","permalink":"https://sillybilly-share.top/nginx%E6%9C%AC%E5%9C%B0%E7%BC%93%E5%AD%98.html","excerpt":"前提通常nginx作为一个很强大的高性能Web和反向代理服务，在没有F5的情况下用来作为负载均衡器都是一种很不错的选择。而实际的使用中我发现nginx的作用远不止于此，本文在此主要讲述nginx作为缓存服务器的使用和实现。nginx支持类似Squid的缓存功能，分为两种。一种是永久缓存，即指定一个文件将用户访问的数据缓存在该文件中，并且不会过期；另一种是临时缓存，顾名思义可以指定过期策略、缓存空间大小，存在第三方插件支持(purge模块)，用来清除某个路径缓存。比较坑的是，只有付费版的nginx plus支持路径匹配删除,例如：https//sillybilly-share.top/* 删除缓存key值匹配https//sillybilly-share.top的所有缓存内容，第三方插件只能全路径匹配，网上也看到一些用lua脚本写的删除策略，但都是遍历删除，当缓存文件很大时清除缓存的效率就会低下。","text":"前提通常nginx作为一个很强大的高性能Web和反向代理服务，在没有F5的情况下用来作为负载均衡器都是一种很不错的选择。而实际的使用中我发现nginx的作用远不止于此，本文在此主要讲述nginx作为缓存服务器的使用和实现。nginx支持类似Squid的缓存功能，分为两种。一种是永久缓存，即指定一个文件将用户访问的数据缓存在该文件中，并且不会过期；另一种是临时缓存，顾名思义可以指定过期策略、缓存空间大小，存在第三方插件支持(purge模块)，用来清除某个路径缓存。比较坑的是，只有付费版的nginx plus支持路径匹配删除,例如：https//sillybilly-share.top/* 删除缓存key值匹配https//sillybilly-share.top的所有缓存内容，第三方插件只能全路径匹配，网上也看到一些用lua脚本写的删除策略，但都是遍历删除，当缓存文件很大时清除缓存的效率就会低下。 准备在配置永久缓存和临时缓存之前，需要将nginx编译安装完成。这里在linux环境下操作（window下编译第三方模块太麻烦了）。如果linux没有安装编译工具和库文件的需要执行： 1yum -y install make zlib zlib-devel gcc-c++ libtool openssl openssl-devel 为了让nginx支持rewrite功能需要下载pcre包，官网地址：pcre进入解压后的pcre目录下,编译后安装： 12[root@user pcre-8.35]# ./configure[root@user pcre-8.35]# make &amp;&amp; make install 然后下载nginx源码包以及第三方purge模块，nginx下载地址：nginx，purge模块：purge执行命令编译安装，同时加入第三方purge模块 12./configure --prefix=/usr/local/webserver/nginx --with-http_stub_status_module --with-http_ssl_module --with-pcre=/usr/local/src/pcre-8.45 （pcre安装地址） --add-module=/usr/ngx_cache_purge-2.3 (purge模块解压地址)make &amp;&amp; make install 此时进入nginx目录，执行./sbin/nginx -v，出现版本号就没问题了。 nginx配置临时缓存http层级定义临时缓存保存策略: 12proxy_temp_path &#x2F;apps&#x2F;nginx&#x2F;short-temp;proxy_cache_path &#x2F;apps&#x2F;nginx&#x2F;short-cache levels&#x3D;1:2 keys_zone&#x3D;nginx-cache:100m inactive&#x3D;7d max_size&#x3D;10g; 说明：proxy_temp_path：缓存临时文件，该文件需和proxy_cache_path在统一分区proxy_cache_path：定义缓存文件路径为/apps/nginx/short-cache，key由两层目录结构（第一层是key值md5最后一位字符，第二层是key值md5倒数第2、3位字符），缓存名称为nginx-cache，缓存空间大小为100m,内容7天未被访问则清除该缓存，最大硬盘缓存空间为10g。 定义location正则匹配: 1234567891011121314location ~* ~* \\.(jpeg|jpg|png|css|js)$ &#123; add_header Cache-Control no-cache; proxy_pass http:&#x2F;&#x2F;ip:port; proxy_cache nginx-cache; proxy_cache_key $host$uri$is_args$args; proxy_cache_valid 200 304 1d; proxy_set_header Host $host:$server_port; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Range $http_range; add_header Nginx-Cache &quot;$upstream_cache_status&quot;; proxy_next_upstream http_500 http_502 http_503 error timeout invalid_header; expires 1d; &#125; 说明：将后缀为.jpg/.png等请求路由到某个服务。proxy_cache:定义配置的缓存名proxy_cache_key：以域名、URL、请求参数合成缓存key值经过md5hash到二级缓存目录中去proxy_cache_valid：可以给不同http状态码设置不同的缓存时间…proxy_next_upstream:对于服务器返回的502，504和执行超时等错误，将请求转发给upstream中的另一台服务器，实现故障转移 补充对于http1.0遗留的Pragma:no-cache响应头：nginx会略过该请求不做任何处理(请求不会被缓存)，所以需要添加： 123proxy_hide_header Pragma;proxy_ignore_headers Expires;proxy_ignore_headers Cache-Control; 定义缓存清除配置: 12345location ~ &#x2F;purge(&#x2F;.*) &#123; allow 127.0.0.1; deny all; proxy_cache_purge nginx-cache $host$1$is_args$args; &#125; 说明：purge的调用也十分简单，只需在原请求路径前加上purge即可，例如：https://sillybilly-share.top/1.html 经过缓存后，调用 https://sillybilly-share.top/purge/1.html 即可 永久缓存123456789101112131415161718 location ~* \\.(html)$ &#123; if ($request_uri ~ \\.($is_args$args)$ )&#123; proxy_pass http:&#x2F;&#x2F;ip:port; break; &#125; if (!-e $request_filename) &#123; proxy_pass http:&#x2F;&#x2F;ip:port; break; &#125; root &#x2F;apps&#x2F;nginx&#x2F;long-cache; autoindex on; proxy_store on; proxy_store_access user:rw group:rw all:r; proxy_temp_path &#x2F;apps&#x2F;nginx&#x2F;long-temp; proxy_set_header x-real-ip $remote_addr; proxy_set_header x-forwarded-for $proxy_add_x_forwarded_for; &#125; 说明：这样就指定了一个文件目录为/apps/nginx/long-cache的地址，用来缓存所有为.html结尾的请求资源。$request_uri 如果携带参数(表明为非静态资源)，不访问本地缓存，从后端服务器读取资源；!-e $request_filename，如果为ture,则本地缓存没有该文件，走服务器访问资源。","categories":[{"name":"nginx","slug":"nginx","permalink":"https://sillybilly-share.top/categories/nginx/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://sillybilly-share.top/tags/nginx/"},{"name":"cache","slug":"cache","permalink":"https://sillybilly-share.top/tags/cache/"}]},{"title":"基于amazonaws s3的分片上传(前后端实现)","slug":"基于amazonaws-s3的分片上传-前后端实现","date":"2020-04-08T12:56:35.000Z","updated":"2022-11-24T01:35:09.630Z","comments":true,"path":"基于amazonaws-s3的分片上传-前后端实现.html","link":"","permalink":"https://sillybilly-share.top/%E5%9F%BA%E4%BA%8Eamazonaws-s3%E7%9A%84%E5%88%86%E7%89%87%E4%B8%8A%E4%BC%A0-%E5%89%8D%E5%90%8E%E7%AB%AF%E5%AE%9E%E7%8E%B0.html","excerpt":"前提s3对象存储在单个操作上文件上传的最大值为5个G，所以对于大文件的上传肯定需要使用分片功能。使用分段上传可提供以下优势：1、提高吞吐量 – 可以并行上传分段以提高吞吐量。2、从任何网络问题中快速恢复 - 由于网络原因导致的上传失败，分段的操作可以避免文件再次全量上传，提高上传效率。3、暂停和恢复对象上传 – 启动分段上传后，在一段时间内逐步上传对象分段，不存在过期期限，所以可以显式地完成或中止分段上传。4、在不知道对象大小的情况前就可以开始上传 – 您可以在创建对象时将其上传。s3推荐启动分段上传的阈值为100M,可以根据业务需求自己定义。基本的对象操作官网示例demo:s3开发人员指南。","text":"前提s3对象存储在单个操作上文件上传的最大值为5个G，所以对于大文件的上传肯定需要使用分片功能。使用分段上传可提供以下优势：1、提高吞吐量 – 可以并行上传分段以提高吞吐量。2、从任何网络问题中快速恢复 - 由于网络原因导致的上传失败，分段的操作可以避免文件再次全量上传，提高上传效率。3、暂停和恢复对象上传 – 启动分段上传后，在一段时间内逐步上传对象分段，不存在过期期限，所以可以显式地完成或中止分段上传。4、在不知道对象大小的情况前就可以开始上传 – 您可以在创建对象时将其上传。s3推荐启动分段上传的阈值为100M,可以根据业务需求自己定义。基本的对象操作官网示例demo:s3开发人员指南。 分片上传实现准备新建一个springboot+thymeleaf工程，并添加相关jar包 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;3.9&lt;/version&gt;&lt;/dependency&gt; &lt;!-- AmazonS3对象存储 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.amazonaws&lt;/groupId&gt; &lt;artifactId&gt;aws-java-sdk-s3&lt;/artifactId&gt; &lt;version&gt;1.11.592&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.amazonaws&lt;/groupId&gt; &lt;artifactId&gt;aws-java-sdk-core&lt;/artifactId&gt; &lt;version&gt;1.11.592&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;27.0.1-jre&lt;/version&gt; &lt;!-- thymeleaf --&gt;&lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;1.4&lt;/version&gt;&lt;/dependency&gt; yml文件配置thymeleaf和开放字节上传限制 123456789101112131415server: port: 8090spring: thymeleaf: prefix: classpath:&#x2F;templates&#x2F; suffix: .html devtools: restart: #需要实时更新的目录 additional-paths: resources&#x2F;**,static&#x2F;**,templates&#x2F;** servlet: multipart: max-file-size: 4096MB max-request-size: 4096MB 后端接口实现定义一个s3接口类,预定义出一些方法用于Controller层调用 12345678910111213141516171819202122public interface AwsS3Service &#123; /** * 大文件分片上传 max-5TB 每段最小5MB * 建议100MB以上文件上传启动分段 * 在上传期间更改分段的大小或者事先不知道上传的数据大小的情况下用此方法 * @param id 文件id * @param key 桶键 * @param file 分片文件内容 * @param chunks 总分片数 * @param chunk 当前分片 */ void uploadAppenderFile(String id,String key, MultipartFile file,int chunks,int chunk); /** * 默认建议使用此方法 * @param key * @param stream 上传源文件 * @return */ boolean uploadByTransferManager(String key,InputStream stream,long length);&#125; s3有两种分段上传方式，一种是高级API即第二种实现(这里可以直接去操作指南看)，另一种是低级API即第一种实现，这里用第一种方式，因为数据的分片是前端来做。 接口实现的处理（第一种） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@Service@Slf4jpublic class AwsS3ServiceImpl implements AwsS3Service &#123; @Autowired private AmazonawsS3utils amazonawsS3utils; @Override public void uploadAppenderFile(String id, String key, MultipartFile file, int chunks, int chunk) &#123; AmazonS3 amazonS3 = amazonawsS3utils.getConnection(); String bucketName = amazonawsS3utils.getBucketName(); String uploadId = PartETagsCacheUtils.getUploadId(id,bucketName,key,amazonS3); try &#123; BufferedInputStream stream = new BufferedInputStream(file.getInputStream()); long partSize = file.getSize(); //上传请求参数设置 必需参数：BucketName，Key，UploadId，PartNumber，PartSize(partNumber between 1 and 10,000) UploadPartRequest partRequest = new UploadPartRequest() .withBucketName(bucketName) .withKey(key) .withUploadId(uploadId) .withPartNumber(chunk + 1) .withPartSize(partSize) .withInputStream(stream); //配置最大缓冲区大小 partRequest.getRequestClientOptions().setReadLimit(1024 * 1024 * 100); //partRequest.setGeneralProgressListener(progressEvent -&gt; log.info(\"data upload:&#123;&#125;\", progressEvent.getBytesTransferred())); UploadPartResult uploadResult = amazonS3.uploadPart(partRequest); PartETagsCacheUtils.addPartETag(id, uploadResult.getPartETag()); List&lt;PartETag&gt; partETags = PartETagsCacheUtils.getPartETags(id); //完成上传 if (partETags.size == chunks)&#123; CompleteMultipartUploadRequest compRequest = new CompleteMultipartUploadRequest(bucketName, key, uploadId, partETags); amazonS3.completeMultipartUpload(compRequest); PartETagsCacheUtils.cleanCache(id); &#125; &#125; catch (IOException e) &#123; log.info(\"IO异常,&#123;&#125;\", e.getMessage()); PartETagsCacheUtils.cleanCache(id); &#125; catch (SdkClientException e) &#123; //终止分段上传 amazonS3.abortMultipartUpload(new AbortMultipartUploadRequest(bucketName, key, uploadId)); log.info(\"Failed to upload, &#123;&#125;\", e.getMessage()); PartETagsCacheUtils.cleanCache(id); &#125; &#125;&#125; AmazonawsS3utils类可以参考之前的内容（差不多）(api验证),PartETagsCacheUtils类用于缓存分段上传的PartETag以及不同文件上传的uploadId。简单的实现如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * @Author: sillybilly * @Date: 2020/4/8 16:17 * @Description: 分段上传信息本地缓存 * @Version: 1.0 */public class PartETagsCacheUtils &#123; //创建一个列表保存某个文件所有分段的 PartETag private static Map&lt;String, List&lt;PartETag&gt;&gt; partETagList = new ConcurrentHashMap&lt;&gt;(); //分段上传&lt;文件id，uploadId&gt; private static Map&lt;String,String&gt; uploadIds = new ConcurrentHashMap&lt;&gt;(); public static void addPartETag(String id, PartETag partETag) &#123; List&lt;PartETag&gt; partETags = partETagList.get(id); if (null == partETags)&#123; partETags = new ArrayList&lt;&gt;(); &#125; partETags.add(partETag); partETagList.put(id,partETags); &#125; public static List&lt;PartETag&gt; getPartETags(String id)&#123; return partETagList.get(id); &#125; public static void cleanCache(String id)&#123; partETagList.remove(id); uploadIds.remove(id); &#125; public static synchronized String getUploadId(String id, String bucketName, String key, AmazonS3 amazonS3)&#123; String uploadId = uploadIds.get(id); if (null == uploadId)&#123; InitiateMultipartUploadRequest initRequest = new InitiateMultipartUploadRequest(bucketName, key) .withCannedACL(CannedAccessControlList.PublicRead); //启动分段上传，并返回包含上传ID的InitiateMultipartUploadResult InitiateMultipartUploadResult initResult = amazonS3.initiateMultipartUpload(initRequest); uploadId = initResult.getUploadId(); uploadIds.put(id,uploadId); &#125; return uploadId; &#125;&#125; 然后就可以用Controller层去调用该方法了。 12345678910111213141516171819202122@Slf4j@RestControllerpublic class AwsS3Controller &#123; @Autowired private AwsS3Service awsS3Service; @PostMapping(value = \"/uploadAppenderFile\") public void uploadAppenderFile(DataUploadVO dataUploadVO) throws IOException&#123; log.info(\"开启分段信息：&#123;&#125;\",dataUploadVO.toString()); String key = dataUploadVO.getName(); if (null==dataUploadVO.getChunks())&#123; //todo 不走分片 &#125; int chunks = Integer.parseInt(dataUploadVO.getChunks()); int chunk = Integer.parseInt(dataUploadVO.getChunk()); MultipartFile file = dataUploadVO.getFile(); String id = dataUploadVO.getId(); awsS3Service.uploadAppenderFile(id,key,file,chunks,chunk); &#125;&#125; DataUploadVO封装了前端发送的数据： 12345678910111213141516171819202122@Datapublic class DataUploadVO &#123; //当前文件id 文件ID，如WU_FILE_1，后面数字代表当前传的是第几个文件,后续使用此ID来创建临时目录，将属于该文件ID的所有分片全部放在同一个文件夹中 String id; //当前所传文件的分片总数 String chunks; //当前所传文件的当前分片数 String chunk; //文件名称，如07-中文分词器和业务域的配置.avi String name; //当前所传分片数据 MultipartFile file; //* 可选参数 //* guid 可省略；每个文件有自己唯一的guid，后续测试中发现，每个分片也有自己的guid，所以不能使用guid来确定分片属于哪个文件。 //* md5value 文件的MD5值 //* type 文件类型，可选，在这里没有用到 //* lastModifiedDate 文件修改日期，可选，在这里没有用到 //* size 当前所传分片大小，可选，没有用到&#125; 当然100兆以下的文件不走分片，chunks为null,可以直接调用putObject上传数据。 前端实现这里主要用前端将数据包分片传给我们的oss服务器，所以我选择了百度的webupload插件，地址：webupload官网，我们可以使用staticfile提供的cdn版本，或者下载源码放在自己的项目中，这里我们直接下载放入自己的项目中。然后根据thymeleaf模板的方式引入资源。upload.html: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218&lt;!DOCTYPE html&gt;&lt;html lang=\"en\" xmlns:th=\"http://www.thymeleaf.org\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;!--引入CSS--&gt; &lt;link rel=\"stylesheet\" type=\"text/css\" th:href=\"@&#123;css/webuploader.css&#125;\"&gt; &lt;!--引入JS--&gt; &lt;script src=\"https://code.jquery.com/jquery-3.1.1.min.js\"&gt;&lt;/script&gt; &lt;script type=\"text/javascript\" th:src=\"@&#123;js/webuploader.js&#125;\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;!-- Main content --&gt;&lt;section class=\"content\"&gt; &lt;div class=\"container\" style=\"margin-top: 20px\"&gt; &lt;div class=\"alert alert-info\"&gt;&lt;h1&gt;大文件上传&lt;/h1&gt;&lt;/div&gt; &lt;/div&gt; &lt;div class=\"container\" style=\"margin-top: 50px\"&gt; &lt;div id=\"uploader\" class=\"container\"&gt; &lt;div class=\"container\"&gt; &lt;div id=\"fileList\" class=\"uploader-list\"&gt;&lt;/div&gt; &lt;!--存放文件的容器--&gt; &lt;/div&gt; &lt;div class=\"btns container\"&gt; &lt;div id=\"picker\" class=\"webuploader-container\" style=\"float: left; margin-right: 10px\"&gt; &lt;div&gt; 选择文件 &lt;input type=\"file\" name=\"file\" class=\"webuploader-element-invisible\" multiple=\"multiple\"&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=\"UploadBtn\" class=\"webuploader-pick\" style=\"float: left; margin-right: 10px\"&gt;开始上传&lt;/div&gt; &lt;div id=\"StopBtn\" class=\"webuploader-pick\" style=\"float: left; margin-right: 10px\" status=\"suspend\"&gt;暂停上传&lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/section&gt;&lt;script type=\"text/javascript\"&gt; $(function () &#123; $list = $('#fileList'); var flie_count = 0; var uploader = WebUploader.create(&#123; //设置选完文件后是否自动上传 auto: false, //swf文件路径 swf: 'js/Uploader.swf', // 文件接收服务端。 server: '/uploadAppenderFile', // 选择文件的按钮。可选。 // 内部根据当前运行是创建，可能是input元素，也可能是flash. pick: '#picker', chunked: true, //开启分块上传 chunkSize: 10 * 1024 * 1024, chunkRetry: 3,//网络问题上传失败后重试次数 threads: 5, //上传并发数 //fileNumLimit :1, fileSizeLimit: 5000 * 1024 * 1024,//总文件大小 fileSingleSizeLimit: 3000 * 1024 * 1024, //单个文件最大值 resize: false//不压缩 //选择文件类型 //accept: &#123; // title: 'Video', // extensions: 'mp4,avi', // mimeTypes: 'video/*' //&#125; &#125;); // 当有文件被添加进队列的时候 uploader.on('fileQueued', function (file) &#123; $list.append('&lt;div id=\"' + file.id + '\" class=\"item\"&gt;' + '&lt;h4 class=\"info\"&gt;' + file.name + '&lt;button type=\"button\" fileId=\"' + file.id + '\" class=\"btn btn-danger btn-delete\"&gt;&lt;span class=\"glyphicon glyphicon-trash\"&gt;取消&lt;/span&gt;&lt;/button&gt;&lt;/h4&gt;' + '&lt;p class=\"state\"&gt;正在计算文件MD5...请等待计算完毕后再点击上传！&lt;/p&gt;' + '&lt;/div&gt;'); console.info(\"id=file_\"+flie_count); flie_count++; //删除要上传的文件 //每次添加文件都给btn-delete绑定删除方法 $(\".btn-delete\").click(function () &#123; //console.log($(this).attr(\"fileId\"));//拿到文件id uploader.removeFile(uploader.getFile($(this).attr(\"fileId\"), true)); $(this).parent().parent().fadeOut();//视觉上消失了 $(this).parent().parent().remove();//DOM上删除了 &#125;); //uploader.options.formData.guid = WebUploader.guid();//每个文件都附带一个guid，以在服务端确定哪些文件块本来是一个 //console.info(\"guid= \"+WebUploader.guid()); //md5计算 uploader.md5File(file) .progress(function(percentage) &#123; console.log('Percentage:', percentage); &#125;) // 完成 .then(function (fileMd5) &#123; // 完成 var end = +new Date(); console.log(\"before-send-file preupload: file.size=\"+file.size+\" file.md5=\"+fileMd5); file.wholeMd5 = fileMd5;//获取到了md5 //uploader.options.formData.md5value = file.wholeMd5;//每个文件都附带一个md5，便于实现秒传 $('#' + file.id).find('p.state').text('MD5计算完毕，可以点击上传了'); console.info(\"MD5=\"+fileMd5); &#125;); &#125;); // 文件上传过程中创建进度条实时显示。 uploader.on('uploadProgress', function (file, percentage) &#123; var $li = $('#' + file.id), $percent = $li.find('.progress .progress-bar'); // 避免重复创建 if (!$percent.length) &#123; $percent = $('&lt;div class=\"progress progress-striped active\"&gt;' + '&lt;div class=\"progress-bar\" role=\"progressbar\" style=\"width: 0%\"&gt;' + '&lt;/div&gt;' + '&lt;/div&gt;').appendTo($li).find('.progress-bar'); &#125; $li.find('p.state').text('上传中'); $percent.css('width', percentage * 100 + '%'); &#125;); //发送前填充数据 uploader.on( 'uploadBeforeSend', function( block, data ) &#123; // block为分块数据。 // file为分块对应的file对象。 var file = block.file; var fileMd5 = file.wholeMd5; // 修改data可以控制发送哪些携带数据。 console.info(\"fileName= \"+file.name+\" fileMd5= \"+fileMd5+\" fileId= \"+file.id); console.info(\"input file= \"+ flie_count); // 将存在file对象中的md5数据携带发送过去。 data.md5value = fileMd5;//md5 data.fileName_ = $(\"#s_\"+file.id).val(); console.log(\"fileName_: \"+data.fileName_); // 删除其他数据 // delete data.key; if(block.chunks&gt;1)&#123; //文件大于chunksize 分片上传 data.isChunked = true; console.info(\"data.isChunked= \"+data.isChunked); &#125;else&#123; data.isChunked = false; console.info(\"data.isChunked=\"+data.isChunked); &#125; &#125;); uploader.on('uploadSuccess', function (file) &#123; $('#' + file.id).find('p.state').text('已上传'); $('#' + file.id).find(\".progress\").find(\".progress-bar\").attr(\"class\", \"progress-bar progress-bar-success\"); $('#' + file.id).find(\".info\").find('.btn').fadeOut('slow');//上传完后删除\"删除\"按钮 $('#StopBtn').fadeOut('slow'); &#125;); uploader.on('uploadError', function (file) &#123; $('#' + file.id).find('p.state').text('上传出错'); //上传出错后进度条变红 $('#' + file.id).find(\".progress\").find(\".progress-bar\").attr(\"class\", \"progress-bar progress-bar-danger\"); //添加重试按钮 //为了防止重复添加重试按钮，做一个判断 //var retrybutton = $('#' + file.id).find(\".btn-retry\"); //$('#' + file.id) if ($('#' + file.id).find(\".btn-retry\").length &lt; 1) &#123; var btn = $('&lt;button type=\"button\" fileid=\"' + file.id + '\" class=\"btn btn-success btn-retry\"&gt;&lt;span class=\"glyphicon glyphicon-refresh\"&gt;取消&lt;/span&gt;&lt;/button&gt;'); $('#' + file.id).find(\".info\").append(btn);//.find(\".btn-danger\") &#125; $(\".btn-retry\").click(function () &#123; //console.log($(this).attr(\"fileId\"));//拿到文件id uploader.retry(uploader.getFile($(this).attr(\"fileId\"))); &#125;); &#125;); uploader.on('uploadComplete', function (file) &#123;//上传完成后回调 //$('#' + file.id).find('.progress').fadeOut();//上传完删除进度条 //$('#' + file.id + 'btn').fadeOut('slow')//上传完后删除\"删除\"按钮 &#125;); uploader.on('uploadFinished', function () &#123; //上传完后的回调方法 //alert(\"所有文件上传完毕\"); //提交表单 &#125;); $(\"#UploadBtn\").click(function () &#123; uploader.upload();//上传 &#125;); $(\"#StopBtn\").click(function () &#123; console.log($('#StopBtn').attr(\"status\")); var status = $('#StopBtn').attr(\"status\"); if (status == \"suspend\") &#123; console.log(\"当前按钮是暂停，即将变为继续\"); $(\"#StopBtn\").html(\"继续上传\"); $(\"#StopBtn\").attr(\"status\", \"continuous\"); console.log(\"当前所有文件===\"+uploader.getFiles()); console.log(\"=============暂停上传==============\"); uploader.stop(true); console.log(\"=============所有当前暂停的文件=============\"); console.log(uploader.getFiles(\"interrupt\")); &#125; else &#123; console.log(\"当前按钮是继续，即将变为暂停\"); $(\"#StopBtn\").html(\"暂停上传\"); $(\"#StopBtn\").attr(\"status\", \"suspend\"); console.log(\"===============所有当前暂停的文件==============\"); console.log(uploader.getFiles(\"interrupt\")); uploader.upload(uploader.getFiles(\"interrupt\")); &#125; &#125;); uploader.on('uploadAccept', function (file, response) &#123; if (response._raw === '&#123;\"error\":true&#125;') &#123; return false; &#125; &#125;); &#125;);&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 这里需要注意官网提供的css文件，没有下载进度条的样式，需要自己写入，额外添加的样式： 1234567891011121314151617181920212223242526272829303132333435.progress &#123; height: 20px; margin-bottom: 20px; overflow: hidden; background-color: #f5f5f5; border-radius: 4px; -webkit-box-shadow: inset 0 1px 2px rgba(0,0,0,0.1); box-shadow: inset 0 1px 2px rgba(0,0,0,0.1);&#125;.progress.active .progress-bar &#123; -webkit-animation: progress-bar-stripes 2s linear infinite; animation: progress-bar-stripes 2s linear infinite;&#125;.progress-striped .progress-bar &#123; background-image: linear-gradient(45deg,rgba(255,255,255,0.15) 25%,transparent 25%,transparent 50%,rgba(255,255,255,0.15) 50%,rgba(255,255,255,0.15) 75%,transparent 75%,transparent); background-size: 40px 40px;&#125;.progress-bar &#123; background-image: -webkit-linear-gradient(top,#428bca 0,#3071a9 100%); background-image: linear-gradient(to bottom,#428bca 0,#3071a9 100%); background-repeat: repeat-x; filter: progid:DXImageTransform.Microsoft.gradient(startColorstr=’#ff428bca’,endColorstr=’#ff3071a9’,GradientType=0);&#125;.progress-bar &#123; float: left; height: 100%; font-size: 12px; line-height: 20px; color: #fff; text-align: center; background-color: #428bca; box-shadow: inset 0 -1px 0 rgba(0,0,0,0.15); transition: width .6s ease;&#125; 测试最后，我们就可以启动项目输入ip+端口进行测试了,截取某段效果图如下：","categories":[{"name":"java","slug":"java","permalink":"https://sillybilly-share.top/categories/java/"},{"name":"ceph","slug":"ceph","permalink":"https://sillybilly-share.top/categories/ceph/"},{"name":"oss","slug":"ceph/oss","permalink":"https://sillybilly-share.top/categories/ceph/oss/"},{"name":"amazonaws s3","slug":"amazonaws-s3","permalink":"https://sillybilly-share.top/categories/amazonaws-s3/"}],"tags":[{"name":"java","slug":"java","permalink":"https://sillybilly-share.top/tags/java/"},{"name":"ceph","slug":"ceph","permalink":"https://sillybilly-share.top/tags/ceph/"},{"name":"oss","slug":"oss","permalink":"https://sillybilly-share.top/tags/oss/"}]},{"title":"netty ByteBuf使用与释放","slug":"netty-ByteBuf使用与释放","date":"2020-04-05T02:54:08.000Z","updated":"2022-11-24T01:35:09.628Z","comments":true,"path":"netty-ByteBuf使用与释放.html","link":"","permalink":"https://sillybilly-share.top/netty-ByteBuf%E4%BD%BF%E7%94%A8%E4%B8%8E%E9%87%8A%E6%94%BE.html","excerpt":"前提在了解netty的byteBuf方法之前，我们需要对JVM的内存分配有一定的认知。这里引用网上的一张JVM内存模型图:","text":"前提在了解netty的byteBuf方法之前，我们需要对JVM的内存分配有一定的认知。这里引用网上的一张JVM内存模型图: JVM的内存分配机制大概如下： 123451、方法区（Method Area）：存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码数据等。（即持久代），回收目标主要是常量池的回收和已加载类的卸载，各线程共享2、堆区（Heap）：java内存最大的一块，所有对象实例、数组都存放在java堆（new出来的东西），GC回收最频繁的地方，线程共享3、虚拟机栈（VM Stack）：存放基本数据类型、对象的引用、方法出口等，线程私有（定义了两种异常类型StackOverFlowError(栈溢出)和OutOfMemoryError（内存溢出））4、本地方法栈（Native Method Stack）：和虚拟栈相似，只不过它服务于Native方法，线程私有5、程序计数器（Program Counter Register）：当前线程所执行的字节码的行号指示器，用于记录正在执行的虚拟机字节指令地址，线程私有（此内存区是唯一不会抛出OutOfMemoryError的区域） netty-ByteBuf解析netty提供内存泄漏的检测机制1234禁用（DISABLED） - 完全禁止泄露检测，省点消耗。简单（SIMPLE） - 默认等级，告诉我们取样的1%的ByteBuf是否发生了泄露，但总共一次只打印一次，看不到就没有了。高级（ADVANCED） - 告诉我们取样的1%的ByteBuf发生泄露的地方。每种类型的泄漏（创建的地方与访问路径一致）只打印一次。对性能有影响。偏执（PARANOID） - 跟高级选项类似，但此选项检测所有ByteBuf，而不仅仅是取样的那1%。对性能有绝大的影响。 一般我们可以使用-D参数，把防漏等级从默认的simple升到advanced，就能具体看到被泄漏的ByteBuf被创建和访问的地方，而在项目中问题定位到ByteBuf对象的释放上，在解决内存溢出之前，我们需要了解netty中ByteBuf对象的内存分配与释放机制。从netty4之后，ByteBuf对象的生命周期由它们的引用计数（reference counts）管理，而不是由垃圾收集器（garbage collector）管理了。ByteBuf是最值得注意的，它使用了引用计数来改进分配内存和释放内存的性能。 何为引用计数器？对于ByteBuf来说，分为池化（Pooled）和非池化（Unpooled）两种分配内存的方式。其中UnpooledHeapByteBuf 底下的byte[]能够依赖JVM GC自然回收，而UnpooledDirectByteBuf底下是DirectByteBuffer，除了等JVM GC，最好也能主动进行回收；而PooledHeapByteBuf 和 PooledDirectByteBuf，则必须要主动将用完的byte[]/ByteBuffer放回池里，否则内存就要爆掉。所以，Netty ByteBuf需要在JVM的GC机制之外，有自己的引用计数器和回收过程。这种感觉就是又回到大学里写c++的时候，自己malloc对象要自己free。 但又并不完全一样,具体体现在： 12345所有ByteBuf的引用计数器初始值为1。调用release()，将计数器减1，等于零时， deallocate()被调用，各种回收。调用retain()，将计数器加1，即使ByteBuf在别的地方被人release()了，在本Class没喊cut之前，不要把它释放掉。由duplicate(), slice()和order()所衍生的ByteBuf，与原对象共享底下的buffer，也共享引用计数器，所以它们经常需要调用retain()来显示自己的存在。当引用计数器为0，底下的buffer已被回收，即使ByteBuf对象还在，对它的各种访问操作都会抛出异常 ByteBuf之slice()/retainedSlice()ByteBuf.duplicate(), ByteBuf.slice()和ByteBuf.order(ByteOrder)创建了子缓冲，这些缓存共享了它们的父缓冲（parent buffer）的一部分内存。子缓冲没有自己的引用计数，而是共享父缓冲的引用计数。注意父缓冲和它的子缓冲共享同样的引用计数，当创建子缓冲时并不会增加对象的引用计数。因此，如果你要传递（pass）一个子缓冲给你的程序中的其他组件的话，你得先调用retain()。 在这里，主要讲下我对于slice()和retainedSlice()方法的粗略理解。我们现在都知道，每当我们创建一个ByteBuf对象时，当前的ByteBuf对象的引用计数器初始为1。而当我们调用slice()方法时，子缓冲和父缓冲共享同一块内存，但它们的读写指针是不共享的，所以我们经常用这个方法来copy一份数据出来（算是浅拷贝的一种但读写指针互不影响？我不知道这么理解对不对）。那么retainedSlice()是否为slice()+retained()方法结合呢？JPA中对这两个方法解释如下： retainedSlice: 1Returns a retained slice of this buffer&#39;s readable bytes. Modifying the content of the returned buffer or this buffer affects each other&#39;s content while they maintain separate indexes and marks. This method is identical to buf.slice(buf.readerIndex(), buf.readableBytes()). This method does not modify readerIndex or writerIndex of this buffer. slice 1Returns a slice of this buffer&#39;s readable bytes. Modifying the content of the returned buffer or this buffer affects each other&#39;s content while they maintain separate indexes and marks. This method is identical to buf.slice(buf.readerIndex(), buf.readableBytes()). This method does not modify readerIndex or writerIndex of this buffer. 其实看不出retainedSlice与slice+retained的方法有什么区别，然而这和ByteBuf对象是否池化有很大关系。在非池化的ByteBuf中，retainedSlice()应该和slice()一样，拷贝的子缓冲和父缓冲共享同一个引用计数，不过就是多调用了retain()方法，使其引用计数器+1了而已；而在池化的ByteBuf中，retainedSlice()得到子缓冲他对象初始refCnt都是1，这里无论之前的父缓冲refCnf是多少。并且可以通过测试得出，它们的引用计数器各自独立互不影响，除了一个特殊情况（子缓冲refCnt=0，即被释放掉了，那么父缓冲的计数器才会-1） 可以用代码验证一下： 非池化验证： 123456ByteBuf byteBuf = Unpooled.copiedBuffer(new byte[6]);ByteBuf copyBuf = byteBuf.retainedSlice(0,byteBuf.readableBytes());if (log.isDebugEnabled())&#123; log.debug(\"byteBuf refCnt,&#123;&#125;\",byteBuf.refCnt()); log.debug(\"copyBuf refCnt,&#123;&#125;\",copyBuf.refCnt());&#125; 结果： 池化验证： 1234567PooledByteBufAllocator allocator = PooledByteBufAllocator.DEFAULT;ByteBuf byteBuf = allocator.directBuffer(10);ByteBuf copyBuf = byteBuf.retainedSlice(0,byteBuf.readableBytes());if (log.isDebugEnabled())&#123; log.debug(\"byteBuf refCnt,&#123;&#125;\",byteBuf.refCnt()); log.debug(\"copyBuf refCnt,&#123;&#125;\",copyBuf.refCnt());&#125; 结果： 最重要的是，我们在netty定义的handler中传递的ByteBuf都是池化的，所以对于此对象的复制与释放就需要格外注意了。 存在的内存溢出问题回到项目中内存溢出的问题，大部分存在调用slice(),retainedSlice()的地方，大都是集中在继承ByteToMessageDecoder类的decode粘包解包逻辑里面。这个解包处理是自定义的，所以我去翻看了一下netty自带的解包器的处理，大概看个最简单的例子：FixedLengthFrameDecoder（它本身也是继承的ByteToMessageDecoder） 可以看到该解包器用于处理定长的数据报文,in.readableBytes()大于数据解包长度时，我们就读取数据,并通过out.add()将解出的数据包传给下一个handler。而这里调用了readRetainedSlice()方法。read使其读指针右移我们不做讨论，既然它调用了retainedSlice()方法，那么in这个ByteBuf引用计数器必定进行了+1操作，所以我们需要在下一个handler中释放掉这个引用的子缓冲，这样在handler中的in的引用计数器才会保持在1的状态。所以我们会看到Netty在Handler链的最末补了一个TailHandler，如果此时消息仍然是ReferenceCounted类型就会被release掉。一般而言，我们会在下一个handler中继承SimpleChannelHandler类，该类可以自动释放decode方法传进来解包完的msg对象。如果不然，需要我们在业务处理完，手动调用ReferenceCountUtil.release(msg);这样保证资源的释放回收，减少内存溢出的可能。 项目中的decode解包完是通过netty直接发给其他服务的，所以并不会有下一个handler去释放资源，所有的资源都要在当前class用完释放掉。起初的做法是将所有用到retainedSlice()地方都在最后释放掉，但似乎内存损耗并没有得到显著的遏止。 再次排查，发现slice()这个方法不太好，虽然slice()方法引用了父缓冲且并不会增加父缓冲的引用计数，所以这个方法用出来，其对象必然不能释放，否则父缓冲就被释放掉了（数据就没了）。再回过头来想想父缓冲是必不能释放的，那这些大量的子引用类型变量就一直存在着，在推到几千万条数据报文的时候，这些可恶的无法释放的变量是不是就是导致内存溢出的罪魁祸首？ 想到这里，我终于明白了为什么netty在自定义解包器的时候用retainedSlice去引用父类型，而不是用slice()方法。虽然slice()方法同样可以将解包结果推给下个handler（而且在下个handler并不需要继承SimpleChannelHandler，换句话说并不需要手动释放msg），但由于缓冲区中ByteBuf对象一直需要保持活跃用于数据传输，slice()方法产生的大量引用不被释放是不能忍受的。因此，每次调用slice()必然会去调用retain()，这样我们才可以去释放这个子引用，很明显简洁程度没有retainedSlice高。另外还是避免代码里出现大量这种深、浅拷贝的引用类型对象（特别还是JVM回收不了，需要手动释放的）。","categories":[{"name":"netty","slug":"netty","permalink":"https://sillybilly-share.top/categories/netty/"}],"tags":[{"name":"java","slug":"java","permalink":"https://sillybilly-share.top/tags/java/"},{"name":"netty","slug":"netty","permalink":"https://sillybilly-share.top/tags/netty/"},{"name":"JVM","slug":"JVM","permalink":"https://sillybilly-share.top/tags/JVM/"}]},{"title":"springcloudstream 集成kafka和rabbitmq","slug":"springcloudstream-集成kafka和rabbitmq","date":"2020-03-31T12:56:13.000Z","updated":"2022-11-24T01:35:09.629Z","comments":true,"path":"springcloudstream-集成kafka和rabbitmq.html","link":"","permalink":"https://sillybilly-share.top/springcloudstream-%E9%9B%86%E6%88%90kafka%E5%92%8Crabbitmq.html","excerpt":"前提业务中不同消息中间件的切换，需要修改大量的代码，增加了业务开发者的负担。所以我们需要寻求一种解决方案用来兼容多种消息中间件，springcloudstream就是一个很好的选择，它提供许多可以简化消息驱动微服务应用程序编写的抽象和原语，目前springcloudstream支持的binder有RabbitMQ、Apache Kafka、Amazon Kinesis、Google PubSub等。在这里用springcloudstream编写简单的demo同时集成kafka和rabbitmq,验证消息中间件的可用性。 准备创建一个springboot工程,并添加核心jar包: 1234567891011121314&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-kafka&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream&lt;/artifactId&gt;&lt;/dependency&gt;","text":"前提业务中不同消息中间件的切换，需要修改大量的代码，增加了业务开发者的负担。所以我们需要寻求一种解决方案用来兼容多种消息中间件，springcloudstream就是一个很好的选择，它提供许多可以简化消息驱动微服务应用程序编写的抽象和原语，目前springcloudstream支持的binder有RabbitMQ、Apache Kafka、Amazon Kinesis、Google PubSub等。在这里用springcloudstream编写简单的demo同时集成kafka和rabbitmq,验证消息中间件的可用性。 准备创建一个springboot工程,并添加核心jar包: 1234567891011121314&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-kafka&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream&lt;/artifactId&gt;&lt;/dependency&gt; 其他依赖 12345678910111213141516171819202122232425262728&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream-test-support&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Hoxton.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 代码实现yml配置配置文件是spingcloudstream的核心，这样有利于消息组件的变更。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556server: port: 18080spring: application: name: msg-integrate cloud: stream: bindings: mq_output: #自定义消息通道（默认output/input） binder: rabbit-demo #指定要连接binders中kafka或rabbitmq destination: mq-dest #kafka中的topic rabbit中的exchange content-type: text/plain #消息发送类型 json格式则为application/json mq_input: binder: rabbit-demo destination: mq-dest content-type: text/plain #消息接收类型 group: mq-cus #消息分组 防止多个实例下的重复消费 kafka_output: binder: kafka-demo destination: kafka-dest content_type: text/plain kafka_input: binder: kafka-demo destination: kafka-dest content_type: text/plain group: kafka-cus listener: concurrency: 3 #根据分区决定消费线程数 consumer: group-id: kafka-consumer enable-auto-commit: true auto-offset-reset: earliest #从提交的offset开始消费 max-poll-records: 1000 binders: kafka-demo: #kafka配置 type: kafka environment: spring: cloud: stream: kafka: binder: brokers: ip:port #集群以，分开 auto-add-partitions: true #根据需要自动创建新分区 auto-create-topics: true #自动创建主题 若为false且主题不存在 binder无法启动 min-partition-count: 1 #仅在设置autoCreateTopics或autoAddPartitions时有效 全局分区的最小个数 rabbit-demo: #rabbit配置 type: rabbit environment: spring: rabbitmq: addresses: ip port: 5672 username: admin password: admin binders为不同消息组件的配置，在自定义消息通道时可以指定配置的消息binder,具体说明标注于yml文件上。 自定义消息通道springcloudstream有默认通道（input,out）,而配置文件中的mq_output、mq_input、kafka_output、kafka_input为代码中自定义的消息通道 123456789101112131415161718/** * @Author: silly-billy * @Date: 2020/3/31 11:04 * @Version 1.0 */public interface KafkaChannel &#123; //kafka消息通道 String KAFKA_OUT_PUT = \"kafka_output\"; String KAFKA_IN_PUT = \"kafka_input\"; @Output(KAFKA_OUT_PUT) MessageChannel kafkaOutput(); @Input(KAFKA_IN_PUT) SubscribableChannel kafkaInput();&#125; 1234567891011121314151617/** * @Author: silly-billy * @Date: 2020/3/31 10:53 * @Version 1.0 */public interface MqChannel &#123; //rabbitmq 消息生产者通道 String MQ_OUT_PUT = \"mq_output\"; //消费者通道 String MQ_IN_PUT = \"mq_input\"; @Output(MQ_OUT_PUT) MessageChannel OutPut(); @Input(MQ_IN_PUT) SubscribableChannel InPut();&#125; 编写消息的生产者1234567891011121314151617181920212223/** * @Author: silly-billy * @Date: 2020/3/31 11:53 * @Version 1.0 */@EnableBinding(KafkaChannel.class)public class KafkaMsgProducer &#123; @Autowired private KafkaChannel source; /** * 发送一个Message到此频道。如果消息发送成功，则该方法返回true。 * 如果由于非致命原因而无法发送消息，则该方法返回false。 * 如果发生不可恢复的错误，该方法还可能引发RuntimeException * @param msg * @return */ public boolean sendMsg(String msg)&#123; return source.kafkaOutput().send(MessageBuilder.withPayload(msg).setHeader(\"flag\",\"test\").build()); &#125;&#125; 12345678910111213141516171819/** * @Author: silly-billy * @Date: 2020/3/31 11:08 * @Version 1.0 */@Slf4j@EnableBinding(MqChannel.class)public class MqMsgProducer &#123; @Autowired @Output(MqChannel.MQ_OUT_PUT) private MessageChannel channel; public boolean sendMsg(String msg) &#123; return channel.send(MessageBuilder.withPayload(msg).build()); &#125;&#125; 编写消息的消费者1234567891011121314/** * @Author: silly-billy * @Date: 2020/3/31 11:54 * @Version 1.0 */@Slf4j@EnableBinding(KafkaChannel.class)public class KafkaMsgConsumer &#123; @StreamListener(value = KafkaChannel.KAFKA_IN_PUT,condition = \"headers['flag']=='test'\") public void recieve0(Object payload)&#123; log.info(\"kafka receive &#123;&#125;\",payload); &#125;&#125; 1234567891011121314/** * @Author: silly-billy * @Date: 2020/3/31 11:15 * @Version 1.0 */@Slf4j@EnableBinding(MqChannel.class)public class MqMsgConsumer &#123; @StreamListener(MqChannel.MQ_IN_PUT) public void messageInPut(Message&lt;String&gt; message) &#123; log.info(\"rabbit receive：&#123;&#125;\",message.getPayload()); &#125;&#125; 到这里demo就已经完成了springcloudstream对kafka和rabbitmq消息收发的处理。整个工程只需要简单配置消息组件的可选项，并且完全屏蔽了它的底层实现，方便迁移。 测试为了验证程序的正确性，编写controller层相关代码，然后用postman进行测试。 1234567891011121314151617/** * @Author: silly-billy * @Date: 2020/3/31 11:17 * @Version 1.0 */@Controllerpublic class KafkaController &#123; @Autowired private KafkaMsgProducer kafkaMsgProducer; @GetMapping(value = \"/testKafka\") @ResponseBody public boolean testKafka(@RequestParam(\"msg\")String msg)&#123; return kafkaMsgProducer.sendMsg(msg); &#125;&#125; 1234567891011121314151617/** * @Author: silly-billy * @Date: 2020/3/31 11:16 * @Version 1.0 */@Controllerpublic class MqController &#123; @Autowired private MqMsgProducer mqMessageProducer; @GetMapping(value = \"/testMq\") @ResponseBody public boolean testMq(@RequestParam(\"msg\")String msg)&#123; return mqMessageProducer.sendMsg(msg); &#125;&#125; 调试结果kafka：rabbitmq：控制台输出：","categories":[{"name":"spring","slug":"spring","permalink":"https://sillybilly-share.top/categories/spring/"},{"name":"springcloudstream","slug":"spring/springcloudstream","permalink":"https://sillybilly-share.top/categories/spring/springcloudstream/"},{"name":"kafka","slug":"kafka","permalink":"https://sillybilly-share.top/categories/kafka/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://sillybilly-share.top/categories/rabbitmq/"}],"tags":[{"name":"java","slug":"java","permalink":"https://sillybilly-share.top/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://sillybilly-share.top/tags/spring/"},{"name":"springcloudstream","slug":"springcloudstream","permalink":"https://sillybilly-share.top/tags/springcloudstream/"},{"name":"kafka","slug":"kafka","permalink":"https://sillybilly-share.top/tags/kafka/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://sillybilly-share.top/tags/rabbitmq/"}]},{"title":"netty实现tcp和websocket之间的通信","slug":"netty实现tcp和websocket之间的通信","date":"2020-03-28T12:56:40.000Z","updated":"2022-11-24T01:35:09.628Z","comments":true,"path":"netty实现tcp和websocket之间的通信.html","link":"","permalink":"https://sillybilly-share.top/netty%E5%AE%9E%E7%8E%B0tcp%E5%92%8Cwebsocket%E4%B9%8B%E9%97%B4%E7%9A%84%E9%80%9A%E4%BF%A1.html","excerpt":"前提公司要求做一个中间层，用来实现pos机和web端之间的通信。由于年前做通信网关的时候，我接触了些netty的皮毛，深知netty在通信编程中的地位以及强大的api实现，所以这次我也准备用netty来实现此功能。 netty代码实现首先根据官网demo写一个主类用于监听pos机和web端的接入","text":"前提公司要求做一个中间层，用来实现pos机和web端之间的通信。由于年前做通信网关的时候，我接触了些netty的皮毛，深知netty在通信编程中的地位以及强大的api实现，所以这次我也准备用netty来实现此功能。 netty代码实现首先根据官网demo写一个主类用于监听pos机和web端的接入 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374/** * @Author: sillybilly * @Date: 2020/3/25 16:16 * @Description: 服务启动类 * @Version: 1.0 */public class SocketServer &#123; private int port; public SocketServer(int port) &#123; this.port = port; &#125; public void run() throws Exception &#123; EventLoopGroup bossGroup = new NioEventLoopGroup(); // (1)EpollEventLoop EventLoopGroup workerGroup = new NioEventLoopGroup();//EpollEventLoopGroup try &#123; ServerBootstrap b = new ServerBootstrap(); // (2) //开启内存泄漏调试 ResourceLeakDetector.setLevel(ResourceLeakDetector.Level.ADVANCED); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) // (3) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; // (4) @Override public void initChannel(SocketChannel ch) &#123; ChannelPipeline pipeline = ch.pipeline(); //pipeline.addLast(new ReadTimeoutHandler(60)); // 长时间不写会断 // ====================== 增加心跳支持 start ====================== // 针对客户端，如果在3分钟时没有向服务端发送读写心跳(ALL)，则主动断开 // 如果是读空闲或者写空闲，不处理 pipeline.addLast(new IdleStateHandler(NETTY_READ_TIMEOUT, NETTY_WRITE_TIMEOUT, NETTY_ALL_TIMEOUT)); // 自定义的空闲状态检测 //判断是websocket 还是普通socket //如果是websocket 则添加HttpServerCodec()等 否则添加new ProtobufDecoder（）等 pipeline.addLast(new SocketChooseHandler()); &#125; &#125;) .option(ChannelOption.SO_BACKLOG, 128) // (5) .childOption(ChannelOption.SO_KEEPALIVE, true); // (6) //如果需要绑定多个端口 保留 //List&lt;ChannelFuture&gt; futures = new ArrayList&lt;&gt;(); //futures.add(b.bind(8080)); //futures.add(b.bind(8081)); //for (ChannelFuture f : futures) &#123; // f.channel().closeFuture().sync(); //&#125; // 绑定端口，开始接收进来的连接 ChannelFuture f = b.bind(port).sync(); // (7) System.out.println(\"Server start listen at \" + port ); // 等待服务器 socket 关闭 。 // 在这个例子中，这不会发生，但你可以优雅地关闭你的服务器。 f.channel().closeFuture().sync(); &#125; finally &#123; workerGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); &#125; &#125; public static void main(String[] args) throws Exception &#123; int port; if (args.length &gt; 0) &#123; port = Integer.parseInt(args[0]); &#125; else &#123; port = 8080; &#125; new SocketServer(port).run(); &#125;&#125; NETTY_READ_TIMEOUT, NETTY_WRITE_TIMEOUT, NETTY_ALL_TIMEOUT是读写超时时间,可以根据需要自行设置。SocketChooseHandler是自己定义的handler处理类，主要用来区分不同的通信协议。下面是SocketChooseHandler代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * @Author: sillybilly * @Date: 2020/3/25 16:15 * @Description: 区分tcpsocket和websocket * @Version: 1.0 */@Slf4jpublic class SocketChooseHandler extends ByteToMessageDecoder &#123; /** * 默认暗号长度为23(随便取吧) */ private static final int MAX_LENGTH = 23; /** * WebSocket握手的协议前缀 */ private static final String WEBSOCKET_PREFIX = \"GET /\"; private PipelineAdd pipelineAdd = new PipelineAdd(); @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception &#123; String protocol = getBufStart(in); if (protocol.startsWith(WEBSOCKET_PREFIX)) &#123; //对于 webSocket ，不设置超时断开 ctx.pipeline().remove(IdleStateHandler.class); pipelineAdd.websocketAdd(ctx); &#125;else &#123; ByteBuf buf = Unpooled.copiedBuffer(\"$$\".getBytes()); ctx.pipeline().addLast(new DelimiterBasedFrameDecoder(1024, buf)); ctx.pipeline().addLast(new StringDecoder()); ctx.pipeline().addLast(new StringEncoder()); ctx.pipeline().addLast(new ConnectorIdleState()); ctx.pipeline().addLast(\"devicehandler\",new DeviceServerHandler()); &#125; in.resetReaderIndex(); ctx.pipeline().remove(this.getClass()); &#125; private String getBufStart(ByteBuf in) &#123; int length = in.readableBytes(); if (length &gt; MAX_LENGTH) &#123; length = MAX_LENGTH; &#125; // 标记读位置 in.markReaderIndex(); byte[] content = new byte[length]; in.readBytes(content); return new String(content); &#125; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; log.info(\"&#123;&#125;,已上线\",ctx.channel()); &#125;&#125; 因为websocket协议请求头会带上’GET /‘标志，所以通过getBufStart方法把tcp和web端的消息做个区分，不同的协议走不同的handler处理类。这里的DelimiterBasedFrameDecoder处理粘包，因为我们的消息格式设计的很简单，消息类型会以”$$“结尾，所以这里用netty自带的解析器就可以了。 websocket处理netty有相关处理websocket握手协议的api,当然这也是我选择用netty作为技术栈的原因。通过上文的pipelineAdd.websocketAdd(ctx)处理websocket协议，websocketAdd的方法是这样的： 1234567891011121314151617181920212223242526272829/** * @Author: sillybilly * @Date: 2020/3/25 16:12 * @Description: websoceket协议添加请求头处理handler * @Version: 1.0 */@Slf4jpublic class PipelineAdd &#123; public void websocketAdd(ChannelHandlerContext ctx) &#123; // HttpServerCodec：将请求和应答消息解码为HTTP消息 ctx.pipeline().addLast(\"http-codec\",new HttpServerCodec()); // HttpObjectAggregator：将HTTP消息的多个部分合成一条完整的HTTP消息 ctx.pipeline().addLast(\"aggregator\",new HttpObjectAggregator(65535)); // ChunkedWriteHandler：向客户端发送HTML5文件,文件过大会将内存撑爆 ctx.pipeline().addLast(\"http-chunked\",new ChunkedWriteHandler()); ctx.pipeline().addLast(\"WebSocketAggregator\",new WebSocketFrameAggregator(65535)); //解析uri 带?参数 ctx.pipeline().addLast(\"url-explained\",new CustomUrlHandler()); //用于处理websocket, /ws为访问websocket时的uri ctx.pipeline().addLast(\"ProtocolHandler\", new WebSocketServerProtocolHandler(\"/ws\")); //消息处理 ctx.pipeline().addLast(\"webhandler\",new WebServerHandler()); &#125;&#125; 其中CustomUrlHandler和WebServerHandler是自己定义的handler，其他是api实现。CustomUrlHandler是用于web端的登录校验用的，伪代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/** * @Author: sillybilly * @Date: 2020/3/25 16:14 * @Description: 请求url参数解析 * @Version: 1.0 */@Slf4jpublic class CustomUrlHandler extends ChannelInboundHandlerAdapter &#123; //设置web端登录超时时间为10分钟 防止恶意重试 private static final long OVER_TIME = 10 * 60 * 1000L; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; // 只针对FullHttpRequest类型的做处理，其它类型的自动放过 if (msg instanceof FullHttpRequest) &#123; FullHttpRequest request = (FullHttpRequest) msg; String uri = request.uri(); int idx = uri.indexOf(\"?\"); if (idx &gt; 0) &#123; String query = uri.substring(idx + 1); // uri中参数的解析使用的是jetty-util包，其性能比自定义及正则性能高。 MultiMap values = new MultiMap(); UrlEncoded.decodeTo(query, values, \"UTF-8\"); //根据约定算法 -- 登录校验 boolean isValid = loginValidate(values); if (isValid) &#123; //登录成功-保存当前登录信息 saveWebInfo(***); request.setUri(uri.substring(0, idx)); &#125; else &#123; //验证失败 关闭连接 ctx.disconnect(); &#125; &#125; &#125; ctx.fireChannelRead(msg); &#125; /** * @return boolean * @Author sillybilly * @Description values Verification validity * @Date 2020/3/4 * @Param [values, ts] */ private boolean loginValidate(MultiMap values) &#123; //ts超时？ long parmTime = StringToLong(ts).orElseGet(() -&gt; 0L); //long diffTime = Clock.systemUTC().millis() - parmTime; long current = Clock.systemUTC().millis(); long diffTime = current - parmTime; if (diffTime &gt; OVER_TIME) &#123; log.info(\"CustomUrlHandler.loginValidate 验证超时,&#123;&#125;\", ts); return false; &#125; //根据约定算法验证登录者身份信息 成功返回true 失败false return ?; &#125;&#125; WebServerHandler是handler的尾链，用来处理成功登录的web端与pos机通信，web端信息和pos机信息分别存放在两个不同本地缓存中，根据登录的身份码完成一对一通信。WebServerHandler伪代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * @Author: sillybilly * @Date: 2020/3/25 16:16 * @Description: web端tailhandler * @Version: 1.0 */@Slf4jpublic class WebServerHandler extends SimpleChannelInboundHandler&lt;WebSocketFrame&gt; &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; // WebSocket消息处理 try &#123; if (msg instanceof WebSocketFrame) &#123; String webSocketInfo = ((TextWebSocketFrame) msg).text().trim(); log.debug(\"receive webSocket Info:&#123;&#125;\", webSocketInfo); //找到与其对应的tcp连接并发送消息 tcpInfO = findTcpInfo() ChannelWriteUtils.channelWrite(tcpInfO,webSocketInfo); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); log.info(\"WebServerHandler.channelRead 非心跳，非规范业务消息类型\"); &#125; &#125; @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception &#123; log.debug(\"client: \" + ctx.channel() + \" disconnect\"); //同时删除对应本地缓存信息 deleteCache(***); super.channelInactive(ctx); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; cause.printStackTrace(); if (ctx.channel().isActive()) &#123; ctx.channel().close(); &#125; &#125; @Override protected void channelRead0(ChannelHandlerContext channelHandlerContext, WebSocketFrame webSocketFrame) throws Exception &#123; &#125;&#125; tcp处理tcp端需要处理心跳连接，每次心跳都需要进行缓存。心跳即为ping-pong处理，pos机每次ping结束，netty服务端都需要发送一个pong信息，以便tcp和netty都能确定双方的存活状态。伪代码大概如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * @Author: sillybilly * @Date: 2020/5/27 13:36 * @Description: 心跳发送处理 * @Version: 1.0 */@Slf4jpublic class ConnectorIdleState extends ChannelInboundHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; String heartBeats = String.valueOf(msg); //json字符串不合法 解析失败？ try &#123; if 发送的信息为心跳信息&#123; //更新redis缓存 pos机心跳的时间戳 updataHeartBeatsTs(); //逻辑处理 存入pos机代码 checkAndSave(ctx.channel()); //将pong写回pos机 writeBackHeartBeats(sth.); //释放bytebuf ReferenceCountUtil.release(msg); &#125;else &#123; if 此前已登录&#123; //将信息转给下个handler ctx.fireChannelRead(msg); &#125;else &#123; ReferenceCountUtil.release(msg); log.info(\"ConnectorIdleState.channelRead 心跳未接入成功\"); &#125; &#125; &#125; catch (JsonSyntaxException e)&#123; ReferenceCountUtil.release(msg); log.warn(\"ConnectorIdleState.channelRead 非心跳，非规范业务消息类型\"); &#125; &#125; @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception &#123; log.debug(\"client: \" + ctx.channel().remoteAddress() + \" disconnect\"); //清缓存 deleteCache(***); super.channelInactive(ctx); &#125;&#125; 测试我们可以写一个tcp客户端和web端测试一下，tcp客户端可以用netty编写，也可以用直接用Telent连接，这里忽略。websocket: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;WebSocket客户端&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;script type=\"text/javascript\"&gt; var socket; if (window.WebSocket) &#123; //？后面携带自身信息，包含当前时间戳 socket = new WebSocket(\"ws://localhost:8080/ws?********\"); socket.onmessage = function (event) &#123; var ta = document.getElementById('responseText'); ta.value = ta.value + \"\\n\" + event.data; &#125;; socket.onopen = function (event) &#123; var ta = document.getElementById('responseText') ta.value = \"连接开启\" &#125; socket.onclose = function (event) &#123; var ta = document.getElementById('responseText'); ta.value = ta.value + \"\\n\" + \"连接关闭\"; &#125; &#125; else &#123; alert('浏览器不支持WebSocket！') &#125; function send(message) &#123; if (!window.WebSocket) &#123; return; &#125; if (socket.readyState == WebSocket.OPEN) &#123; socket.send(message); &#125; else &#123; alert(\"连接尚未开启\") &#125; &#125;&lt;/script&gt;&lt;form onsubmit=\"return false;\"&gt; &lt;textarea name=\"message\" style=\"width: 400px;height:200px\"&gt;&lt;/textarea&gt; &lt;input type=\"button\" value=\"发送数据\" onclick=\"send(this.form.message.value)\"&gt; &lt;h3&gt;服务端输出：&lt;/h3&gt; &lt;textarea id=\"responseText\" style=\"width: 400px;height: 300px;\"&gt;&lt;/textarea&gt; &lt;input type=\"button\" onclick=\"javascript: document.getElementById('responseText').value=''\" value=\"清除内容\"&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt;","categories":[{"name":"netty","slug":"netty","permalink":"https://sillybilly-share.top/categories/netty/"}],"tags":[{"name":"netty","slug":"netty","permalink":"https://sillybilly-share.top/tags/netty/"},{"name":"tcp","slug":"tcp","permalink":"https://sillybilly-share.top/tags/tcp/"},{"name":"websocket","slug":"websocket","permalink":"https://sillybilly-share.top/tags/websocket/"}]},{"title":"java8之CompletableFuture初识","slug":"java8之CompletableFuture初识","date":"2020-03-24T13:43:07.000Z","updated":"2022-11-24T01:35:09.628Z","comments":true,"path":"java8之CompletableFuture初识.html","link":"","permalink":"https://sillybilly-share.top/java8%E4%B9%8BCompletableFuture%E5%88%9D%E8%AF%86.html","excerpt":"提要在jdk5中增加了很多新的并发处理机制，对于多线程处理有了很大的优化。我们通常会选择通过Future接口构建异步的应用，因为在之前的多线程的实现中，不管是继承thread类还是实现runnable接口，都无法保证获取到之前的执行结果。我们现在可以通过实现Callable接口，并用Future来接收多线程的执行结果。 Callable处理demo通过kafka多线程消费举个例子(伪代码): 1234567891011121314151617181920212223public void execute(int threads) &#123; //threads核心数 10-最大线程数 0L-空闲等待时间 var executors = new ThreadPoolExecutor(threads, 10, 0L, TimeUnit.MILLISECONDS, new ArrayBlockingQueue(1000), new ThreadPoolExecutor.CallerRunsPolicy());//启动一个子线程来监听消息 Thread t = new Thread(() -&gt; &#123; try &#123; while (true) &#123; /*采用循环不断从kafka里捞数据*/ ConsumerRecords&lt;String, String&gt; records = //todo 返回数据; List&lt;Callable&lt;String&gt;&gt; consumerWork = new ArrayList&lt;&gt;(); for (final ConsumerRecord record : records) &#123; consumerWork.add(writeData(record)); &#125; List&lt;Future&lt;String&gt;&gt; futures = executors.invokeAll(consumerWork); //拿到futures结果 &#125; &#125; catch (InterruptedException e) &#123; log.error(\"Test.execute()-&gt;&#123;&#125;\",e); &#125; &#125;); t.start();&#125;","text":"提要在jdk5中增加了很多新的并发处理机制，对于多线程处理有了很大的优化。我们通常会选择通过Future接口构建异步的应用，因为在之前的多线程的实现中，不管是继承thread类还是实现runnable接口，都无法保证获取到之前的执行结果。我们现在可以通过实现Callable接口，并用Future来接收多线程的执行结果。 Callable处理demo通过kafka多线程消费举个例子(伪代码): 1234567891011121314151617181920212223public void execute(int threads) &#123; //threads核心数 10-最大线程数 0L-空闲等待时间 var executors = new ThreadPoolExecutor(threads, 10, 0L, TimeUnit.MILLISECONDS, new ArrayBlockingQueue(1000), new ThreadPoolExecutor.CallerRunsPolicy());//启动一个子线程来监听消息 Thread t = new Thread(() -&gt; &#123; try &#123; while (true) &#123; /*采用循环不断从kafka里捞数据*/ ConsumerRecords&lt;String, String&gt; records = //todo 返回数据; List&lt;Callable&lt;String&gt;&gt; consumerWork = new ArrayList&lt;&gt;(); for (final ConsumerRecord record : records) &#123; consumerWork.add(writeData(record)); &#125; List&lt;Future&lt;String&gt;&gt; futures = executors.invokeAll(consumerWork); //拿到futures结果 &#125; &#125; catch (InterruptedException e) &#123; log.error(\"Test.execute()-&gt;&#123;&#125;\",e); &#125; &#125;); t.start();&#125; 下面是实现Callable的耗时任务(伪代码): 123456789101112131415private Callable&lt;String&gt; writeData(ConsumerRecord record) &#123; Callable&lt;String&gt; run = new Callable&lt;String&gt;() &#123; public void run() &#123; // TODO 耗时任务逻辑 /*业务处理*/ &#125; @Override public String call() throws Exception &#123; // TODO Auto-generated method stub run(); return null; &#125; &#125;; return run;&#125; 看起来挺不错的，可是当我们真正去调用get()方法时，当前线程会去等待异步任务的执行。换言之，主线程会被阻塞，大大增加了异步操作的时耗。 CompletableFuture使用实际开发场景 针对Future的完成事件，我们希望可以得到它完成后的返回结果，又不想阻塞主线程的运行 面对Future集合来讲，很难将List中的future结果依赖关系描述出来，我们希望在所有future完成结束后去做一些事情 在异步计算中，存在某两个业务处理独立计算，而其中一个依赖前一个的运算结果。如上的几种场景，是future的短板，它本身缺乏一种观察者模式去监听线程处理状态从而得到回调结果。面对这样的局限性，在java8中CompletableFuture提供了较为不错的api实现 CompletableFuture常见API解析注：所有没有指定Executor的方法会使用ForkJoinPool.commonPool() 作为它的线程池执行异步代码 创建异步任务runAsync和supplyAsync123456789101112131415public static &lt;U&gt; CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; var0) &#123; return asyncSupplyStage(asyncPool, var0);&#125;public static &lt;U&gt; CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; var0, Executor var1) &#123; return asyncSupplyStage(screenExecutor(var1), var0);&#125;public static CompletableFuture&lt;Void&gt; runAsync(Runnable var0) &#123; return asyncRunStage(asyncPool, var0);&#125;public static CompletableFuture&lt;Void&gt; runAsync(Runnable var0, Executor var1) &#123; return asyncRunStage(screenExecutor(var1), var0);&#125; runAsync方法没有返回值，异步操作完就结束了,而supplyAsync方法类似submit方法，支持返回值。 异步任务执行完时的回调方法whenComplete和exceptionally1234567891011121314public CompletableFuture&lt;T&gt; whenComplete(BiConsumer&lt;? super T, ? super Throwable&gt; var1) &#123; return this.uniWhenCompleteStage((Executor)null, var1);&#125;public CompletableFuture&lt;T&gt; whenCompleteAsync(BiConsumer&lt;? super T, ? super Throwable&gt; var1) &#123; return this.uniWhenCompleteStage(asyncPool, var1);&#125;public CompletableFuture&lt;T&gt; whenCompleteAsync(BiConsumer&lt;? super T, ? super Throwable&gt; var1, Executor var2) &#123; return this.uniWhenCompleteStage(screenExecutor(var2), var1);&#125;public CompletableFuture&lt;T&gt; exceptionally(Function&lt;Throwable, ? extends T&gt; var1) &#123; return this.uniExceptionallyStage(var1);&#125; 这些方法都是上述创建的异步任务完成后 (也可能是抛出异常后结束) 所执行的方法。whenComplete和whenCompleteAsync方法的区别在于： &emsp;前者是由上面的线程继续执行，而后者是将whenCompleteAsync的任务继续交给线程池去做决定。exceptionally则是上面的任务执行抛出异常后所要执行的方法。值得注意的是：哪怕supplyAsync抛出了异常，whenComplete也会执行，意思就是，只要supplyAsync执行结束，它就会执行，不管是不是正常执行完。exceptionally只有在异常的时候才会执行。其实，在whenComplete的参数内e就代表异常了，判断它是否为null，就可以判断是否有异常，只不过这样的做法，我们不提倡。whenComplete和exceptionally这两个谁在前，谁先执行。 此类的回调方法，哪怕主线程已经执行结束，回调方法依然可以继续等待异步任务执行完成再触发得到执行结果。 thenApply和handle方法如果两个任务之间有依赖关系，比如B任务依赖于A任务的执行结果，那么就可以使用这两个方法。 123456789101112131415161718192021public &lt;U&gt; CompletableFuture&lt;U&gt; thenApply(Function&lt;? super T, ? extends U&gt; var1) &#123; return this.uniApplyStage((Executor)null, var1);&#125;public &lt;U&gt; CompletableFuture&lt;U&gt; thenApplyAsync(Function&lt;? super T, ? extends U&gt; var1) &#123; return this.uniApplyStage(asyncPool, var1);&#125;public &lt;U&gt; CompletableFuture&lt;U&gt; thenApplyAsync(Function&lt;? super T, ? extends U&gt; var1, Executor var2) &#123; return this.uniApplyStage(screenExecutor(var2), var1);&#125;public &lt;U&gt; CompletableFuture&lt;U&gt; handle(BiFunction&lt;? super T, Throwable, ? extends U&gt; var1) &#123; return this.uniHandleStage((Executor)null, var1);&#125;public &lt;U&gt; CompletableFuture&lt;U&gt; handleAsync(BiFunction&lt;? super T, Throwable, ? extends U&gt; var1) &#123; return this.uniHandleStage(asyncPool, var1);&#125;public &lt;U&gt; CompletableFuture&lt;U&gt; handleAsync(BiFunction&lt;? super T, Throwable, ? extends U&gt; var1, Executor var2) &#123; return this.uniHandleStage(screenExecutor(var2), var1);&#125; 这两个方法，效果是一样的。区别在于，当A任务执行出现异常时，thenApply方法不会执行，而handle 方法一样会去执行，因为在handle方法里，我们可以处理异常，而前者不行。这里延伸两个方法thenAccept和thenRun。其实和上面两个方法差不多，都是等待前面一个任务执行完 再执行。区别就在于thenAccept接收前面任务的结果，且无需return。而thenRun只要前面的任务执行完成，它就执行，不关心前面的执行结果如何如果前面的任务抛了异常，非正常结束，这两个方法是不会执行的，所以处理不了异常情况。 allOf方法123public static CompletableFuture&lt;Void&gt; allOf(CompletableFuture... var0) &#123; return andTree(var0, 0, var0.length - 1);&#125; 很多时候，不止存在两个异步任务，可能有几十上百个。我们需要等这些任务都完成后，再来执行相应的操作。那怎么集中监听所有任务执行结束与否呢？ allOf方法可以帮我们完成它接收一个可变入参，既可以接收CompletableFuture单个对象，可以接收其数组对象。 代码重构大致了解jdk8中对多线程异步流处理之后，我们对刚开始的代码进一步修改（对应业务-&gt;某两个业务处理独立计算，而其中一个依赖前一个的运算结果） 12345678910111213141516public void execute(int threads)&#123; var executors = new ThreadPoolExecutor(threads, 10, 0L, TimeUnit.MILLISECONDS, new ArrayBlockingQueue(1000), new ThreadPoolExecutor.CallerRunsPolicy()); while (true) &#123; /*采用循环不断从kafka里捞数据*/ ConsumerRecords&lt;String, String&gt; records = //todo 返回数据; //基于异步的流式编程 Flux.fromIterable(records) .doOnNext(a -&gt; CompletableFuture.supplyAsync(()-&gt;&#123; //创建异步任务 return parse1(a); //todo 处理d中数据 &#125;,executors).thenAcceptAsync(b-&gt;parse2(b))) //取得parse1处理后的数据进行下一步处理 .subscribe(); //订阅处理流 &#125;&#125; 归档 Futrue FutureTask CompletionService CompletableFuture 原理 Futrue接口 RunnableFuture的实现类 阻塞队列+FutureTask接口 FutureCompletionStage实现类 支持任务完成先后顺序 支持 未知 支持 支持 异常捕捉 代码实现 代码实现 代码实现 源生API支持 建议 CPU高速轮询，耗资源 功能不对口，并发任务这一块多套一层 没有JDK8CompletableFuture之前最好的方案 API极端丰富，配合流式编程，速度飞起，推荐使用","categories":[{"name":"java","slug":"java","permalink":"https://sillybilly-share.top/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://sillybilly-share.top/tags/java/"},{"name":"multi-thread","slug":"multi-thread","permalink":"https://sillybilly-share.top/tags/multi-thread/"}]},{"title":"ceph对象存储-amasonaws s3 api验证","slug":"ceph对象存储-amasonaws-s3-api验证","date":"2020-03-23T13:01:50.000Z","updated":"2022-11-24T01:35:09.627Z","comments":true,"path":"ceph对象存储-amasonaws-s3-api验证.html","link":"","permalink":"https://sillybilly-share.top/ceph%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8-amasonaws-s3-api%E9%AA%8C%E8%AF%81.html","excerpt":"前提 Ceph的软件库为客户端应用程序对基于RADOS对象的存储系统提供了直接访问，并为Ceph的某些高级功能（包括RADOS块设备（RBD），RADOS网关（RGW）和Ceph文件系统（ CephFS）提供技术支持。其中Ceph对象网关(RGW)是在librados之上构建的对象存储接口，旨在为应用程序提供通往Ceph存储集群的RESTful网关。Ceph对象存储支持两个接口,它同时兼容amazonaws s3和OpenStack swift。本文主要通过s3调用ceph的对象存储功能，验证数据上传下载的稳定性。 在ceph官方上查阅s3的api(java)，其实文档已经很老旧了，用来验证程序可能会出现很多问题，地址:ceph官网 推荐直接去amazonaws官网找资料，地址:amazonaws s3 api","text":"前提 Ceph的软件库为客户端应用程序对基于RADOS对象的存储系统提供了直接访问，并为Ceph的某些高级功能（包括RADOS块设备（RBD），RADOS网关（RGW）和Ceph文件系统（ CephFS）提供技术支持。其中Ceph对象网关(RGW)是在librados之上构建的对象存储接口，旨在为应用程序提供通往Ceph存储集群的RESTful网关。Ceph对象存储支持两个接口,它同时兼容amazonaws s3和OpenStack swift。本文主要通过s3调用ceph的对象存储功能，验证数据上传下载的稳定性。 在ceph官方上查阅s3的api(java)，其实文档已经很老旧了，用来验证程序可能会出现很多问题，地址:ceph官网 推荐直接去amazonaws官网找资料，地址:amazonaws s3 api AmazonS3 maven相关依赖首先创建一个maven工程，添加AmazonAws S3相关jar包 12345678910111213141516&lt;!-- AmazonS3对象存储 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.amazonaws&lt;/groupId&gt; &lt;artifactId&gt;aws-java-sdk-s3&lt;/artifactId&gt; &lt;version&gt;1.11.592&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.amazonaws&lt;/groupId&gt; &lt;artifactId&gt;aws-java-sdk-core&lt;/artifactId&gt; &lt;version&gt;1.11.592&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;27.0.1-jre&lt;/version&gt;&lt;/dependency&gt; s3 api基本方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101@Configurationpublic class AmazonawsS3utils &#123; //s3用户身份验证accessKey、secretKey 配置信息在yml文件中 @Value(\"$&#123;accessKey:null&#125;\") private String accessKey; @Value(\"$&#123;secretKey:null&#125;\") private String secretKey; //服务器地址 @Value(\"$&#123;endPoint:null&#125;\") private String endPoint; //自定义一个bucket值 @Value(\"$&#123;bucketName:null&#125;\") private String bucketName; private static AmazonS3 amazonS3 = null; public AmazonS3 getConnection() &#123; if (amazonS3 == null) &#123; synchronized (this) &#123; if (amazonS3 == null) &#123; AWSCredentials credentials = new BasicAWSCredentials(accessKey, secretKey); ClientConfiguration clientConfig = new ClientConfiguration(); clientConfig.setProtocol(Protocol.HTTP); ////设置用于签署此客户端请求的签名算法的名称。如果未设置或显式设置为null，客户端将根据服务和区域的支持的签名算法的配置文件选择使用的签名算法。 clientConfig.setSignerOverride(\"S3SignerType\"); amazonS3 = AmazonS3ClientBuilder.standard() .withEndpointConfiguration(new AwsClientBuilder.EndpointConfiguration(endPoint, Regions.US_EAST_1.name())) .withPathStyleAccessEnabled(true) .withClientConfiguration(clientConfig) .withCredentials(new AWSStaticCredentialsProvider(credentials)) .build(); if (!amazonS3.doesBucketExistV2(bucketName)) &#123; amazonS3.createBucket(bucketName); &#125; &#125; &#125; &#125; return amazonS3; &#125; public void upload(String amazonS3Key, InputStream inputStream, ObjectMetadata objectMetadata) &#123; AmazonS3 amazonS3 = this.getConnection(); PutObjectRequest request = new PutObjectRequest(bucketName, amazonS3Key, inputStream, objectMetadata); //设置大小接近100MB. request.getRequestClientOptions().setReadLimit(1024 * 1204 * 100); amazonS3.putObject(request); &#125; public InputStream download(String key) &#123; AmazonS3 amazonS3 = this.getConnection(); GetObjectRequest request = new GetObjectRequest(bucketName, key); S3Object object = amazonS3.getObject(request); return object.getObjectContent(); &#125; public void download(String key, File file) &#123; AmazonS3 amazonS3 = this.getConnection(); amazonS3.getObject(new GetObjectRequest(bucketName, key), file); &#125; public long downloadLength(String key) &#123; AmazonS3 amazonS3 = this.getConnection(); return amazonS3.getObjectMetadata(bucketName, key).getContentLength(); &#125; public void delete(String key) &#123; AmazonS3 amazonS3 = this.getConnection(); amazonS3.deleteObject(bucketName, key); &#125; public ObjectMetadata getObjectMetadata(String key) &#123; AmazonS3 amazonS3 = this.getConnection(); ObjectMetadata objectMetadata = amazonS3.getObjectMetadata(bucketName, key); return objectMetadata; &#125; public URL getGeneratePresignedUrl(String key)&#123; AmazonS3 amazonS3 = this.getConnection(); GeneratePresignedUrlRequest request = new GeneratePresignedUrlRequest(bucketName,key); //一个预签名URL，可用于访问Amazon S3资源，而无需URL用户知道账户的AWS安全凭证 return amazonS3.generatePresignedUrl(request); &#125; public boolean isExist(String key) &#123; AmazonS3 amazonS3 = this.getConnection(); boolean b = amazonS3.doesObjectExist(bucketName, key); return b; &#125; public boolean isExistByKey(String key) &#123; if (StringUtils.isNotBlank(key)) &#123; AmazonS3 amazonS3 = this.getConnection(); boolean b = amazonS3.doesObjectExist(bucketName, key); return b; &#125; return false; &#125; 验证上传的可用性和下载稳定性首先创建类实现上传功能,并注入AmazonawsS3utils工具类SpeedVerifyService.java 123456789101112131415161718192021@Servicepublic class SpeedVerifyService &#123; @Autowired private AmazonawsS3utils amazonawsS3utils; /** * 上传文件 * * @param key s3桶键值 * @param path 源地址路径 * @throws FileNotFoundException */ public void upload(String key, String path) throws FileNotFoundException &#123; File file = new File(path); FileInputStream stream = new FileInputStream(file); ObjectMetadata data = new ObjectMetadata(); //大文件上需要预设文件长度，否则会出现outOfMemoryError data.setContentLength(file.length()); amazonawsS3utils.upload(key, stream, data); &#125;&#125; 通过创建Junit测试类上传不同格式的文件，在确保程序正常运行，且数据未丢包的情况下，开始侧重验证下载功能 单线程验证s3提供了不同的下载接口，我们这里直接用getObject(GetObjectRequest getObjectRequest, File destinationFile)指定下载路径下载ceph上的文件。验证程序要求计算下载过程中的最大速率、平均速率以及总耗时。所以需要开启一个子线程来实时计算已下载文件的大小。在原SpeedVerifyService.java添加以下代码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141/** * @Author: silly-billy * @Date: 2020/3/20 14:23 * @Description: 上传 下载 删除 测速 * @Version: 1.0 */@Service@Slf4jpublic class SpeedVerifyService &#123; @Autowired private AmazonawsS3utils amazonawsS3utils; /** * 上传文件 * * @param key s3桶键值 * @param path 源地址路径 * @throws FileNotFoundException */ public void upload(String key, String path) throws FileNotFoundException &#123; File file = new File(path); FileInputStream stream = new FileInputStream(file); ObjectMetadata data = new ObjectMetadata(); //大文件上需要预设文件长度，否则会出现outOfMemoryError data.setContentLength(file.length()); amazonawsS3utils.upload(key, stream, data); &#125; /** * 删除指定桶-键文件 * * @param key */ public void delete(String key) &#123; amazonawsS3utils.delete(key); &#125; /** * 下载文件 * key-bucket对应键下对象 * path本地下载地址 */ public CompletableFuture&lt;Map&lt;String, Double&gt;&gt; showDownloadDetails(String key, String path) &#123; File file = new File(path); //开启一个子线程用于测速 CompletableFuture&lt;Map&lt;String, Double&gt;&gt; future = dowloadListening(key, file); //文件下载 amazonawsS3utils.download(key, file); return future; &#125; /** * 下载测速并返回异步结果 * * @param file * @return */ private CompletableFuture&lt;Map&lt;String, Double&gt;&gt; dowloadListening(String key, File file) &#123; ThreadFactory namedThreadFactory = new ThreadFactoryBuilder() .setNameFormat(\"test-speed-%d\").build(); ExecutorService singleThreadPool = new ThreadPoolExecutor(1, 300, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(1024), namedThreadFactory, new ThreadPoolExecutor.AbortPolicy()); CompletableFuture&lt;Map&lt;String, Double&gt;&gt; resultFuture = CompletableFuture.supplyAsync(() -&gt; &#123; Map&lt;String, Double&gt; resultMap = new HashMap&lt;&gt;(); try &#123; log.info(\"测速线程启动,&#123;&#125;\",Thread.currentThread().getName()); //文件大小 long length = amazonawsS3utils.downloadLength(key); //下载速度集合 List&lt;Double&gt; speeds = new ArrayList&lt;&gt;(); //上一次时间节点 long lastTime = Clock.systemUTC().millis(); //当前时间节点 long currentTime; //上一次文件大小 long lastFileSize = 0L; //已下载文件大小 long currentFileSize; //开始下载时间 long startTime = 0L; while (true) &#123; if (!file.exists()) &#123; continue; &#125; if (0L == startTime)&#123; startTime = Clock.systemUTC().millis(); &#125; currentFileSize = file.length(); if (currentFileSize &gt;= length) &#123; if (speeds.isEmpty()) &#123; log.info(\"已下载文件\"); break; &#125; currentTime = Clock.systemUTC().millis(); //单位 kb/s double speed = (1000 * (currentFileSize - lastFileSize)) / (1024 * (currentTime - lastTime)); speeds.add(speed); log.info(\"实时速度：&#123;&#125;kb/s\", speed); log.info(\"当前进度：&#123;&#125;%\", (currentFileSize / (double) length) * 100); double consumeTime = (currentTime - startTime) / 1000; double maxSpeed = speeds.stream().distinct().max(Double::compareTo).get(); double avgSpeed = speeds.stream().mapToDouble(x -&gt; x).average().getAsDouble(); log.info(\"下载完成,总耗时：&#123;&#125;s\", consumeTime); log.info(\"最大时速：&#123;&#125;kb/s\", maxSpeed); log.info(\"平均时速：&#123;&#125;kb/s\", avgSpeed); resultMap.put(\"耗时\", consumeTime); resultMap.put(\"最大下载速度\", maxSpeed); resultMap.put(\"平均下载速度\", (double) Math.round(avgSpeed * 100) / 100); break; &#125; currentTime = Clock.systemUTC().millis(); long size = currentFileSize - lastFileSize; if (size == 0) &#123; //未下载 continue; &#125; double speed = (1000 * size) / (1024 * (currentTime - lastTime)); lastTime = currentTime; lastFileSize = currentFileSize; speeds.add(speed); log.info(\"实时速度：&#123;&#125;kb/s\", speed); log.info(\"当前进度：&#123;&#125;%\", (currentFileSize / (double) length) * 100); Thread.sleep(1000); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); return null; &#125; return resultMap; &#125;, singleThreadPool); if (!singleThreadPool.isShutdown()) &#123; singleThreadPool.shutdown(); &#125; return resultFuture; &#125;&#125; 然后可以通过测试类或者用添加web依赖，用postman进行测试，我们这里新建一个Controller，调用showDownloadDetails(key,file)方法,然后抛出异步返回结果SpeedVerifyController.java: 1234567891011121314151617181920212223242526@Controller@Slf4jpublic class SpeedVerifyController &#123; @Autowired SpeedVerifyService speedVerifyService; /** * @param key 通键值 * @param path 下载保存路径 * @return */ @ResponseBody @GetMapping(\"/showSpeedDetails\") public Map&lt;String, Double&gt; showSpeedDetails(@RequestParam(\"key\") String key, @RequestParam(\"path\") String path) &#123; try &#123; Map&lt;String, Double&gt; resultMap = speedVerifyService.showDownloadDetails(key, path).get(); return resultMap; &#125; catch (InterruptedException e) &#123; log.error(e.getMessage()); &#125; catch (ExecutionException e) &#123; log.error(e.getMessage()); &#125; return null; &#125;&#125; 控制台打印结果: 12345678910111213142020-03-23 23:06:02.493 INFO com.set.cephverify.service.SpeedVerifyService - 下载线程启动,Thread[http-nio-8080-exec-1,5,main]2020-03-23 23:06:02.498 INFO com.set.cephverify.service.SpeedVerifyService - 测速线程启动,test-speed-02020-03-23 23:06:03.057 INFO com.set.cephverify.service.SpeedVerifyService - 实时速度：350.0kb&#x2F;s2020-03-23 23:06:03.057 INFO com.set.cephverify.service.SpeedVerifyService - 当前进度：0.11664949383248767%2020-03-23 23:06:04.098 INFO com.set.cephverify.service.SpeedVerifyService - 实时速度：1066.0kb&#x2F;s2020-03-23 23:06:04.099 INFO com.set.cephverify.service.SpeedVerifyService - 当前进度：11.643242433961678%...2020-03-23 23:07:04.877 INFO com.set.cephverify.service.SpeedVerifyService - 实时速度：1965.0kb&#x2F;s2020-03-23 23:07:04.877 INFO com.set.cephverify.service.SpeedVerifyService - 当前进度：97.21021070550222%2020-03-23 23:07:05.877 INFO com.set.cephverify.service.SpeedVerifyService - 实时速度：268.0kb&#x2F;s2020-03-23 23:07:05.877 INFO com.set.cephverify.service.SpeedVerifyService - 当前进度：100.0%2020-03-23 23:07:05.884 INFO com.set.cephverify.service.SpeedVerifyService - 下载完成,总耗时：62.0s2020-03-23 23:07:05.884 INFO com.set.cephverify.service.SpeedVerifyService - 最大时速：2036.0kb&#x2F;s2020-03-23 23:07:05.885 INFO com.set.cephverify.service.SpeedVerifyService - 平均时速：659.2kb&#x2F;s postman异步返回值：由于我这里是用VPN挂的网络环境，所以速度慢了很多，网络正常的话测试是十几M/s。尝试下载不同大小的文件(1M-2GB),不同的文件格式(mp3,mp4,txt,exe…),程序执行完成后，根据下载路径打开文件，确保文件未曾损坏或缺失。 多线程验证接着我们需要开启多个线程在ceph服务器上下载同一个文件，以此模拟多用户同时下载某个文件时，确认ceph服务器是否能够提供有效的下载支持以及验证ceph的稳定性。 1234567891011121314151617181920212223242526272829303132333435363738394041/** * 模拟多用户同时下载文件，ceph性能验证 * @param key s3桶键值 * @param threadNum 线程数 * @param path 下载保存路径 n个线程对应n个path * @return */ public List&lt;CompletableFuture&lt;Map&lt;String,Double&gt;&gt;&gt; showMultiDownloadDetails(String key,int threadNum,final String... path)&#123; //开启多线程 var executor = new ThreadPoolExecutor(threadNum, 300, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingDeque&lt;&gt;(1000), new ThreadPoolExecutor.CallerRunsPolicy()); List&lt;CompletableFuture&lt;Map&lt;String,Double&gt;&gt;&gt; futures = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; threadNum; i++) &#123; int index = i; //保存异步处理结果 CompletableFuture.supplyAsync(()-&gt;showDownloadDetails(key,path[index]),executor) .thenAccept(result-&gt;&#123; synchronized (this)&#123; //同一时间多个线程进入arrayList.add方法会出现不安全问题--数据覆盖 futures.add(result); &#125; &#125;); &#125; while (true) &#123; if (futures.size() &lt; threadNum) &#123; try &#123; //while(true)这种方式判断的执行级别过高，会阻塞其他子线程的执行 //所以每次判断后需要sleep一段时间 Thread.sleep(100L); &#125; catch (InterruptedException e) &#123; log.info(e.getMessage()); &#125; continue; &#125; break; &#125; if (!executor.isShutdown())&#123; executor.shutdown(); &#125; return futures; &#125; 耗时任务调用单线程的下载逻辑即可，这里简单的通过异步结果数组个数和线程数做判断，用来确定所有异步future返回了结果(因为实现逻辑的线程数和任务处理个数是一致的)，抛弃这个特殊情况，一般多个异步任务判断是否全部执行完毕，是通过定义volatile字段的数值描述线程执行状态。注：在多线程的任务调度中，可以通过jdk原生命令调用jps命令获取java运行的pid,然后通过jstack命令查看每个执行线程的堆栈信息，排查问题。 新建一个测试类测试一下结果： 12345678910111213141516171819202122@Testvoid showDownloadDetails() throws ExecutionException, InterruptedException, IOException &#123; String key = ***; int threadNum = ***; String[] paths = ***; var futures = speedVerifyService.showMultiDownloadDetails(key, threadNum, paths); System.err.println( futures.stream().map(m-&gt;&#123; try &#123; return m.get(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; return null; &#125;); )； &#125; 控制台打印结果：经过多次测试，ceph下载文件在单线程状态下没有任何问题。在多线程状态下，ceph的下载速率随着线程数增多，下载速率会变慢。(发现所有线程总的下载速率和单线程情况下几乎一致，可能用的同一个连接的缘故)如果文件格式过大，比如1G以上的文件，如果开启超过60个线程，会出现丢包的情况,甚至少数线程并没有执行s3的download方法，查看线程堆栈信息，发现此类线程一直处于wait状态。文件越大，可同时开启的线程数就越少，具体问题未知(有空去问问运维)。","categories":[{"name":"java","slug":"java","permalink":"https://sillybilly-share.top/categories/java/"},{"name":"ceph","slug":"ceph","permalink":"https://sillybilly-share.top/categories/ceph/"},{"name":"oss","slug":"ceph/oss","permalink":"https://sillybilly-share.top/categories/ceph/oss/"},{"name":"amazonaws s3","slug":"amazonaws-s3","permalink":"https://sillybilly-share.top/categories/amazonaws-s3/"}],"tags":[{"name":"java","slug":"java","permalink":"https://sillybilly-share.top/tags/java/"},{"name":"ceph","slug":"ceph","permalink":"https://sillybilly-share.top/tags/ceph/"},{"name":"oss","slug":"oss","permalink":"https://sillybilly-share.top/tags/oss/"}]}]}